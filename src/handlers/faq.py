import logging
import os
import re
import tempfile
import unicodedata
from collections.abc import Sequence
from functools import lru_cache

from aiogram import Dispatcher, F, Router
from aiogram.filters import Command
from aiogram.fsm.context import FSMContext
from aiogram.types import (
    CallbackQuery,
    FSInputFile,
    InlineKeyboardButton,
    InlineKeyboardMarkup,
    Message,
    InputFile,
)
from aiogram.enums import ParseMode
from sqlalchemy import desc, select

from ..deepseek_client import deepseek
from ..knowledge import search_store
from ..knowledge.text_search import STRUCTURED_DIR
from ..knowledge import image_mapper
from .. import prompt_config
from ..db.chat_history import get_chat_history, save_chat_message
from ..db.user_profile import get_or_create_user_profile, update_user_profile, get_user_profile, reset_user_profile_fields, check_status_changed
from ..handlers.booking import BookingStates
from ..handlers.policy import show_policy_window
from ..stt_client import transcribe_file


router = Router()

LINKS_FILE_PATH = os.path.abspath(
    os.path.join(os.path.dirname(__file__), "..", "knowledge", "data", "links.txt")
)

PRIMARY_SOURCE_LABELS: dict[str, str] = {
    "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt": "–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_2021.pdf",
    "2.1.1_–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞_structured.txt": "–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –ü–∏—Ä–∞–º–∏–¥—ã_2018.pdf",
    "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt": (
        "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_2020.pdf"
    ),
}
CORONA_SOURCE = "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt"
TECHNICAL_REQUIREMENTS_SOURCE = "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt"

PRIMARY_SOURCE_ALIASES: dict[str, str] = {
    "–∫–æ—Ä–æ–Ω–∞": "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt",
    "–∏–≥—Ä–µ –∫–æ—Ä–æ–Ω–∞": "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt",
    "–ø—Ä–∞–≤–∏–ª–∞ –∫–æ—Ä–æ–Ω–∞": "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt",
    "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥": "2.1.1_–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞_structured.txt",
    "–ø–∏—Ä–∞–º–∏–¥–∞": "2.1.1_–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞_structured.txt",
    "–ø—Ä–∞–≤–∏–ª–∞": "2.1.1_–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞_structured.txt",
    "—Ç—Ä–µ–±–æ–≤–∞–Ω": "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
    "—Ç–µ—Ö–Ω–∏—á": "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
    "—Ä–∞–∑–º–µ—Ä": "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
    "–∞–∫—Å–µ—Å": "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
    "–æ–±–æ—Ä—É–¥": "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
}

STOP_WORDS_FOR_PRIMARY = {"–æ–±—É—á–µ–Ω", "–±–∏—Å–∞", "–º–µ—Ç–æ–¥–∏–∫", "–∞–±–æ–Ω–µ–º–µ–Ω—Ç", "–∫—É—Ä—Å", "—É—Ä–æ–∫", "–∑–∞–Ω—è—Ç–∏", "–æ–ø–ª–∞—Ç",}

# –°—Ç–æ–ø-—Å–ª–æ–≤–∞ –≤ –æ—Ç–≤–µ—Ç–µ LLM, –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ –∫–æ—Ç–æ—Ä—ã—Ö –∫–Ω–æ–ø–∫–∞ "–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫" –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è
STOP_WORDS_IN_LLM_RESPONSE = {"–∏–∑–≤–∏–Ω–∏—Ç–µ", "–∑–∞—Ç—Ä—É–¥–Ω—è", "–∑–∞–ø—Ä–æ—Å", "–∫–æ–Ω—Å—É–ª—å—Ç"}

# –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ï —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ –≤ –æ—Ç–≤–µ—Ç–µ LLM - –∂–µ—Å—Ç–∫–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –∫–Ω–æ–ø–∫–∏ "–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫"
# –î–∞–∂–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª (rule_query=True) –∫–Ω–æ–ø–∫–∞ –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, –µ—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å —ç—Ç–∏ —Å–ª–æ–≤–∞
CRITICAL_STOP_WORDS_IN_LLM_RESPONSE = {"–∑–∞—Ç—Ä—É–¥–Ω", "–∏–∑–≤–∏–Ω"}

RULE_SOURCE_PATTERNS = (
    "2.1.1_",
    "2.1.2_",
    "2.2_",
)

RULE_PRIMARY_ALLOWED_SOURCES = {
    "2.1.1_–ú–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞_structured.txt",
    "2.1.2_–ü—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã –ö–æ—Ä–æ–Ω–∞_structured.txt",
    "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt",
}

RULE_INTENT_KEYWORDS = (
    "–ø—Ä–∞–≤–∏–ª",
    "—Ç—Ä–µ–±–æ–≤–∞–Ω",
    "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫",
    "–∏–≥—Ä",
    "–∫–æ—Ä–æ–Ω–∞",
    "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥",
    "—Ñ–±—Å—Ä",
    "–æ–±–æ—Ä—É–¥",
    "–∞–∫—Å–µ—Å",
    "–±–∏—Ç–æ–∫",
    "–ø—Ä–∏—Ü–µ–ª",
    "—É–¥–∞—Ä",
)

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –¢–µ–º—ã 1 (–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —à–∫–æ–ª–µ)
SCHOOL_TOPIC_KEYWORDS = (
    "—à–∫–æ–ª", "–æ–±—É—á–µ–Ω", "–∫—É—Ä—Å", "—É—Ä–æ–∫", "–∑–∞–Ω—è—Ç", "—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫", "–º–µ—Ç–æ–¥–∏–∫",
    "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç", "–∞–±–æ–Ω–µ–º–µ–Ω—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º", "—Ç—Ä–µ–Ω–µ—Ä", "–Ω–∞—Å—Ç–∞–≤–Ω–∏–∫",
    "–∞–±—Ä–∏–∫–æ–ª—å", "–±–∏—Å–∞", "—Å–∏—Å—Ç–µ–º–∞", "–≤–∏–¥—ã –æ–±—É—á", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ü–µ–Ω–∞",
    "–Ω–∞—á–∞–ª—å–Ω",  # "–Ω–∞—á–∞–ª—å–Ω—ã–π" –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —à–∫–æ–ª–µ (–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å), –∞ –Ω–µ –∫ –ø—Ä–∞–≤–∏–ª–∞–º
)

PRIMARY_SOURCE_TELEGRAM_LIMIT = 3500


def classify_topic(query: str) -> tuple[str, float]:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç –∑–∞–ø—Ä–æ—Å –ø–æ —Ç–µ–º–∞–º –æ–±—â–µ–Ω–∏—è.

    Args:
        query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

    Returns:
        tuple: (topic, confidence) –≥–¥–µ topic –º–æ–∂–µ—Ç –±—ã—Ç—å:
            - "school" (–¢–µ–º–∞ 1: –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —à–∫–æ–ª–µ)
            - "rules" (–¢–µ–º–∞ 2: –ü—Ä–∞–≤–∏–ª–∞ –∏ —Å–ø—Ä–∞–≤–∫–∞ –ø–æ –±–∏–ª—å—è—Ä–¥—É)
            - "unknown" (–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Ç–µ–º–∞)
        confidence: —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –æ—Ç 0.0 –¥–æ 1.0
    """
    if not query:
        return "unknown", 0.0

    query_lower = query.lower()

    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –ø–æ –∫–∞–∂–¥–æ–π —Ç–µ–º–µ
    school_matches = sum(1 for kw in SCHOOL_TOPIC_KEYWORDS if kw in query_lower)
    rules_matches = sum(1 for kw in RULE_INTENT_KEYWORDS if kw in query_lower)

    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–æ–≤–∞ –∏–∑ –¢–µ–º—ã 2, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤ –¢–µ–º–µ 1
    # –ù–∞–ø—Ä–∏–º–µ—Ä, "–∏–≥—Ä" –º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –≤ "–∏–≥—Ä–∞—Ç—å –Ω–∞ –±–∏–ª—å—è—Ä–¥–µ" –∏ –≤ "–ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã"
    # –ù–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–∞–≤–∏–ª - —ç—Ç–æ —Ç–æ—á–Ω–æ –¢–µ–º–∞ 2
    rules_specific = ["–ø—Ä–∞–≤–∏–ª", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫", "–∫–æ—Ä–æ–Ω–∞", "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥", "—Ñ–±—Å—Ä"]
    has_rules_specific = any(kw in query_lower for kw in rules_specific)

    # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Å–ª–æ–≤–∞ –ø—Ä–∞–≤–∏–ª - —ç—Ç–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ –¢–µ–º–∞ 2
    if has_rules_specific:
        return "rules", min(1.0, 0.5 + rules_matches * 0.1)

    # –ï—Å–ª–∏ –±–æ–ª—å—à–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ —à–∫–æ–ª–µ - –¢–µ–º–∞ 1
    if school_matches > rules_matches:
        return "school", min(1.0, 0.3 + school_matches * 0.15)

    # –ï—Å–ª–∏ –±–æ–ª—å—à–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º - –¢–µ–º–∞ 2
    if rules_matches > school_matches:
        return "rules", min(1.0, 0.3 + rules_matches * 0.15)

    # –ï—Å–ª–∏ —Ä–∞–≤–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–ª–∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π - –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–∞—è —Ç–µ–º–∞
    return "unknown", 0.0


def _unique_preserving(seq: Sequence[str]) -> list[str]:
    seen: set[str] = set()
    ordered: list[str] = []
    for item in seq:
        if item and item not in seen:
            seen.add(item)
            ordered.append(item)
    return ordered


def _normalize_source_name(source: str | None) -> str:
    if not source:
        return ""
    return re.sub(r"\s+", "", source.lower())


def _collect_fragments_by_source(
    fragments: list[dict],
    main_source: str | None,
    source_name: str,
) -> list[dict]:
    if not fragments or not source_name:
        return []
    try:
        normalized_target = _normalize_source_name(source_name)
        collected: list[dict] = []
        for fragment in fragments:
            if not isinstance(fragment, dict):
                continue
            fragment_source = fragment.get("source") or main_source
            if fragment_source and _normalize_source_name(fragment_source) == normalized_target:
                collected.append(fragment)
        return collected
    except Exception:
        return []


def _fragments_contain_keywords(
    fragments: list[dict],
    keywords: tuple[str, ...],
    exclude_keywords: tuple[str, ...] | None = None,
) -> bool:
    if not fragments or not keywords:
        return False
    try:
        excludes = exclude_keywords or ()
        for fragment in fragments:
            if not isinstance(fragment, dict):
                continue
            text = (fragment.get("text") or "").lower()
            if not text:
                continue
            if excludes and any(exclude in text for exclude in excludes):
                continue
            if any(keyword in text for keyword in keywords):
                return True
        return False
    except Exception:
        return False


def _is_rules_source(source: str | None) -> bool:
    normalized = _normalize_source_name(source)
    return any(normalized.startswith(pattern.replace(" ", "")) for pattern in RULE_SOURCE_PATTERNS)


def is_rule_intent(query: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –∫ –ø—Ä–∞–≤–∏–ª–∞–º –∏–≥—Ä—ã.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ª–æ–∂–Ω—ã—Ö —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏–π.
    """
    if not query or len(query.strip()) < 3:
        return False

    lowered = query.lower().strip()

    # –ò—Å–∫–ª—é—á–∞–µ–º –∑–∞–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –Ω–µ –ø—Ä–æ –ø—Ä–∞–≤–∏–ª–∞
    # (–≤–æ–ø—Ä–æ—Å—ã –æ –±–æ—Ç–µ, –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è, –æ–±—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã)
    excluded_patterns = [
        "—Ç—ã –∫—Ç–æ", "–∫—Ç–æ —Ç—ã", "—á—Ç–æ —Ç—ã", "—á—Ç–æ —Ç–∞–∫–æ–µ —Ç—ã",
        "–ø–æ–º–æ—â—å", "–ø–æ–º–æ–≥–∏", "—á—Ç–æ —É–º–µ–µ—à—å", "—á—Ç–æ –º–æ–∂–µ—à—å",
        "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π", "–¥–æ–±—Ä–æ–µ",
        "–∫–∞–∫ –¥–µ–ª–∞", "–∫–∞–∫ –ø–æ–∂–∏–≤–∞–µ—à—å",
    ]
    for pattern in excluded_patterns:
        if pattern in lowered:
            return False

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, –Ω–æ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω
    # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (–º–µ–Ω–µ–µ 10 —Å–∏–º–≤–æ–ª–æ–≤) —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    has_rule_keyword = any(word in lowered for word in RULE_INTENT_KEYWORDS)

    if len(lowered) < 10:
        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
        # –í–∫–ª—é—á–∞–µ–º "–∞–∫—Å–µ—Å" –∏ "–æ–±–æ—Ä—É–¥" –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        specific_keywords = ["–ø—Ä–∞–≤–∏–ª", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "—Ç–µ—Ö–Ω–∏—á–µ—Å–∫", "–∫–æ—Ä–æ–Ω–∞", "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥", "–ø–∏—Ä–∞–º–∏–¥–∞", "—Ñ–±—Å—Ä", "–∞–∫—Å–µ—Å", "–æ–±–æ—Ä—É–¥"]
        has_specific = any(kw in lowered for kw in specific_keywords)
        return has_specific and has_rule_keyword

    return has_rule_keyword


def _load_download_links() -> dict[str, str]:
    links: dict[str, str] = {}
    if not os.path.exists(LINKS_FILE_PATH):
        return links
    try:
        with open(LINKS_FILE_PATH, "r", encoding="utf-8") as file:
            for line in file:
                line = line.strip()
                if not line or " - " not in line:
                    continue
                left, url = line.split(" - ", 1)
                left = re.sub(r"^\d+\.\s*", "", left.strip())
                url = url.strip()
                if left and url:
                    links[left] = url
    except OSError:
        return {}
    return links


def _get_download_info_for_source(source: str | None) -> dict[str, str] | None:
    if not source:
        return None
    label = PRIMARY_SOURCE_LABELS.get(source)
    if not label:
        return None
    url = _load_download_links().get(label)
    if not url:
        return None
    return {"label": label, "url": url}


def remove_hash_and_trash(text: str) -> str:
    if not text:
        return ""
    cleaned = re.sub(r"#+", "", text)
    cleaned = re.sub(r"[\s‚Ä¢‚Üí\*]+$", "", cleaned)
    cleaned = re.sub(r"^—Ä–∏—Å\.\s*", "", cleaned, flags=re.IGNORECASE)
    # –ù–ï —É–¥–∞–ª—è–µ–º —Ü–∏—Ñ—Ä—ã –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å "–†–ê–ó–î–ï–õ 5." –∏–ª–∏ "–†–ê–ó–î–ï–õ 1."
    if not re.match(r'–†–ê–ó–î–ï–õ\s+\d+\.', cleaned, re.IGNORECASE):
        cleaned = re.sub(r"^[\d. ]+", "", cleaned)
    return cleaned.strip()


def _truncate_primary_source_text(text: str) -> str:
    if len(text) <= PRIMARY_SOURCE_TELEGRAM_LIMIT:
        return text
    # –û–±—Ä–µ–∑–∞–µ–º –ø–æ –≥—Ä–∞–Ω–∏—Ü–∞–º —Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ –æ–±—Ä–µ–∑–∞—Ç—å –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ
    max_length = PRIMARY_SOURCE_TELEGRAM_LIMIT - 70
    if len(text) <= max_length:
        return text

    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –ø–µ—Ä–µ–¥ –ª–∏–º–∏—Ç–æ–º
    trimmed = text[:max_length]
    last_newline = trimmed.rfind('\n')
    if last_newline > max_length * 0.8:  # –ï—Å–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–∞–ª–µ–∫–æ –æ—Ç –∫–æ–Ω—Ü–∞
        trimmed = text[:last_newline].rstrip()
    else:
        # –ï—Å–ª–∏ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏ –Ω–µ—Ç –±–ª–∏–∑–∫–æ, –æ–±—Ä–µ–∑–∞–µ–º –ø–æ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –ø—Ä–æ–±–µ–ª—É
        last_space = trimmed.rfind(' ')
        if last_space > max_length * 0.8:
            trimmed = text[:last_space].rstrip()
        else:
            trimmed = trimmed.rstrip()

    return f"{trimmed}\n‚Ä¶ (—Ñ—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–∫—Ä–∞—â—ë–Ω, –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç Telegram)"


_BOLD_LINE_PATTERN = re.compile(r"^\s*\*\*(.+?)\*\*\s*$", re.MULTILINE)
CTA_KEYWORDS = (
    "–∑–∞–ø–∏—Å",
    "–æ—Å—Ç–∞–≤–∏—Ç –∑–∞—è–≤–∫—É",
    "–æ—Å—Ç–∞–≤—å –∑–∞—è–≤–∫—É",
    "—Å–≤—è–∂",
    "–Ω–∞–ø–∏—à",
    "–Ω–∞–ø–∏—Å",
    "–ø–æ–∑–≤–æ–Ω",
    "—Ö–æ—Ç–∏—Ç–µ",
    "—É–∑–Ω–∞",
    "–∂–µ–ª–∞",
    "–ø–æ–º–æ–≥—É",
    "–ø–æ–º–æ—á—å",
    "—Å–∫–∞–∂",
    "—Å–∫–∞–∑",
    "—Ç–µ–ª–µ—Ñ",
    "–≥–æ—Ç–æ–≤",
    "–º–æ–≥—É",
)

BRACKETED_COUNT_FIGURE_PATTERN = re.compile(
    r"\[\s*\d+\s+(?:—É–ø—Ä–∞–∂–Ω–µ–Ω\w*|–∑–∞–¥–∞—á\w*)\s*\]",
    re.IGNORECASE,
)

COUNT_FIGURE_PATTERN = re.compile(
    r"\b\d+\s+(?:—É–ø—Ä–∞–∂–Ω–µ–Ω\w*|–∑–∞–¥–∞—á\w*)\b",
    re.IGNORECASE,
)

GENERIC_SECTION_MARKERS = {"—Ä–∞–∑–¥–µ–ª"}


def _normalize_primary_body(text: str) -> str:
    if not text:
        return text

    lines = text.splitlines()
    paragraphs: list[str] = []
    current: list[str] = []
    enum_pattern = re.compile(r"^(?:\(?\d+[\).]|[-‚Ä¢])\s")

    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()
        if not stripped:
            if current:
                paragraphs.append(" ".join(current))
                current = []
            i += 1
            continue

        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –ø–∞—Ç—Ç–µ—Ä–Ω–∞ —Å–ø–∏—Å–∫–∞, –≤—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
        # –ò –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∏—Ç–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏ –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–∏
        if enum_pattern.match(stripped) or stripped.lower().startswith("–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ"):
            if current:
                paragraphs.append(" ".join(current))
                current = []

            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞ –≤ –æ–¥–∏–Ω –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            list_item_lines = [stripped]
            i += 1
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —á–∏—Ç–∞—Ç—å —Å–ª–µ–¥—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏, –ø–æ–∫–∞ –Ω–µ –≤—Å—Ç—Ä–µ—Ç–∏–º –Ω–æ–≤—ã–π –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
            while i < len(lines):
                next_line = lines[i].strip()
                if not next_line:
                    # –ü—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ - –∫–æ–Ω–µ—Ü –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞
                    break
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ - –Ω–æ–≤—ã–π –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
                if enum_pattern.match(next_line) or next_line.lower().startswith("–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ"):
                    break
                # –ò–Ω–∞—á–µ —ç—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞
                list_item_lines.append(next_line)
                i += 1

            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞ –≤ –æ–¥–∏–Ω –ø–∞—Ä–∞–≥—Ä–∞—Ñ
            paragraphs.append(" ".join(list_item_lines))
            continue

        current.append(stripped)
        i += 1

    if current:
        paragraphs.append(" ".join(current))

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã: –ø—É–Ω–∫—Ç—ã —Å–ø–∏—Å–∫–∞ —Ä–∞–∑–¥–µ–ª—è–µ–º –æ–¥–Ω–∏–º –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Å—Ç—Ä–æ–∫–∏
    # –æ–±—ã—á–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã - –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–æ–º —Å—Ç—Ä–æ–∫–∏
    cleaned_parts = []
    for i, para in enumerate(paragraphs):
        if i > 0:
            prev_enum = bool(enum_pattern.match(paragraphs[i-1]) or paragraphs[i-1].lower().startswith("–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ"))
            curr_enum = bool(enum_pattern.match(para) or para.lower().startswith("–ø—Ä–∏–º–µ—á–∞–Ω–∏–µ"))
            # –ï—Å–ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∏–ª–∏ —Ç–µ–∫—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ - –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ–¥–∏–Ω –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏
            if prev_enum or curr_enum:
                cleaned_parts.append("\n")
            else:
                cleaned_parts.append("\n\n")
        cleaned_parts.append(para)

    cleaned = "".join(cleaned_parts)
    # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    # –í–∞–∂–Ω–æ: –Ω–µ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –ø–µ—Ä–µ–Ω–æ—Å–∞—Ö —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–Ω—É—Ç—Ä–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –ø—Ä–æ–±–µ–ª–æ–º, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã –º–µ–∂–¥—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏
    cleaned = re.sub(r"[ \t]+", " ", cleaned)  # –¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–∞–±—ã, –Ω–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
    cleaned = re.sub(r"\n{3,}", "\n\n", cleaned)  # –ú–∞–∫—Å–∏–º—É–º 2 –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç—Ä–æ–∫–∏ –ø–æ–¥—Ä—è–¥

    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ —Ç–µ–∫—Å—Ç –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–ª—É—Å–ª–æ–≤–µ –∏–∑-–∑–∞ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–±–∏–µ–Ω–∏—è
    # –ü—Ä–æ–±–ª–µ–º–∞: –∫–æ—Ä–æ—Ç–∫–∏–µ —Å—Ç—Ä–æ–∫–∏ (1-3 –±—É–∫–≤—ã) –º–æ–≥—É—Ç –±—ã—Ç—å —Ä–∞–∑–æ—Ä–≤–∞–Ω–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Ö —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π –∏–ª–∏ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–æ–π
    lines = cleaned.split('\n')
    fixed_lines = []
    i = 0

    while i < len(lines):
        line = lines[i]
        stripped = line.strip()

        if not stripped:
            fixed_lines.append(line)
            i += 1
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –ø—É–Ω–∫—Ç–æ–º —Å–ø–∏—Å–∫–∞
        is_list_item = enum_pattern.match(stripped)

        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –∫–æ—Ä–æ—Ç–∫–∞—è (1-3 –±—É–∫–≤—ã) –∏ –Ω–µ –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞
        if not is_list_item and len(stripped) <= 3:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Å—Ç—Ä–æ–∫—É - –µ—Å–ª–∏ –æ–Ω–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º —Å–ª–æ–≤–æ–º
            # –∏ –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π (—Ç–æ—á–∫–∞, –¥–≤–æ–µ—Ç–æ—á–∏–µ, —Ç–æ—á–∫–∞ —Å –∑–∞–ø—è—Ç–æ–π), –æ–±—ä–µ–¥–∏–Ω—è–µ–º
            if fixed_lines:
                prev_line = fixed_lines[-1].strip()
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ª–∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è —Å—Ç—Ä–æ–∫–∞ –∫–æ—Ä–æ—Ç–∫–∏–º —Å–ª–æ–≤–æ–º (1-3 –±—É–∫–≤—ã)
                # –∏ –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ª–∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π
                if prev_line and not prev_line.endswith(('.', ':', ';', '-', '‚Äî')):
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–µ
                    words = prev_line.split()
                    if words:
                        last_word = words[-1].rstrip('.,;:!?')
                        if len(last_word) <= 3 and last_word.isalpha():
                            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–æ–π
                            fixed_lines[-1] = fixed_lines[-1].rstrip() + ' ' + stripped
                            i += 1
                            continue

            # –ï—Å–ª–∏ –Ω–µ –æ–±—ä–µ–¥–∏–Ω–∏–ª–∏ —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É
            if i + 1 < len(lines):
                next_stripped = lines[i + 1].strip()
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è –∏ –Ω–µ –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞
                if next_stripped and not enum_pattern.match(next_stripped):
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏
                    fixed_lines.append(stripped + ' ' + next_stripped)
                    i += 2
                    continue

        fixed_lines.append(line)
        i += 1

    cleaned = '\n'.join(fixed_lines)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—Ç—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Å–ª–æ–≤–∞–º–∏
    # –∏ –ø—Ä–æ–¥–æ–ª–∂–∞—é—Ç—Å—è –Ω–∞ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ
    lines = cleaned.split('\n')
    final_lines = []
    i = 0
    while i < len(lines):
        line = lines[i]
        stripped = line.strip()

        if not stripped:
            final_lines.append(line)
            i += 1
            continue

        is_list_item = enum_pattern.match(stripped)

        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –∫–æ—Ä–æ—Ç–∫–∏–º —Å–ª–æ–≤–æ–º (1-3 –±—É–∫–≤—ã), –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é
        # –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç—å –ø—É–Ω–∫—Ç–∞ —Å–ø–∏—Å–∫–∞ –∏–ª–∏ –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if i + 1 < len(lines):
            words = stripped.split()
            if words:
                last_word = words[-1].rstrip('.,;:!?')
                # –ï—Å–ª–∏ –ø–æ—Å–ª–µ–¥–Ω–µ–µ —Å–ª–æ–≤–æ –∫–æ—Ä–æ—Ç–∫–æ–µ (1-3 –±—É–∫–≤—ã) –∏ —Å—Ç—Ä–æ–∫–∞ –Ω–µ –∑–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π
                if len(last_word) <= 3 and last_word.isalpha() and not stripped.rstrip().endswith(('.', ':', ';')):
                    next_stripped = lines[i + 1].strip()
                    # –û–±—ä–µ–¥–∏–Ω—è–µ–º, –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–µ –ø—É—Å—Ç–∞—è –∏ –Ω–µ –Ω–æ–≤—ã–π –ø—É–Ω–∫—Ç —Å–ø–∏—Å–∫–∞
                    # (–Ω–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º —Ç–µ–∫—É—â–µ–≥–æ –ø—É–Ω–∫—Ç–∞)
                    if next_stripped and not enum_pattern.match(next_stripped):
                        # –ù–µ –æ–±—ä–µ–¥–∏–Ω—è–µ–º, –µ—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –ø–æ—Å–ª–µ –¥–≤–æ–µ—Ç–æ—á–∏—è
                        # (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ)
                        if not (is_list_item and next_stripped[0].isupper() and ':' in stripped):
                            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏
                            final_lines.append(stripped.rstrip() + ' ' + next_stripped)
                            i += 2
                            continue

        final_lines.append(line)
        i += 1

    cleaned = '\n'.join(final_lines)
    return cleaned.strip()


def _is_generic_section_marker(text: str) -> bool:
    if not text:
        return False
    normalized = re.sub(r"[#:\s]+", "", text.lower())
    return normalized in GENERIC_SECTION_MARKERS


def _truncate_to_single_point(text: str, header_line: str | None = None, rule_number: str | None = None) -> str:
    """
    –û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞/–ø–æ–¥–ø—É–Ω–∫—Ç–∞, —á—Ç–æ–±—ã –≤ –æ–∫–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—É–Ω–∫—Ç.
    –≠—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–±—â–∏–º –ø—Ä–∞–≤–∏–ª–∞–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–∫–æ–Ω.
    """
    if not text:
        return text

    lines = text.split('\n')
    if not lines:
        return text

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–æ–º–µ—Ä –ø–µ—Ä–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞ –∏–∑ header_line –∏–ª–∏ rule_number
    first_point_number = None
    if header_line:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ header_line (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1. –ù–∞–∑–≤–∞–Ω–∏–µ" -> "1")
        match = re.match(r'^(\d+(?:\.\d+)*)', header_line.strip())
        if match:
            first_point_number = match.group(1)
    elif rule_number:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º rule_number
        first_point_number = rule_number.strip().rstrip('.')

    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–æ–º–µ—Ä –∏–∑ header_line/rule_number, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –≤ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ —Ç–µ–∫—Å—Ç–∞
    if not first_point_number:
        first_line = lines[0].strip() if lines else ""
        match = re.match(r'^(\d+(?:\.\d+)*)', first_line)
        if match:
            first_point_number = match.group(1)

    if not first_point_number:
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –Ω–æ–º–µ—Ä, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç
        return text

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ø–µ—Ä–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –≤ –Ω–æ–º–µ—Ä–µ)
    first_level = first_point_number.count('.') + 1

    # –ò—â–µ–º —Å–ª–µ–¥—É—é—â–∏–π –ø—É–Ω–∫—Ç —Ç–æ–≥–æ –∂–µ –∏–ª–∏ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è
    result_lines = [lines[0]]  # –í—Å–µ–≥–¥–∞ –≤–∫–ª—é—á–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É

    for i in range(1, len(lines)):
        line = lines[i].strip()
        if not line:
            # –ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤–∫–ª—é—á–∞–µ–º, –Ω–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é —Å—Ç—Ä–æ–∫—É
            result_lines.append(lines[i])
            continue

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∞–ª–æ–º –Ω–æ–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞/–ø–æ–¥–ø—É–Ω–∫—Ç–∞
        # –ü–∞—Ç—Ç–µ—Ä–Ω: –Ω–æ–º–µ—Ä –ø—É–Ω–∫—Ç–∞ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "1.", "1.1.", "2.", "2.1." –∏ —Ç.–¥.)
        point_match = re.match(r'^(\d+(?:\.\d+)*)(?:\.)?\s+', line)
        if point_match:
            current_point_number = point_match.group(1)
            current_level = current_point_number.count('.') + 1

            # –ï—Å–ª–∏ —ç—Ç–æ –ø—É–Ω–∫—Ç —Ç–æ–≥–æ –∂–µ –∏–ª–∏ –±–æ–ª–µ–µ –≤—ã—Å–æ–∫–æ–≥–æ —É—Ä–æ–≤–Ω—è - –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è
            if current_level <= first_level:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –¥—Ä—É–≥–æ–π –ø—É–Ω–∫—Ç (–Ω–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ)
                if current_point_number != first_point_number:
                    break

        # –í–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫—É –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result_lines.append(lines[i])

    return '\n'.join(result_lines)


def _remove_generic_section_lines(text: str) -> str:
    if not text:
        return text
    lines = []
    for line in text.splitlines():
        if _is_generic_section_marker(line):
            continue
        lines.append(line)
    return "\n".join(lines).strip()


def _is_emoji_only(text: str) -> bool:
    meaningful = [ch for ch in text if unicodedata.category(ch) not in {"Mn", "Me", "Cf", "Cc"}]
    if not meaningful:
        return False
    if len(meaningful) > 4:
        return False
    if any(ch.isalnum() for ch in meaningful):
        return False
    return all(unicodedata.category(ch).startswith("S") for ch in meaningful)


def _remove_lonely_emojis(text: str) -> str:
    if not text:
        return text
    lines = text.splitlines()
    cleaned: list[str] = []
    for line in lines:
        stripped = line.strip()
        if stripped and _is_emoji_only(stripped):
            continue
        cleaned.append(line)
    return "\n".join(cleaned)


def _normalize_cta_block(text: str) -> str:
    if not text:
        return text
    lines = text.splitlines()
    cta_index: int | None = None
    for i in range(len(lines) - 1, -1, -1):
        stripped = lines[i].strip()
        if not stripped:
            continue
        lower = stripped.lower()
        has_cta_keyword = any(keyword in lower for keyword in CTA_KEYWORDS)
        is_question = stripped.endswith("?")
        if has_cta_keyword or is_question:
            cta_index = i
            break
    if cta_index is None:
        return text
    stripped_cta = lines[cta_index].lstrip()
    if stripped_cta.startswith("üéØ"):
        content = stripped_cta[1:].lstrip()
    else:
        content = stripped_cta
    stripped_content = content.lstrip("".join(ch for ch in content if _is_emoji_only(ch)))
    lines[cta_index] = f"üéØ {stripped_content.strip()}"
    return "\n".join(lines)


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ –±–ª–æ–∫–æ–º CTA/–≤–æ–ø—Ä–æ—Å–æ–≤
def _ensure_cta_spacing(text: str) -> str:
    if not text:
        return text

    lines = text.splitlines()
    cta_index: int | None = None

    # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É —Å –°–¢–ê (–∏—â–µ–º —Å –∫–æ–Ω—Ü–∞)
    for i in range(len(lines) - 1, -1, -1):
        stripped = lines[i].strip()
        if not stripped:
            continue
        lower = stripped.lower()
        has_cta_keyword = any(keyword in lower for keyword in CTA_KEYWORDS)
        is_question = stripped.endswith("?")
        if has_cta_keyword or is_question:
            cta_index = i
            break

    if cta_index is None or cta_index == 0:
        return text

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –ø–µ—Ä–µ–¥ –°–¢–ê –µ—Å—Ç—å –æ–¥–Ω–∞ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    if lines[cta_index - 1].strip():
        lines.insert(cta_index, "")
        cta_index += 1

    # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–æ–¥–∑–∏ –∫ –°–¢–ê, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ—Ç
    current = lines[cta_index].lstrip()
    if current and not current.startswith("üéØ"):
        lines[cta_index] = f"üéØ {current}"
    elif not current:
        lines[cta_index] = "üéØ"

    # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω–µ—Ü –°–¢–ê –±–ª–æ–∫–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫)
    cta_end = cta_index
    while cta_end < len(lines) - 1:
        next_line = lines[cta_end + 1].strip()
        if not next_line:
            cta_end += 1
        elif any(keyword in next_line.lower() for keyword in CTA_KEYWORDS) or next_line.endswith("?"):
            cta_end += 1
        else:
            break

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –°–¢–ê –±–ª–æ–∫–∞
    # –ù–∞—Ö–æ–¥–∏–º –ø–µ—Ä–≤—É—é –Ω–µ–ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–æ—Å–ª–µ –°–¢–ê –±–ª–æ–∫–∞
    first_non_empty_after_cta = None
    for i in range(cta_end + 1, len(lines)):
        if lines[i].strip():
            first_non_empty_after_cta = i
            break

    if first_non_empty_after_cta is not None:
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –º–µ–∂–¥—É –°–¢–ê –∏ –æ—Å–Ω–æ–≤–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º
        empty_lines_count = first_non_empty_after_cta - cta_end - 1

        # –ï—Å–ª–∏ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –±–æ–ª—å—à–µ –æ–¥–Ω–æ–π, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É
        if empty_lines_count > 1:
            # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω—É
            lines_to_remove = empty_lines_count - 1
            for _ in range(lines_to_remove):
                lines.pop(cta_end + 1)
        # –ï—Å–ª–∏ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫ –Ω–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –æ–¥–Ω—É
        elif empty_lines_count == 0:
            lines.insert(cta_end + 1, "")

    return "\n".join(lines)


def _bold_to_arrow(text: str) -> str:
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫–∏ –≤–∏–¥–∞ **–ö—É—Ä—Å—ã:** –≤ –º–∞—Ä–∫–µ—Ä-—Å—Ç—Ä–µ–ª–∫—É."""
    if not text or not isinstance(text, str):
        return text if isinstance(text, str) else ""

    def _replace(match: re.Match[str]) -> str:
        content = match.group(1).strip()
        if not content:
            return ""
        return f"‚Üí {content}"

    return _BOLD_LINE_PATTERN.sub(_replace, text)


def _split_into_sentences(text: str) -> list[str]:
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:
    
    –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ:
    - –ù–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã (–∏–ª–∏ —Ü–∏—Ñ—Ä—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤)
    - –ó–∞–∫–∞–Ω—á–∏–≤–∞–µ—Ç—Å—è –Ω–∞ ".", "?", "!" –∏–ª–∏ "..."
    - –ü–æ—Å–ª–µ –∫–æ–Ω–µ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
    
    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–±–µ–∑ –ø—É—Å—Ç—ã—Ö)
    """
    if not text:
        return []
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç: –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ –ø—Ä–æ–±–µ–ª—å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –Ω–∞ –æ–¥–∏–Ω –ø—Ä–æ–±–µ–ª
    # –¢–∞–∫–∂–µ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ: –∑–∞–º–µ–Ω—è–µ–º —Å–∏–º–≤–æ–ª –º–Ω–æ–≥–æ—Ç–æ—á–∏—è (‚Ä¶) –Ω–∞ —Ç—Ä–∏ —Ç–æ—á–∫–∏
    normalized_text = re.sub(r'‚Ä¶', '...', text.strip())
    normalized_text = re.sub(r'\s+', ' ', normalized_text)
    if not normalized_text:
        return []
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (–≤–∫–ª—é—á–∞—è "...") —Å –ø—Ä–æ–±–µ–ª–æ–º –∏–ª–∏ –∫–æ–Ω—Ü–æ–º —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ –Ω–∏—Ö
    # –ü–∞—Ç—Ç–µ—Ä–Ω: –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º lookahead –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–±–µ–ª–∞ –∏–ª–∏ –∫–æ–Ω—Ü–∞ —Å—Ç—Ä–æ–∫–∏
    parts = re.split(r'(\.\.\.|[.!?])(?=\s+|$)', normalized_text)
    
    sentences = []
    current_sentence = ''
    
    i = 0
    while i < len(parts):
        part = parts[i]
        if not part:
            i += 1
            continue
        
        # –ï—Å–ª–∏ —ç—Ç–æ –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (–º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–π –∑–Ω–∞–∫)
        if part in ['.', '!', '?', '...']:
            current_sentence += part
            # –ó–∞–≤–µ—Ä—à–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ (–∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –æ–∑–Ω–∞—á–∞–µ—Ç –∫–æ–Ω–µ—Ü –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
            if current_sentence.strip():
                sentences.append(current_sentence.strip())
                current_sentence = ''
            i += 1
        else:
            # –≠—Ç–æ —Ç–µ–∫—Å—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (–º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ)
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –ø–µ—Ä–≤–∞—è —á–∞—Å—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            if current_sentence:
                part = part.lstrip()  # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ, –µ—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
            current_sentence += part
            i += 1
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å (–±–µ–∑ –∑–Ω–∞–∫–∞ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –≤ –∫–æ–Ω—Ü–µ)
    if current_sentence.strip():
        sentences.append(current_sentence.strip())
    
    # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –¥–æ–ª–∂–Ω—ã –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã
    filtered_sentences = []
    for sentence in sentences:
        stripped = sentence.strip()
        if not stripped:
            continue
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã
        first_char = stripped.lstrip()[0] if stripped.lstrip() else ''
        if first_char and (first_char.isupper() or first_char.isdigit()):
            filtered_sentences.append(stripped)
    
    return filtered_sentences


def _move_cta_to_end(text: str) -> str:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–æ–Ω–µ—Ü —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ CTA –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –±–ª–æ–∫ CTA.
    
    –í–ê–ñ–ù–û: 
    1. –ò—â–µ—Ç—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç –≤ –∫–æ–Ω—Ü–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç –∫—Ä–∏—Ç–µ—Ä–∏—è–º CTA
    2. –§–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è –∏–∑ –Ω–µ–≥–æ CTA –±–ª–æ–∫ —Å–æ –∑–Ω–∞–∫–æ–º üéØ, —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, —Å –æ–¥–Ω–æ–π –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–æ–π —Å–≤–µ—Ä—Ö—É
    3. –í CTA –≤—Ö–æ–¥–∏—Ç –õ–Æ–ë–û–ô —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Ü–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è, –æ—Ç–≤–µ—á–∞—é—â–∏–π –∫—Ä–∏—Ç–µ—Ä–∏—è–º CTA
    
    –ö—Ä–∏—Ç–µ—Ä–∏–∏ CTA:
    - –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ (–∑–Ω–∞–∫ "?") –ò–õ–ò –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏ CTA
    """
    if not text:
        return text

    # –í–ê–ñ–ù–û: –¢–µ–∫—Å—Ç –º–æ–∂–µ—Ç –ø—Ä–∏–π—Ç–∏ —É–∂–µ —Å –ø–µ—Ä–µ–Ω–æ—Å–∞–º–∏ —Å—Ç—Ä–æ–∫ (–ø–æ—Å–ª–µ _format_llm_response_layout)
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é _split_into_sentences –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    sentences = _split_into_sentences(text)
    if not sentences:
        return text
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–æ–∏—Å–∫ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
    # –ò—â–µ–º –°–í–ï–†–•–£ –í–ù–ò–ó (—Å –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π) –ø–µ—Ä–≤–æ–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
    search_limit = min(5, len(sentences))  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    last_5_start = len(sentences) - search_limit  # –ù–∞—á–∞–ª–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    
    cta_start_index = None
    cta_start_index_by_keyword = None
    
    # –ò–¥–µ–º –°–í–ï–†–•–£ –í–ù–ò–ó –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (—Å –Ω–∞—á–∞–ª–∞ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –∫ –∫–æ–Ω—Ü—É)
    # –°–Ω–∞—á–∞–ª–∞ –∏—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –≤–æ–ø—Ä–æ—Å–∞–º–∏ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    for i in range(last_5_start, len(sentences)):
        sentence = sentences[i]
        stripped = sentence.strip()
        if not stripped:
            continue
        
        is_question = "?" in stripped or stripped.endswith("?")
        if is_question:
            # –ù–∞—à–ª–∏ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –≤–æ–ø—Ä–æ—Å–æ–º - —ç—Ç–æ –Ω–∞—á–∞–ª–æ CTA –±–ª–æ–∫–∞
            cta_start_index = i
            break
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –≤–æ–ø—Ä–æ—Å–æ–º, –∏—â–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
    if cta_start_index is None:
        for i in range(last_5_start, len(sentences)):
            sentence = sentences[i]
            stripped = sentence.strip()
            if not stripped:
                continue
            
        lower = stripped.lower()
        has_cta_keyword = any(keyword in lower for keyword in CTA_KEYWORDS)
            if has_cta_keyword:
                # –ù–∞—à–ª–∏ –ø–µ—Ä–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º - —ç—Ç–æ –Ω–∞—á–∞–ª–æ CTA –±–ª–æ–∫–∞
                cta_start_index = i
                break
    
    # –ï—Å–ª–∏ CTA –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
    if cta_start_index is None:
        return text

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –∏ CTA –±–ª–æ–∫
    # –í CTA –∏–¥—É—Ç –í–°–ï –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞—á–∏–Ω–∞—è —Å –ø–µ—Ä–≤–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ –∫–æ–Ω—Ü–∞
    # (–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ –≤ –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö)
    other_sentences = sentences[:cta_start_index]
    cta_sentences = sentences[cta_start_index:]
    
    # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç –∏ CTA –±–ª–æ–∫
    main_part = " ".join(other_sentences).strip()
    cta_part = " ".join(cta_sentences).strip()

    if main_part and cta_part:
        return f"{main_part}\n\n{cta_part}"
    if cta_part:
        return cta_part
    return main_part


def _normalize_arrows(text: str) -> str:
    """–ó–∞–º–µ–Ω—è–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Å—Ç—Ä–µ–ª–∫–∏ ‚Üí –Ω–∞ –µ–¥–∏–Ω—ã–π –º–∞—Ä–∫–µ—Ä üëâ."""
    if not text:
        return text

    def _replace_line(line: str) -> str:
        stripped = line.lstrip()
        if stripped.startswith("-") or stripped.startswith("‚Ä¢"):
            return line
        replaced = re.sub(r"(‚Üí\s*){1,}", "üëâ ", line)
        replaced = re.sub(r"^(\s*)(üëâ\s*){1,}", r"\1üëâ ", replaced)
        return replaced

    return "\n".join(_replace_line(line) for line in text.split("\n"))


def _strip_unwanted_symbols(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è."""
    if not text:
        return text
    text = text.replace("**", "")
    text = text.replace("‚Üí", "")
    text = text.replace("#", "")
    text = re.sub(r"[ \t]{2,}", " ", text)
    text = re.sub(r"\n{3,}", "\n\n", text)
    return text.strip()


def _validate_anketa_answer(answer: str, question_num: int) -> tuple[bool, str]:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –∞–Ω–∫–µ—Ç—ã –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM.

    Args:
        answer: –û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        question_num: –ù–æ–º–µ—Ä –≤–æ–ø—Ä–æ—Å–∞ (1-4)

    Returns:
        tuple[bool, str]: (is_valid, reason)
        - is_valid: True –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, False –µ—Å–ª–∏ –Ω–µ—Ç
        - reason: –ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è (–µ—Å–ª–∏ is_valid=False) –∏–ª–∏ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
    """
    if not answer:
        return False, "–û—Ç–≤–µ—Ç –ø—É—Å—Ç–æ–π"

    answer_lower = answer.lower().strip()
    answer_length = len(answer_lower)

    # –î–ª—è –≤–æ–ø—Ä–æ—Å–∞ 4 (–î–∞/–ù–µ—Ç) —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –æ—Ç–≤–µ—Ç—ã "–¥–∞"/"–Ω–µ—Ç"
    if question_num == 4:
        yes_words = ["–¥–∞", "yes"]
        no_words = ["–Ω–µ—Ç", "no"]
        if answer_lower in yes_words or answer_lower in no_words:
            # –î–ª—è —è–≤–Ω—ã—Ö "–¥–∞"/"–Ω–µ—Ç" –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
            pass
        elif answer_length < 3:
            return False, "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"
    else:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç (–º–µ–Ω—å—à–µ 3 —Å–∏–º–≤–æ–ª–æ–≤) –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
        if answer_length < 3:
            return False, "–°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏—è –∏–ª–∏ –æ—Ç–∫–∞–∑–∞ –æ—Ç–≤–µ—á–∞—Ç—å
    skip_phrases = [
        "–Ω–µ –∑–Ω–∞—é", "–Ω–µ –ø–æ–Ω–∏–º–∞—é", "–Ω–µ –ø–æ–Ω—è–ª", "–Ω–µ –ø–æ–Ω—è–ª–∞",
        "–Ω–µ –∑–Ω–∞—é —á—Ç–æ", "–Ω–µ –∑–Ω–∞—é –∫–∞–∫", "–Ω–µ –º–æ–≥—É", "–Ω–µ —Ö–æ—á—É",
        "–∑–∞—Ç—Ä—É–¥–Ω—è—é—Å—å", "–Ω–µ —É–≤–µ—Ä–µ–Ω", "–Ω–µ —É–≤–µ—Ä–µ–Ω–∞",
        "?", "??", "???",  # –¢–æ–ª—å–∫–æ –∑–Ω–∞–∫–∏ –≤–æ–ø—Ä–æ—Å–∞
        "—á—Ç–æ", "–∫–∞–∫", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º",  # –í–æ–ø—Ä–æ—Å—ã –≤–º–µ—Å—Ç–æ –æ—Ç–≤–µ—Ç–æ–≤
    ]

    # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∑–Ω–∞–∫–æ–≤ –≤–æ–ø—Ä–æ—Å–∞ –∏–ª–∏ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤–æ–ø—Ä–æ—Å–∞
    if answer_lower.strip() in ["?", "??", "???"] or answer_lower.startswith("?"):
        return False, "–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –≤–æ–ø—Ä–æ—Å"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫—É –∑–∞–¥–∞—Ç—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å –≤–º–µ—Å—Ç–æ –æ—Ç–≤–µ—Ç–∞
    question_words = ["—á—Ç–æ", "–∫–∞–∫", "–ø–æ—á–µ–º—É", "–∑–∞—á–µ–º", "–∫–æ–≥–¥–∞", "–≥–¥–µ", "–∫—Ç–æ"]
    if any(answer_lower.startswith(word + " ") for word in question_words):
        return False, "–û—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –≤–æ–ø—Ä–æ—Å–∞"

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —è–≤–Ω—ã–µ —Ñ—Ä–∞–∑—ã –ø—Ä–æ–ø—É—Å–∫–∞
    if any(phrase in answer_lower for phrase in skip_phrases):
        # –ù–æ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ, —Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ—Ä–º–∞–ª—å–Ω–æ
        if answer_length < 20:  # –ï—Å–ª–∏ –∫–æ—Ä–æ—Ç–∫–∏–π –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç skip_phrase - –æ—Ç–∫–ª–æ–Ω—è–µ–º
            return False, "–û—Ç–≤–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ñ—Ä–∞–∑—É –Ω–µ–ø–æ–Ω–∏–º–∞–Ω–∏—è"

    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞
    if question_num == 1:  # –û–ø—ã—Ç –∏–≥—Ä—ã
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –æ–ø—ã—Ç–æ–º
        experience_keywords = [
            "–∏–≥—Ä–∞—é", "–∏–≥—Ä–∞–ª", "–∏–≥—Ä–∞–ª–∞", "–∏–≥—Ä–∞", "–æ–ø—ã—Ç", "–ª–µ—Ç", "–≥–æ–¥", "–≥–æ–¥–∞",
            "–º–µ—Å—è—Ü", "–º–µ—Å—è—Ü–µ–≤", "—Ä–∞–∑", "—Ä–∞–∑–∞", "—Ä–∞–∑–æ–≤", "–∏–≥—Ä–∞—Ç—å", "–∏–≥—Ä–∞–ª", "–∏–≥—Ä–∞–ª–∞",
            "–Ω–æ–≤–∏—á–æ–∫", "–Ω–∞—á–∏–Ω–∞—é—â", "—É–º–µ—é", "—É–º–µ—é –∏–≥—Ä–∞—Ç—å", "–Ω–µ —É–º–µ—é", "–Ω–µ –∏–≥—Ä–∞–ª",
            "–±–∏–ª—å—è—Ä–¥", "–ø–∏—Ä–∞–º–∏–¥–∞", "—Å—Ç–æ–ª", "—à–∞—Ä—ã", "–∫–∏–π"
        ]
        if not any(keyword in answer_lower for keyword in experience_keywords):
            # –ï—Å–ª–∏ –Ω–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤, –Ω–æ –æ—Ç–≤–µ—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–π - –ø—Ä–∏–Ω–∏–º–∞–µ–º
            if answer_length < 10:
                return False, "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –æ–ø—ã—Ç–µ"

    elif question_num == 2:  # –£—Ä–æ–≤–µ–Ω—å –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏
        level_keywords = [
            "—É—Ä–æ–≤–µ–Ω—å", "–Ω–æ–≤–∏—á–æ–∫", "–Ω–∞—á–∏–Ω–∞—é—â", "—Å—Ä–µ–¥–Ω", "–ø—Ä–æ–¥–≤–∏–Ω—É—Ç", "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª",
            "–ª—é–±–∏—Ç–µ–ª—å", "–Ω–∞—á–∞–ª—å–Ω", "–±–∞–∑–æ–≤", "–≤—ã—Å–æ–∫", "–Ω–∏–∑–∫", "—Å–ª–∞–±", "—Å–∏–ª—å–Ω",
            "–æ–ø—ã—Ç–Ω", "–Ω–µ–æ–ø—ã—Ç–Ω", "—É–º–µ—é", "–Ω–µ —É–º–µ—é", "–∑–Ω–∞—é", "–Ω–µ –∑–Ω–∞—é", "–∫–∏–π"
        ]
        if not any(keyword in answer_lower for keyword in level_keywords):
            if answer_length < 8:
                return False, "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± —É—Ä–æ–≤–Ω–µ"

    elif question_num == 3:  # –¶–µ–ª–∏ –æ–±—É—á–µ–Ω–∏—è
        goals_keywords = [
            "—Ö–æ—á—É", "–∂–µ–ª–∞—é", "–Ω—É–∂–Ω–æ", "–Ω–∞–¥–æ", "—Ü–µ–ª—å", "—Ü–µ–ª–∏", "–Ω–∞—É—á–∏—Ç—å—Å—è", "–∏–∑—É—á–∏—Ç—å",
            "–æ—Å–≤–æ–∏—Ç—å", "—É–ª—É—á—à–∏—Ç—å", "—Ä–∞–∑–≤–∏—Ç—å", "–ø–æ–ª—É—á–∏—Ç—å", "–ø—Ä–∏–æ–±—Ä–µ—Å—Ç–∏", "–Ω–∞–≤—ã–∫",
            "—Ç–µ—Ö–Ω–∏–∫", "–∏–≥—Ä–∞—Ç—å", "–∏–≥—Ä–∞", "–±–∏–ª—å—è—Ä–¥", "–∫–∏–π", "–ø–∏—Ä–∞–º–∏–¥–∞", "—Ç—É—Ä–Ω–∏—Ä", "—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω"
        ]
        if not any(keyword in answer_lower for keyword in goals_keywords):
            if answer_length < 8:
                return False, "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ü–µ–ª—è—Ö"

    elif question_num == 4:  # –û–±—É—á–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ (–î–∞/–ù–µ—Ç)
        # –î–ª—è 4-–≥–æ –≤–æ–ø—Ä–æ—Å–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—â–µ - –∏—â–µ–º "–¥–∞"/"–Ω–µ—Ç" –∏–ª–∏ –ø–æ—Ö–æ–∂–∏–µ —Å–ª–æ–≤–∞
        yes_words = ["–¥–∞", "yes", "—É—á–∏–ª", "–æ–±—É—á–∞–ª", "—É—á–∏–ª–∞—Å—å", "–æ–±—É—á–∞–ª–∞—Å—å", "–±—ã–ª", "–±—ã–ª–∞"]
        no_words = ["–Ω–µ—Ç", "no", "–Ω–µ —É—á–∏–ª", "–Ω–µ –æ–±—É—á–∞–ª", "–Ω–µ —É—á–∏–ª–∞—Å—å", "–Ω–µ –æ–±—É—á–∞–ª–∞—Å—å", "–Ω–µ –±—ã–ª", "–Ω–µ –±—ã–ª–∞"]

        has_yes = any(word in answer_lower for word in yes_words)
        has_no = any(word in answer_lower for word in no_words)

        if not (has_yes or has_no):
            # –ï—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –¥–∞/–Ω–µ—Ç, –Ω–æ –æ—Ç–≤–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π - –æ—Ç–∫–ª–æ–Ω—è–µ–º
            if answer_length < 5:
                return False, "–û—Ç–≤–µ—Ç –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —è–≤–Ω–æ–≥–æ —Å–æ–≥–ª–∞—Å–∏—è –∏–ª–∏ –æ—Ç–∫–∞–∑–∞"
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –¥–ª–∏–Ω–Ω—ã–π, –≤–æ–∑–º–æ–∂–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ–±—ä—è—Å–Ω—è–µ—Ç - –ø—Ä–∏–Ω–∏–º–∞–µ–º

    # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø—Ä–æ–π–¥–µ–Ω—ã
    return True, ""


def _format_pointers_and_bold(text: str) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ 'üëâ—Ç–µ–∫—Å—Ç:', 'üìÖ —Ç–µ–∫—Å—Ç:' (—Å –ª—é–±—ã–º —ç–º–æ–¥–∑–∏) –∏ '*—Ç–µ–∫—Å—Ç*'."""
    if not text:
        return text

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "*—Ç–µ–∫—Å—Ç*" - –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b> –î–û –æ–±—Ä–∞–±–æ—Ç–∫–∏ —ç–º–æ–¥–∑–∏
    # –≠—Ç–æ –≤–∞–∂–Ω–æ, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å –∑–≤–µ–∑–¥–æ—á–∫–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Å–∏–º–≤–æ–ª–∞–º–∏
    def replace_bold(match):
        content = match.group(1).strip()
        full_match = match.group(0)  # –ü–æ–ª–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–æ –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏
        # –ù–ï –≤—ã–¥–µ–ª—è–µ–º –∂–∏—Ä–Ω—ã–º –∏ –ù–ï —É–¥–∞–ª—è–µ–º –∑–≤–µ–∑–¥–æ—á–∫–∏, –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –µ—Å—Ç—å –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (. ! ?)
        # –≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –∑–≤–µ–∑–¥–æ—á–∫–∏ –æ–±—Ä–∞–º–ª—è—é—Ç —Ü–µ–ª–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –∞ –Ω–µ –æ—Ç–¥–µ–ª—å–Ω–æ–µ —Å–ª–æ–≤–æ/—Ñ—Ä–∞–∑—É
        if re.search(r'[.!?]', content):
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å –∑–≤–µ–∑–¥–æ—á–∫–∞–º–∏, –Ω–æ –±–µ–∑ –≤—ã–¥–µ–ª–µ–Ω–∏—è –∂–∏—Ä–Ω—ã–º
            return full_match
        # –ó–∞–º–µ–Ω—è–µ–º *—Ç–µ–∫—Å—Ç* –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b> –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –≤–Ω—É—Ç—Ä–∏ –Ω–µ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        return f'<b>{content}</b>'

    # –ó–∞–º–µ–Ω—è–µ–º *—Ç–µ–∫—Å—Ç* –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b>
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: *—Ç–µ–∫—Å—Ç*, * —Ç–µ–∫—Å—Ç*, *—Ç–µ–∫—Å—Ç *, * —Ç–µ–∫—Å—Ç *
    # –ò—â–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —á–∞—Å—Ç—å—é –¥–≤–æ–π–Ω—ã—Ö
    # –ü–∞—Ç—Ç–µ—Ä–Ω: *—Ç–µ–∫—Å—Ç*, –≥–¥–µ —Ç–µ–∫—Å—Ç –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø—Ä–æ–±–µ–ª—ã, –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–µ–∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ (?) –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤—Ö–æ–∂–¥–µ–Ω–∏–π
    # –í–∞–∂–Ω–æ: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–æ —Ç–æ–≥–æ, –∫–∞–∫ –¥—Ä—É–≥–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –º–æ–≥—É—Ç —É–¥–∞–ª–∏—Ç—å –∑–≤–µ–∑–¥–æ—á–∫–∏
    text = re.sub(r'(?<!\*)\*\s*([^*]+?)\s*\*(?!\*)', replace_bold, text)

    # –£–¥–∞–ª—è–µ–º üëâ –µ—Å–ª–∏ –ø–æ—Å–ª–µ –Ω–µ–≥–æ –∏–¥–µ—Ç –¥—Ä—É–≥–æ–µ —ç–º–æ–¥–∑–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä "üëâ üìö –ö—É—Ä—Å—ã:" -> "üìö –ö—É—Ä—Å—ã:")
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è —ç–º–æ–¥–∑–∏
    emoji_pattern = r'[\U0001F300-\U0001F9FF\U00002600-\U000027BF\U0001F600-\U0001F64F\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002700-\U000027BF\U0001F900-\U0001F9FF\U00002600-\U000026FF\U00002700-\U000027BF\U00002000-\U0000206F\U00002070-\U0000209F\U00002190-\U000021FF\U00002B00-\U00002BFF]'
    # –£–¥–∞–ª—è–µ–º üëâ –µ—Å–ª–∏ –ø–æ—Å–ª–µ –Ω–µ–≥–æ (—Å –ø—Ä–æ–±–µ–ª–∞–º–∏) –∏–¥–µ—Ç –¥—Ä—É–≥–æ–µ —ç–º–æ–¥–∑–∏
    text = re.sub(r'üëâ\s+({})'.format(emoji_pattern), r'\1', text)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ—Ä–∞–∑—ã —Ç–∏–ø–∞ "üìÖ —Ç–µ–∫—Å—Ç:" –∏–ª–∏ "üëâ—Ç–µ–∫—Å—Ç:" - –ø–µ—Ä–µ–Ω–æ—Å–∏–º –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
    # –ò—â–µ–º –ª—é–±–æ–π —Å–∏–º–≤–æ–ª, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç –±—ã—Ç—å —ç–º–æ–¥–∑–∏ (—à–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω Unicode)

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ—Ä–∞–∑—ã —Å —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º —Å–ª–µ–¥—É–µ—Ç —Ç–µ–∫—Å—Ç –∏ –¥–≤–æ–µ—Ç–æ—á–∏–µ
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω: —ç–º–æ–¥–∑–∏ + –ø—Ä–æ–±–µ–ª—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) + —Ç–µ–∫—Å—Ç + –¥–≤–æ–µ—Ç–æ—á–∏–µ
    # –£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: —ç–º–æ–¥–∑–∏ –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–æ–¥—Ä—è–¥
    text = re.sub(r'([^\n])({}+\s*[^\n:]+:)'.format(emoji_pattern), r'\1\n\2', text)
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —ç–º–æ–¥–∑–∏ –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ –Ω–µ –∏–º–µ–µ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –ø–µ—Ä–µ–¥ –Ω–∏–º
    text = re.sub(r'(\n|^)\s+({}+\s*[^\n:]+:)'.format(emoji_pattern), r'\1\2', text, flags=re.MULTILINE)

    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º <b>—Ç–µ–∫—Å—Ç</b> –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
    # –ò—â–µ–º <b>—Ç–µ–∫—Å—Ç</b> –∫–æ—Ç–æ—Ä—ã–µ –∏–¥—É—Ç –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–æ–π –∂–µ —Å—Ç—Ä–æ–∫–µ
    text = re.sub(r'([^\n])(<b>[^<]+</b>)', r'\1\n\2', text)
    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ <b>—Ç–µ–∫—Å—Ç</b> –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ –Ω–µ –∏–º–µ–µ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    text = re.sub(r'(\n|^)\s+(<b>[^<]+</b>)', r'\1\2', text, flags=re.MULTILINE)

    return text


def _format_llm_response_layout(text: str) -> str:
    """
    –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç LLM –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ —á–∞—Ç —Å–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–∞–≤–∏–ª–∞–º:
    1. –ö–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏
    2. –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "N. —Ç–µ–∫—Å—Ç", "* —Ç–µ–∫—Å—Ç", "üëâ —Ç–µ–∫—Å—Ç", "üëâ —Ç–µ–∫—Å—Ç:" –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
    3. –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "* —Ç–µ–∫—Å—Ç *" - —É–±—Ä–∞—Ç—å **, —Å–¥–µ–ª–∞—Ç—å –∂–∏—Ä–Ω—ã–º, –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
    4. –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "‚Äî —Ç–µ–∫—Å—Ç" –ù–ï –ø–µ—Ä–µ–Ω–æ—Å—è—Ç—Å—è –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
    """
    if not text:
        return text

    # –®–∞–≥ 0: –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "‚Äî", —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–æ–π (–¥–µ–ª–∞–µ–º —ç—Ç–æ –ü–ï–†–í–´–ú –¥–µ–ª–æ–º)
    lines = text.split('\n')
    merged_lines = []

    for i, line in enumerate(lines):
        line_stripped = line.strip()
        if not line_stripped:
            merged_lines.append('')
            continue

        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "‚Äî", –æ–±—ä–µ–¥–∏–Ω—è–µ–º –µ—ë —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–æ–π
        if line_stripped.startswith('‚Äî'):
            if merged_lines:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–µ–π —Å—Ç—Ä–æ–∫–æ–π (—É–±–∏—Ä–∞–µ–º –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç—Ä–æ–∫–∏)
                merged_lines[-1] = merged_lines[-1].rstrip() + ' ' + line_stripped
            else:
                # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                merged_lines.append(line_stripped)
        else:
            merged_lines.append(line)

    text = '\n'.join(merged_lines)

    # –®–∞–≥ 1: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "* —Ç–µ–∫—Å—Ç *" - —É–±–∏—Ä–∞–µ–º ** –∏ –¥–µ–ª–∞–µ–º –∂–∏—Ä–Ω—ã–º
    # –í–†–ï–ú–ï–ù–ù–û –û–¢–ö–õ–Æ–ß–ï–ù–û: –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∂–∏—Ä–Ω—ã–º
    # def replace_double_bold(match):
    #     content = match.group(1).strip()
    #     return f'\n<b>{content}</b>'
    #
    # # –ó–∞–º–µ–Ω—è–µ–º **—Ç–µ–∫—Å—Ç** –Ω–∞ <b>—Ç–µ–∫—Å—Ç</b> —Å –ø–µ—Ä–µ–Ω–æ—Å–æ–º –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
    # text = re.sub(r'\*\*([^*]+?)\*\*', replace_double_bold, text)
    #
    # # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "* —Ç–µ–∫—Å—Ç *" (–æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–≤–µ–∑–¥–æ—á–∫–∏ —Å –ø—Ä–æ–±–µ–ª–∞–º–∏)
    # text = re.sub(r'(?<!\*)\*\s+([^*]+?)\s+\*(?!\*)', replace_double_bold, text)

    # –®–∞–≥ 2: –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —Ç–æ—á–∫–∞–º, –≤–æ—Å–∫–ª–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–º –∏ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω—ã–º –∑–Ω–∞–∫–∞–º
    # –ù–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞—Å—Ç–∏ —Å "‚Äî" –≤–º–µ—Å—Ç–µ —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º

    # –°–Ω–∞—á–∞–ª–∞ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
    # –ó–∞—Ç–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
    lines = text.split('\n')
    all_sentences = []

    for line in lines:
        line_stripped = line.strip()
        if not line_stripped:
            all_sentences.append('')
            continue

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –Ω–æ –∑–∞—â–∏—â–∞–µ–º —á–∞—Å—Ç–∏ —Å "‚Äî" –∏ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        # –°–Ω–∞—á–∞–ª–∞ –∑–∞—â–∏—â–∞–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –æ—Ç —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
        # –ó–∞–º–µ–Ω—è–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "—á–∏—Å–ª–æ. —Ç–µ–∫—Å—Ç" –Ω–∞ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        numbered_list_pattern = re.compile(r'(\d+\.\s+[^\n.!?]+?)(?=[.!?]|$)')
        numbered_markers = {}
        marker_counter = 0

        def protect_numbered_list(match):
            nonlocal marker_counter
            marker = f"__NUMBERED_{marker_counter}__"
            numbered_markers[marker] = match.group(0)
            marker_counter += 1
            return marker

        # –ó–∞—â–∏—â–∞–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        protected_line = numbered_list_pattern.sub(protect_numbered_list, line_stripped)

        # –†–∞–∑–¥–µ–ª—è–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –∑–Ω–∞–∫–∞–º –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (–≤–∫–ª—é—á–∞—è –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ)
        # –°–Ω–∞—á–∞–ª–∞ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ
        protected_line = re.sub(r'‚Ä¶', '...', protected_line)
        # –†–∞–∑–¥–µ–ª—è–µ–º: –º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –∑–∞ –∫–æ—Ç–æ—Ä—ã–º–∏ —Å–ª–µ–¥—É–µ—Ç –ø—Ä–æ–±–µ–ª –∏–ª–∏ –∫–æ–Ω–µ—Ü —Å—Ç—Ä–æ–∫–∏
        parts = re.split(r'(\.\.\.|[.!?]+)(?=\s+|$)', protected_line)
        current_sentence = ''

        i = 0
        while i < len(parts):
            part = parts[i]
            if not part:
                i += 1
                continue

            # –ï—Å–ª–∏ —ç—Ç–æ –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è (–º–Ω–æ–≥–æ—Ç–æ—á–∏–µ –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã–µ –∑–Ω–∞–∫–∏)
            if part == '...' or re.match(r'^[.!?]+$', part):
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–ª–µ–¥—É—é—â—É—é —á–∞—Å—Ç—å
                next_part = parts[i + 1] if i + 1 < len(parts) else ''
                next_part_stripped = next_part.strip() if next_part else ''

                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å "‚Äî", –Ω–µ —Ä–∞–∑–¥–µ–ª—è–µ–º
                if next_part_stripped.startswith('‚Äî'):
                    # –ù–µ —Ä–∞–∑–¥–µ–ª—è–µ–º - –¥–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞–∫ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ —á–∞—Å—Ç—å —Å "‚Äî" –∫ —Ç–µ–∫—É—â–µ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é
                    current_sentence += part + next_part
                    i += 2  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —á–∞—Å—Ç—å
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —á–∏—Å–ª–∞ –∏ —Ç–æ—á–∫–∏ (–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫), –†–ê–ó–î–ï–õ–Ø–ï–ú
                # –≠—Ç–æ –Ω—É–∂–Ω–æ, —á—Ç–æ–±—ã "2. –û—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è:" –ø–µ—Ä–µ–Ω–æ—Å–∏–ª–æ—Å—å –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
                elif re.match(r'^\d+\.\s+', next_part_stripped):
                    # –†–∞–∑–¥–µ–ª—è–µ–º - –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±—É–¥–µ—Ç –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
                    current_sentence += part.rstrip()
                    if current_sentence.strip():
                        all_sentences.append(current_sentence.strip())
                        current_sentence = ''
                    # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
                    current_sentence = next_part
                    i += 2  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —á–∞—Å—Ç—å
                # –ï—Å–ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Ä–∫–µ—Ä –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞, —Ä–∞–∑–¥–µ–ª—è–µ–º
                elif '__NUMBERED_' in next_part:
                    # –†–∞–∑–¥–µ–ª—è–µ–º - –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                    current_sentence += part.rstrip()
                    if current_sentence.strip():
                        all_sentences.append(current_sentence.strip())
                        current_sentence = ''
                    # –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞
                    current_sentence = next_part
                    i += 2  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —á–∞—Å—Ç—å
                else:
                    # –†–∞–∑–¥–µ–ª—è–µ–º - –∑–∞–≤–µ—Ä—à–∞–µ–º —Ç–µ–∫—É—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                    current_sentence += part.rstrip()
                    if current_sentence.strip():
                        all_sentences.append(current_sentence.strip())
                        current_sentence = ''
                    i += 1
            else:
                # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç "‚Äî", –¥–æ–±–∞–≤–ª—è–µ–º –µ—ë –∫ —Ç–µ–∫—É—â–µ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é (–Ω–µ —Ä–∞–∑–¥–µ–ª—è–µ–º)
                if '‚Äî' in part.strip():
                    current_sentence += part
                else:
                    current_sentence += part
                i += 1

        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
        if current_sentence.strip():
            all_sentences.append(current_sentence.strip())

        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏
        restored_sentences = []
        for sentence in all_sentences:
            restored = sentence
            for marker, original in numbered_markers.items():
                restored = restored.replace(marker, original)
            restored_sentences.append(restored)

        all_sentences = restored_sentences
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: –¥–æ–ª–∂–Ω—ã –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã
        # (–∏—Å–∫–ª—é—á–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ —Å—Ç—Ä–æ–∫–∏ —Å "‚Äî", –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã)
        filtered_sentences = []
        for sentence in all_sentences:
            if not sentence.strip():
                filtered_sentences.append(sentence)
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –ª–∏ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã –∏–ª–∏ —Ü–∏—Ñ—Ä—ã
            first_char = sentence.strip()[0]
            if first_char.isupper() or first_char.isdigit() or '‚Äî' in sentence:
                filtered_sentences.append(sentence)
        
        all_sentences = filtered_sentences

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º - –∫–∞–∂–¥–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω–æ–π —Å—Ç—Ä–æ–∫–µ
    text = '\n'.join(all_sentences)

    # –®–∞–≥ 3: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–∞ –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–µ
    # –ù–û –∏—Å–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "‚Äî" (–æ–Ω–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–µ—Ä–µ–Ω–æ—Å–∏—Ç—å—Å—è)
    # –ó–∞—â–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å "‚Äî" –æ—Ç –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç–æ–∫ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–º–∏ –≤—ã—Ä–∞–∂–µ–Ω–∏—è–º–∏
    lines = text.split('\n')
    formatted_lines = []

    for i, line in enumerate(lines):
        line_stripped = line.strip()
        if not line_stripped:
            formatted_lines.append('')
            continue

        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç "‚Äî" (–¥–ª–∏–Ω–Ω—ã–π –¥–µ—Ñ–∏—Å) –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ—ë
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ª—é–±—ã—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ —Å "‚Äî"
        if '‚Äî' in line_stripped:
            formatted_lines.append(line_stripped)
            continue

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–æ–ª—å–∫–æ –¥–ª—è —Å—Ç—Ä–æ–∫, –ù–ï —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö "‚Äî"
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç "‚Äî", –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ –Ω–µ–π –Ω–∏–∫–∞–∫–∏–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
        # –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "N. —Ç–µ–∫—Å—Ç" (–Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫) - –í–°–ï–ì–î–ê –Ω–∞ –Ω–æ–≤—É—é —Å—Ç—Ä–æ–∫—É
        if '‚Äî' not in line:
            # –ù—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏: –¥–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å –ø–µ—Ä–µ–¥ "—á–∏—Å–ª–æ. —Ç–µ–∫—Å—Ç" –¥–∞–∂–µ –µ—Å–ª–∏ –∏–¥–µ—Ç –ø–æ—Å–ª–µ —Ç–æ—á–∫–∏
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ —Ç–æ—á–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω, –∫–æ—Ç–æ—Ä—ã–π –Ω–∞—Ö–æ–¥–∏—Ç –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏ –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ —Å—Ç—Ä–æ–∫–∏
            line = re.sub(r'([.!?]\s+)(\d+\.\s+[^\n]+?)(?=\s|$)', r'\1\n\2', line, flags=re.MULTILINE)
            # –¢–∞–∫–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–∏, –∫–æ–≥–¥–∞ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –∏–¥–µ—Ç –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫–∏ –∏–ª–∏ –ø–æ—Å–ª–µ –ø—Ä–æ–±–µ–ª–∞
            line = re.sub(r'(\S)\s+(\d+\.\s+[^\n]+?)(?=\s|$)', r'\1\n\2', line, flags=re.MULTILINE)

            # –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "* —Ç–µ–∫—Å—Ç" (–º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –±–µ–∑ —Ç–æ—á–∫–∏ –≤ –∫–æ–Ω—Ü–µ)
            line = re.sub(r'([^\n])(\*\s+[^\n]+?)(?<!\.)(?=\s|$)(?!\s*‚Äî)', r'\1\n\2', line, flags=re.MULTILINE)

            # –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "üëâ —Ç–µ–∫—Å—Ç" (–±–µ–∑ —Ç–æ—á–∫–∏ –∏ –¥–≤–æ–µ—Ç–æ—á–∏—è –≤ –∫–æ–Ω—Ü–µ)
            line = re.sub(r'([^\n])(üëâ\s+[^\n]+?)(?<![:.])(?=\s|$)(?!\s*‚Äî)', r'\1\n\2', line, flags=re.MULTILINE)

            # –°—Ç—Ä–æ–∫–∏ —Ç–∏–ø–∞ "üëâ —Ç–µ–∫—Å—Ç:" (—Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º –≤ –∫–æ–Ω—Ü–µ)
            line = re.sub(r'([^\n])(üëâ\s+[^\n]+?:)(?!\s*‚Äî)', r'\1\n\2', line, flags=re.MULTILINE)

        # –ï—Å–ª–∏ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–æ–∫–∞ —Ä–∞–∑–¥–µ–ª–∏–ª–∞—Å—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏
        # –ù–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –Ω–∞ –Ω–∞–ª–∏—á–∏–µ "‚Äî"
        if '\n' in line:
            for part in line.split('\n'):
                part_stripped = part.strip()
                if part_stripped:
                    # –ï—Å–ª–∏ —á–∞—Å—Ç—å —Å–æ–¥–µ—Ä–∂–∏—Ç "‚Äî", —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
                    if '‚Äî' in part_stripped:
                        formatted_lines.append(part_stripped)
                    else:
                        formatted_lines.append(part_stripped)
        else:
            formatted_lines.append(line_stripped)

    text = '\n'.join(formatted_lines)

    # –®–∞–≥ 4: –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–±–æ–ª–µ–µ –æ–¥–Ω–æ–π –ø–æ–¥—Ä—è–¥)
    text = re.sub(r'\n{3,}', '\n\n', text)

    # –®–∞–≥ 5: –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ —Å—Ç—Ä–æ–∫ (–∫—Ä–æ–º–µ —Å—Ç—Ä–æ–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö "‚Äî")
    lines = text.split('\n')
    cleaned_lines = []
    for line in lines:
        if '‚Äî' in line.strip():
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä–æ–∫—É —Å "‚Äî" –∫–∞–∫ –µ—Å—Ç—å
            cleaned_lines.append(line)
        else:
            cleaned_lines.append(line.lstrip())

    text = '\n'.join(cleaned_lines)

    return text.strip()


def _enhance_layout(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –¥–ª—è —ç–º–æ–¥–∑–∏ –∏ –º–∞—Ä–∫–µ—Ä–æ–≤."""
    if not text:
        return text

    # –ó–∞—â–∏—â–∞–µ–º —Å—Ç—Ä–æ–∫–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å "‚Äî" –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "‚Äî" –ø–æ—Å–ª–µ –∑–Ω–∞–∫–∞ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è, –æ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
    # –í—Ä–µ–º–µ–Ω–Ω–æ –∑–∞–º–µ–Ω—è–µ–º –∏—Ö –Ω–∞ –º–∞—Ä–∫–µ—Ä—ã
    protected_lines = {}
    marker_counter = 0

    lines = text.split('\n')
    protected_text_parts = []

    for line in lines:
        line_stripped = line.strip()
        # –ó–∞—â–∏—â–∞–µ–º –í–°–ï —Å—Ç—Ä–æ–∫–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ "‚Äî" (–¥–ª–∏–Ω–Ω—ã–π –¥–µ—Ñ–∏—Å) –≤ –ª—é–±–æ–º –º–µ—Å—Ç–µ
        # –≠—Ç–æ –∑–∞—â–∏—â–∞–µ—Ç –æ—Ç –ª—é–±—ã—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫ —Å "‚Äî"
        if '‚Äî' in line_stripped:
            marker = f"__PROTECTED_DASH_{marker_counter}__"
            protected_lines[marker] = line
            protected_text_parts.append(marker)
            marker_counter += 1
        else:
            protected_text_parts.append(line)

    text = '\n'.join(protected_text_parts)

    # –†–∞–∑–¥–µ–ª–∏—Ç—å –ø—É–Ω–∫—Ç—ã —Å–ø–∏—Å–∫–æ–≤, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –≤–ø–ª–æ—Ç–Ω—É—é —á–µ—Ä–µ–∑ –º–∞—Ä–∫–µ—Ä –∏–ª–∏ —Ü–∏—Ñ—Ä—ã
    # –ù–û –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å "‚Äî" (–æ–Ω–∏ —É–∂–µ –∑–∞—â–∏—â–µ–Ω—ã –º–∞—Ä–∫–µ—Ä–∞–º–∏)
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, –ø—Ä–æ–ø—É—Å–∫–∞—è —Å—Ç—Ä–æ–∫–∏ —Å –º–∞—Ä–∫–µ—Ä–∞–º–∏ –∑–∞—â–∏—â–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫
    lines = text.split('\n')
    processed_lines = []
    for line in lines:
        # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Ä–∫–µ—Ä –∑–∞—â–∏—â–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏, –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ—ë
        is_protected = any(marker in line for marker in protected_lines.keys())
        if is_protected:
            processed_lines.append(line)
        else:
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ –±–µ–∑ –º–∞—Ä–∫–µ—Ä–æ–≤
            processed_line = re.sub(r'(\S)\s*(- |‚Ä¢ |\d+[.)])', r'\1\n\2', line)
            processed_line = re.sub(r'(\S)\s*(\d+[.)])', r'\1\n\2', processed_line)
            processed_line = re.sub(r"(\S)\s*üëâ", r"\1\nüëâ", processed_line)
            processed_line = re.sub(r"^\s*üëâ", "üëâ", processed_line, flags=re.MULTILINE)
            processed_line = re.sub(r"\s*([üßøüîπ‚ñ∂Ô∏èüî∏‚úì‚û°Ô∏è])", r"\n\1", processed_line)
            processed_line = re.sub(r"(\n|^)\s*- ", r"\1- ", processed_line)
            processed_line = re.sub(r"(\n|^)\s*‚Ä¢ ", r"\1‚Ä¢ ", processed_line)
            processed_lines.append(processed_line)

    text = '\n'.join(processed_lines)

    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞—â–∏—â–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –ü–û–°–õ–ï –≤—Å–µ—Ö –æ–±—Ä–∞–±–æ—Ç–æ–∫
    for marker, original in protected_lines.items():
        text = text.replace(marker, original)

    lines = [line.strip() for line in text.splitlines() if line.strip()]
    return "\n".join(lines)


def _highlight_search_terms(text: str, found_words: list[str], found_phrases: list[str]) -> str:
    """
    –í—ã–¥–µ–ª—è–µ—Ç –∂–∏—Ä–Ω—ã–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã –≤ —Ç–µ–∫—Å—Ç–µ –∏—Å–ø–æ–ª—å–∑—É—è HTML-—Ç–µ–≥–∏ <b>.
    –†–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–µ–∫—Ç–∞.

    Args:
        text: –¢–µ–∫—Å—Ç –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è
        found_words: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤
        found_phrases: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
    """
    if not text or (not found_words and not found_phrases):
        return text

    result = text

    # –°–Ω–∞—á–∞–ª–∞ –≤—ã–¥–µ–ª—è–µ–º —Ñ—Ä–∞–∑—ã (–≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è –¥–ª–∏–Ω—ã, —á—Ç–æ–±—ã –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏—Å—å –ø–µ—Ä–≤—ã–º–∏)
    sorted_phrases = sorted(found_phrases, key=len, reverse=True)
    for phrase in sorted_phrases:
        if not phrase:
            continue
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è —Ñ—Ä–∞–∑—ã (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
        pattern = re.compile(re.escape(phrase), re.IGNORECASE)
        result = pattern.sub(lambda m: f"<b>{m.group(0)}</b>", result)

    # –ó–∞—Ç–µ–º –≤—ã–¥–µ–ª—è–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–ª–æ–≤–∞ (–æ–±—ã—á–Ω—ã–π –ø–æ–∏—Å–∫ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏)
    for word in found_words:
        if not word or len(word) < 2:
            continue

        # –î–ª—è –≤—Å–µ—Ö —Å–ª–æ–≤ –∏—â–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫—É (–±–µ–∑ –≥—Ä–∞–Ω–∏—Ü —Å–ª–æ–≤), —á—Ç–æ–±—ã –Ω–∞—Ö–æ–¥–∏—Ç—å —á–∞—Å—Ç–∏ —Å–ª–æ–≤
        word_pattern = re.escape(word)
        pattern = re.compile(word_pattern, re.IGNORECASE)

        def replace_word(match):
            matched_text = match.group(0)
            start = match.start()
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –≤–Ω—É—Ç—Ä–∏ —É–∂–µ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ (–º–µ–∂–¥—É <b> –∏ </b>)
            # –°—á–∏—Ç–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–∫—Ä—ã–≤–∞—é—â–∏—Ö –∏ –∑–∞–∫—Ä—ã–≤–∞—é—â–∏—Ö —Ç–µ–≥–æ–≤ –¥–æ –Ω–∞—á–∞–ª–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            before = result[:start]
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–∞—Ö–æ–¥–∏–º—Å—è –ª–∏ –º—ã –≤–Ω—É—Ç—Ä–∏ —Ç–µ–≥–∞ <b>...</b>
            open_tags = before.count('<b>')
            close_tags = before.count('</b>')
            if open_tags > close_tags:
                return matched_text  # –£–∂–µ –≤–Ω—É—Ç—Ä–∏ –≤—ã–¥–µ–ª–µ–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞, –Ω–µ –≤—ã–¥–µ–ª—è–µ–º
            return f"<b>{matched_text}</b>"

        result = pattern.sub(replace_word, result)

    return result


def _format_primary_source_fragment(
    fragment: dict,
    index: int,
    total: int,
    download_info: dict[str, str] | None,
) -> str:
    header = f"üìÑ –ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫ ({index + 1}/{total})"
    section_raw = fragment.get("section") or ""
    section = remove_hash_and_trash(section_raw)
    if _is_generic_section_marker(section):
        section = ""
    body_raw = (fragment.get("text") or "").replace("###", "").strip()
    rule_number = (fragment.get("rule_number") or "").strip().rstrip('.')
    rule_label = (fragment.get("rule_label") or "").strip()
    fragment_source = fragment.get("source") or ""

    pdf_title = ""
    if download_info and download_info.get("label"):
        pdf_title = download_info["label"]
    elif fragment_source:
        pdf_title = PRIMARY_SOURCE_LABELS.get(fragment_source, "")

    header_line = None
    display_body = body_raw

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ section –ø–æ–ª–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–†–ê–ó–î–ï–õ 5. –û–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ...")
    # –ï—Å–ª–∏ section —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –Ω–µ —Å–æ–∑–¥–∞–µ–º header_line –∏–∑ body
    section_has_full_header = section and re.match(r'–†–ê–ó–î–ï–õ\s+\d+\.', section, re.IGNORECASE)

    # –í—ã–¥–µ–ª—è–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—É–Ω–∫—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ, –µ—Å–ª–∏ –Ω–µ—Ç –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤
    # –ù–ï –¥–µ–ª–∞–µ–º —ç—Ç–æ, –µ—Å–ª–∏ section —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞
    if not section_has_full_header:
        first_line_split = display_body.split('\n', 1)
        first_line = first_line_split[0].strip() if first_line_split else ""
        rest_body = first_line_split[1] if len(first_line_split) > 1 else ""
        header_match = None
        if first_line and rest_body.strip():
            header_match = re.match(r"^(\d+(?:\.\d+)*)(?:\.)?\s+(.*)$", first_line)
        if header_match:
            number_part = header_match.group(1)
            title_part = header_match.group(2).strip()
            # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É–Ω–∫—Ç ‚Äî –∫–æ–≥–¥–∞ –Ω–æ–º–µ—Ä –±–µ–∑ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ–¥–ø—É–Ω–∫—Ç–æ–≤
            if number_part and '.' not in number_part:
                clean_title = title_part.rstrip('.')
                header_line = f"{number_part}. {clean_title}" if clean_title else f"{number_part}."
                display_body = rest_body.lstrip('\n')

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–º–µ—Ä –ø—Ä–∞–≤–∏–ª–∞ –≤ –Ω–∞—á–∞–ª–æ —Ç–µ–∫—Å—Ç–∞, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç header_line
    # –ò —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ section –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–æ–ª–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Ä–∞–∑–¥–µ–ª–∞ (–¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π)
    if rule_number and not header_line and not section_has_full_header:
        rule_prefix = f"{rule_number}."
        if not display_body.lstrip().startswith(rule_prefix):
            display_body = f"{rule_prefix} {display_body.lstrip()}"

    lines: list[str] = [header]

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –≤—Å–µ–≥–¥–∞, –µ—Å–ª–∏ –æ–Ω–æ –µ—Å—Ç—å
    # (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∞ –¥–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    if section:
        lines.append(section)
        lines.append("")
    if header_line:
        lines.append(header_line)
    if rule_label and rule_label.lower() not in section.lower():
        lines.append(rule_label)
    if display_body:
        display_body = _normalize_primary_body(display_body)
        display_body = _remove_generic_section_lines(display_body)

        # –û–ë–†–ï–ó–ê–ï–ú —Ç–µ–∫—Å—Ç –¥–æ –ø–µ—Ä–≤–æ–≥–æ –ø—É–Ω–∫—Ç–∞/–ø–æ–¥–ø—É–Ω–∫—Ç–∞, —á—Ç–æ–±—ã –≤ –æ–∫–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–ª—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—É–Ω–∫—Ç
        # –≠—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–±—â–∏–º –ø—Ä–∞–≤–∏–ª–∞–º —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –æ–∫–æ–Ω
        display_body = _truncate_to_single_point(display_body, header_line, rule_number)

        # –í—ã–¥–µ–ª—è–µ–º –∂–∏—Ä–Ω—ã–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ –∏ —Ñ—Ä–∞–∑—ã –¥–ª—è –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
        found_words = fragment.get('found_words', [])
        found_phrases = fragment.get('found_phrases', [])
        if found_words or found_phrases:
            display_body = _highlight_search_terms(display_body, found_words, found_phrases)

        if not header_line and lines and lines[-1] != "":
            lines.append("")
        lines.append(display_body)
    if pdf_title:
        lines.append("")
        lines.append(pdf_title)

    text = "\n".join(line for line in lines if line is not None)
    return _truncate_primary_source_text(text)


def _get_figures_for_fragment(fragment: dict, main_source: str | None) -> list[str]:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –∫–∞–∫–∏–µ —Ä–∏—Å—É–Ω–∫–∏ –Ω—É–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞.
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–º –±–ª–æ–∫–µ (—Ç–µ–∫—Å—Ç–µ –ø—É–Ω–∫—Ç–∞/–ø–æ–¥–ø—É–Ω–∫—Ç–∞), –±–µ–∑ —É—á–µ—Ç–∞ section.
    """
    figures: list[str] = []
    if not isinstance(fragment, dict):
        return figures

    fragment_source = fragment.get("source") or main_source
    if not fragment_source:
        return figures

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ —Ç–æ–ª—å–∫–æ –≤ —Ç–µ–∫—Å—Ç–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ –±–ª–æ–∫–∞ (–±–µ–∑ section)
    fragment_text = (fragment.get("text") or "").lower()
    if not fragment_text:
        return figures

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª—è –ö–æ—Ä–æ–Ω–∞
    if fragment_source == CORONA_SOURCE or _normalize_source_name(fragment_source) == _normalize_source_name(CORONA_SOURCE):
        corona_keywords = ("—Ä–∞—Å—Å—Ç–∞–Ω–æ–≤", "—Ä–∞—Å–ø–æ–ª–æ–∂", "—Ä—è–¥")
        if any(keyword in fragment_text for keyword in corona_keywords):
            figures.append("–†–∏—Å.2.1.2.1")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª—è –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
    if fragment_source == TECHNICAL_REQUIREMENTS_SOURCE or _normalize_source_name(fragment_source) == _normalize_source_name(TECHNICAL_REQUIREMENTS_SOURCE):
        tech_fig_221_keywords = ("–∫–æ—Ä–∏–¥–æ—Ä", "—Ä–∞–¥–∏—É—Å", "—Ä–∞–∑–º–µ—Ä –ª—É–∑", "–∑–∞–∫—Ä—É–≥–ª–µ–Ω", "—É–≥–æ–ª", "—à–∏—Ä–∏–Ω", "—Å—Ç–≤–æ—Ä", "—Å—Ä–µ–¥–Ω –ª—É–∑", "—É–≥–ª–æ–≤ –ª—É–∑")
        if any(keyword in fragment_text for keyword in tech_fig_221_keywords):
            figures.append("–†–∏—Å.2.2.1")

        tech_fig_222_keywords = ("–≤–∞–ª–∏–∫", "—Ä–µ–∑–∏–Ω", "–∫—Ä–æ–º–∫ –±–æ—Ä—Ç", "–Ω–∞–∫–ª–æ–Ω")
        if any(keyword in fragment_text for keyword in tech_fig_222_keywords):
            figures.append("–†–∏—Å.2.2.2")

        tech_fig_223_224_keywords = ("—Å–≤–µ—Ç–∏–ª—å–Ω–∏–∫", "—Å–≤–µ—Ç –∑–æ–Ω", "–æ—Å–≤–µ—â", "–ª–∞–º–ø", "–ø–ª–∞—Ñ–æ–Ω")
        if any(keyword in fragment_text for keyword in tech_fig_223_224_keywords):
            figures.extend(["–†–∏—Å.2.2.3", "–†–∏—Å.2.2.4"])

        # –†–∏—Å.2.2.5: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "–∏–≥—Ä–æ–≤ –∑–æ–Ω" –≤ —Ç–µ–∫—Å—Ç–µ (—Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º—ã: –∏–≥—Ä–æ–≤–∞—è –∑–æ–Ω–∞, –∏–≥—Ä–æ–≤–æ–π –∑–æ–Ω—ã –∏ —Ç.–¥.)
        if re.search(r"–∏–≥—Ä–æ–≤\w*\s+–∑–æ–Ω\w*", fragment_text):
            figures.append("–†–∏—Å.2.2.5")

        tech_fig_226_keywords = ("–∞–∫—Å–µ—Å", "—Ç–∞–±–ª–æ", "–ø–æ–ª–∫", "—Å—Ç–æ–ª-–ø–æ–ª–∫", "—Ç–∞–±–ª–æ-—Å—á–µ—Ç")
        if any(keyword in fragment_text for keyword in tech_fig_226_keywords):
            figures.append("–†–∏—Å.2.2.6")

    return _unique_preserving(figures)


def _build_primary_source_markup(
    current_index: int,
    total: int,
    download_info: dict[str, str] | None,
) -> InlineKeyboardMarkup:
    buttons: list[list[InlineKeyboardButton]] = []
    row: list[InlineKeyboardButton] = []

    if total > 1:
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–Ω–æ–ø–∫–∏ "–ù–∞–∑–∞–¥" —Å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
        prev_index = (current_index - 1) % total
        row.append(InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data=f"primary_source:goto:{prev_index}"))

    if download_info and download_info.get("url"):
        row.append(InlineKeyboardButton(text="üì• –°–∫–∞—á–∞—Ç—å", url=download_info["url"]))

    if total > 1:
        # –í—ã—á–∏—Å–ª—è–µ–º –∏–Ω–¥–µ–∫—Å –¥–ª—è –∫–Ω–æ–ø–∫–∏ "–í–ø–µ—Ä–µ–¥" —Å —Ü–∏–∫–ª–∏—á–µ—Å–∫–æ–π –Ω–∞–≤–∏–≥–∞—Ü–∏–µ–π
        next_index = (current_index + 1) % total
        row.append(InlineKeyboardButton(text="‚ñ∂Ô∏è –í–ø–µ—Ä—ë–¥", callback_data=f"primary_source:goto:{next_index}"))

    row.append(InlineKeyboardButton(text="‚úñÔ∏è –ó–∞–∫—Ä—ã—Ç—å", callback_data="primary_source:close"))
    buttons.append(row)
    return InlineKeyboardMarkup(inline_keyboard=buttons)


# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è file_id –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–∞ —Å –≥–ª–∞–∑–∞–º–∏
# –ë—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è, –∫–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç —Å—Ç–∏–∫–µ—Ä –±–æ—Ç—É
WAITING_STICKER_FILE_ID: str | None = None


async def _send_waiting_sticker(message: Message) -> Message | None:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è (–º–∞–ª–µ–Ω—å–∫–∏–µ –≥–ª–∞–∑–∞).
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç file_id –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä–∞ —Å –≥–ª–∞–∑–∞–º–∏.
    –ï—Å–ª–∏ file_id –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ–±—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–∑–≤–µ—Å—Ç–Ω—ã–µ file_id –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤.
    """
    global WAITING_STICKER_FILE_ID
    logger = logging.getLogger(__name__)

    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–π file_id
    if WAITING_STICKER_FILE_ID:
        try:
            sticker_message = await message.answer_sticker(WAITING_STICKER_FILE_ID)
            logger.debug("–ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ (–∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–≥–æ file_id)")
            return sticker_message
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Ç–∏–∫–µ—Ä –ø–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É file_id: {e}")

    # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä—ã —Å –≥–ª–∞–∑–∞–º–∏ –∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ Telegram
    # –≠—Ç–æ —Å—Ç–∏–∫–µ—Ä—ã –∏–∑ –Ω–∞–±–æ—Ä–∞ "Animated Emoji" - –ø—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤
    # File ID –º–æ–∂–µ—Ç –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –±–æ—Ç–∞, –Ω–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
    POPULAR_ANIMATED_EYES_STICKERS = [
        # –ü–æ–ø—É–ª—è—Ä–Ω—ã–µ file_id –¥–ª—è –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —ç–º–æ–¥–∑–∏ —Å –≥–ª–∞–∑–∞–º–∏ (üëÄ)
        # –≠—Ç–∏ file_id –º–æ–≥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –Ω–∞–±–æ—Ä–æ–≤ Telegram
        "CAACAgIAAxkBAAIBY2ZgZQABAX9kZWQAAUfQZWRkZGQAAQACAgADwDxPAAH4ZWRkZGQAAQACAgADwDxP",
        "CAACAgIAAxkBAAIBZGZgZQABAYBkZWQAAUfQZWRkZGQAAQACAgADwDxPAAH4ZWRkZGQAAQACAgADwDxP",
        "CAACAgIAAxkBAAIBZmZgZQABAYFkZWQAAUfQZWRkZGQAAQACAgADwDxPAAH4ZWRkZGQAAQACAgADwDxP",
    ]

    # –ü—Ä–æ–±—É–µ–º –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å—Ç–∏–∫–µ—Ä –ø–æ –∏–∑–≤–µ—Å—Ç–Ω—ã–º file_id
    for sticker_id in POPULAR_ANIMATED_EYES_STICKERS:
        try:
            sticker_message = await message.answer_sticker(sticker_id)
            logger.debug(f"–ê–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω —É—Å–ø–µ—à–Ω–æ (–∏–∑ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞)")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–∞–±–æ—á–∏–π file_id –¥–ª—è –±—É–¥—É—â–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
            WAITING_STICKER_FILE_ID = sticker_id
            return sticker_message
        except Exception:
            continue

    # –ï—Å–ª–∏ –Ω–∏ –æ–¥–∏–Ω —Å—Ç–∏–∫–µ—Ä –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–æ–¥–∑–∏ –∫–∞–∫ fallback
    # –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–≤–∏–¥–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–π —ç–º–æ–¥–∑–∏ "üëÄ"
    logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∏–∫–µ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–º–æ–¥–∑–∏ –∫–∞–∫ fallback")
    try:
        sticker_message = await message.answer("üëÄ")
        return sticker_message
    except Exception:
        return None


@router.message(F.sticker)
async def handle_sticker_for_waiting(message: Message) -> None:
    """
    –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è file_id –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–∞ —Å –≥–ª–∞–∑–∞–º–∏.
    –ö–æ–≥–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å—Ç–∏–∫–µ—Ä –±–æ—Ç—É, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ file_id –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Å—Ç–∏–∫–µ—Ä–∞ –æ–∂–∏–¥–∞–Ω–∏—è.
    """
    global WAITING_STICKER_FILE_ID

    if message.sticker:
        sticker = message.sticker
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç–∏–∫–µ—Ä (—ç–º–æ–¥–∑–∏-—Å—Ç–∏–∫–µ—Ä –æ–±—ã—á–Ω–æ –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π)
        if sticker.is_animated or sticker.is_video:
            WAITING_STICKER_FILE_ID = sticker.file_id
            logger = logging.getLogger(__name__)
            logger.info(f"File_id –∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å—Ç–∏–∫–µ—Ä–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {WAITING_STICKER_FILE_ID[:30]}...")
            await message.answer(
                f"‚úÖ <b>–°—Ç–∏–∫–µ—Ä —Å–æ—Ö—Ä–∞–Ω–µ–Ω!</b>\n\n"
                f"File ID: <code>{WAITING_STICKER_FILE_ID}</code>\n\n"
                f"–¢–µ–ø–µ—Ä—å —ç—Ç–æ—Ç —Å—Ç–∏–∫–µ—Ä –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –æ–∂–∏–¥–∞–Ω–∏—è.",
                parse_mode=ParseMode.HTML
            )
        else:
            await message.answer("‚ö†Ô∏è –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ—Ç–ø—Ä–∞–≤—å—Ç–µ <b>–∞–Ω–∏–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π</b> —Å—Ç–∏–∫–µ—Ä —Å –≥–ª–∞–∑–∞–º–∏.", parse_mode=ParseMode.HTML)


async def _delete_waiting_sticker(waiting_sticker_message: Message | None) -> None:
    """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç."""
    if waiting_sticker_message:
        try:
            await waiting_sticker_message.delete()
        except Exception as e:
            logger = logging.getLogger(__name__)
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è: {e}")


async def _show_intent_selection_window(
    message: Message,
    state: FSMContext,
    waiting_sticker_message: Message | None = None,
) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è (–û–±—É—á–µ–Ω–∏–µ/–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è/–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å)"""
    logger = logging.getLogger(__name__)

    try:
        if not message:
            logger.error("_show_intent_selection_window: message is None")
            return

        if not message.from_user:
            logger.error("_show_intent_selection_window: message.from_user is None")
            return

        text = (
            "‚è∏Ô∏è <b>–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—Ç–æ—á–Ω–∏—Ç–µ, —á—Ç–æ –í—ã —Ö–æ—Ç–∏—Ç–µ:</b>\n"
            "üëâ - –ó–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –û–±—É—á–µ–Ω–∏–µ\n"
            "üëâ - –ó–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—é –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É\n"
            "üëâ - –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç–µ"
        )

        buttons = [
            InlineKeyboardButton(text="üü¢ –û–±—É—á–µ–Ω–∏–µ", callback_data="intent:training"),
            InlineKeyboardButton(text="üü£ –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è", callback_data="intent:consultation"),
            InlineKeyboardButton(text="‚ñ∂Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å", callback_data="intent:continue"),
        ]

        markup = InlineKeyboardMarkup(inline_keyboard=[buttons])

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –ø–æ–∫–∞–∑–æ–º –æ–∫–Ω–∞
        await _delete_waiting_sticker(waiting_sticker_message)

        await message.answer(text, reply_markup=markup, parse_mode=ParseMode.HTML)
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å"
        original_query = message.text or ""

        # –û–ë–ù–£–õ–Ø–ï–ú –≤—Å–µ –ø–æ–ª—è –ø—Ä–æ—Ñ–∏–ª—è (–∫—Ä–æ–º–µ name_sys) –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –æ–∫–Ω–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        profile = await get_user_profile(message.from_user.id)
        old_status = (profile.status or "").strip() if profile else ""
        await reset_user_profile_fields(message.from_user.id)
        await state.update_data(
            intent_selection_shown=True,
            original_query_for_continue=original_query,
            old_status_before_intent=old_status  # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç–∞—Ä—ã–π —Å—Ç–∞—Ç—É—Å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è
        )

        await save_chat_message(message.from_user.id, "assistant", text)

        logger.info(f"–ü–æ–∫–∞–∑–∞–Ω–æ –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.id}, –ø–æ–ª—è –ø—Ä–æ—Ñ–∏–ª—è –æ–±–Ω—É–ª–µ–Ω—ã")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ _show_intent_selection_window: {e}", exc_info=True)
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
        await _delete_waiting_sticker(waiting_sticker_message)
        # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–∞–ª—å—à–µ, —á—Ç–æ–±—ã –æ–Ω–æ –±—ã–ª–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –∫–æ–¥–µ
        raise


async def _show_phase4_booking_window(
    message: Message,
    state: FSMContext,
    waiting_sticker_message: Message | None = None,
) -> None:
    """–ü–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –∑–∞–ø–∏—Å–∏ –§–∞–∑—ã 4 —Å –∫–Ω–æ–ø–∫–∞–º–∏"""
    logger = logging.getLogger(__name__)

    try:
        if not message:
            logger.error("_show_phase4_booking_window: message is None")
            return

        if not message.from_user:
            logger.error("_show_phase4_booking_window: message.from_user is None")
            return

        text = (
            "===üìù–ó –ê –ü –ò –° –¨===\n"
            "–ü—Ä–µ–¥–ª–∞–≥–∞—é —Å–ª–µ–¥—É—é—â–∏–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã:\n"
            "üëâ –ó–∞–ø–∏—à–∏—Ç–µ—Å—å –°–ê–ú–û–°–¢–û–Ø–¢–ï–õ–¨–ù–û, –ø–æ–∑–≤–æ–Ω–∏–≤ –ø–æ —Ç–µ–ª–µ—Ñ–æ–Ω—É —à–∫–æ–ª—ã üì± +7 983 205 2230.\n"
            "üëâ –û—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–∏ –∫–æ–Ω—Ç–∞–∫—Ç—ã - –ò–ú–Ø –∏ –¢–ï–õ–ï–§–û–ù, —Ç–æ–≥–¥–∞ —è —Å–¥–µ–ª–∞—é –∑–∞–ø–∏—Å—å –∑–∞ –í–∞—Å üòé.\n"
            "<b>–ß—Ç–æ –≤—ã–±–∏—Ä–∞–µ—Ç–µ?</b>"
        )

        buttons = [
            InlineKeyboardButton(text="üìû –°–ê–ú", callback_data="phase4:self"),
            InlineKeyboardButton(text="üë®‚Äçüéì –ö–û–ù–¢–ê–ö–¢–´", callback_data="phase4:contacts"),
            InlineKeyboardButton(text="‚ùå –û—Ç–º–µ–Ω–∞", callback_data="phase4:cancel"),
        ]

        markup = InlineKeyboardMarkup(inline_keyboard=[buttons])

        # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø–µ—Ä–µ–¥ –ø–æ–∫–∞–∑–æ–º –æ–∫–Ω–∞
        await _delete_waiting_sticker(waiting_sticker_message)

        await message.answer(text, reply_markup=markup, parse_mode=ParseMode.HTML)
        await state.update_data(phase4_window_shown=True)

        await save_chat_message(message.from_user.id, "assistant", text)

        logger.info(f"–ü–æ–∫–∞–∑–∞–Ω–æ –æ–∫–Ω–æ –∑–∞–ø–∏—Å–∏ –§–∞–∑—ã 4 –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.id}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ _show_phase4_booking_window: {e}", exc_info=True)
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
        await _delete_waiting_sticker(waiting_sticker_message)
        raise


async def _answer_with_sticker_cleanup(
    message: Message,
    text: str,
    waiting_sticker_message: Message | None = None,
    **kwargs
) -> Message | None:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    sent_message = await message.answer(text, **kwargs)
    await _delete_waiting_sticker(waiting_sticker_message)
    return sent_message


async def _process_faq_query(
    message: Message,
    state: FSMContext,
    user_q: str,
    *,
    input_mode: str = "text",
    waiting_sticker_message: Message | None = None,
) -> None:
    logger = logging.getLogger(__name__)

    user_id = message.from_user.id if message.from_user else 0

    # –ü–æ–ª—É—á–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω–æ–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    name_sys = "–¥—Ä—É–≥"
    if message.from_user:
        if message.from_user.first_name:
            name_sys = message.from_user.first_name
        elif message.from_user.username:
            name_sys = message.from_user.username

    # –ü–æ–ª—É—á–∞–µ–º –∏–ª–∏ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    profile = await get_or_create_user_profile(user_id, name_sys)

    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É –∏–∑ state
    state_data = await state.get_data()
    current_phase = state_data.get("phase", 1)
    continue_button_pressed = state_data.get("continue_button_pressed", False)

    user_q = (user_q or "").strip()
    if not user_q:
        await _answer_with_sticker_cleanup(message, "–ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å –æ —à–∫–æ–ª–µ –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º –±–∏–ª—å—è—Ä–¥–µ –∏ —è –ø–æ–º–æ–≥—É.", waiting_sticker_message)
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–π –±–µ–∑ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –ë–∞–∑–µ –∑–Ω–∞–Ω–∏–π
    normalized = re.sub(r"[\s!.,?;:()\-]+", " ", user_q.lower()).strip()
    greeting_words = {
        "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–¥–æ–±—Ä–æ–µ —É—Ç—Ä–æ", "–¥–æ–±—Ä—ã–π –≤–µ—á–µ—Ä",
        "–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–π–æ", "—Ö–∞–π", "–∑–¥–∞—Ä–æ–≤–∞"
    }
    if any(normalized == gw or normalized.startswith(gw) for gw in greeting_words):
        await _answer_with_sticker_cleanup(message, "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —è –≤–µ—Å—å - –≤–Ω–∏–º–∞–Ω–∏–µ!", waiting_sticker_message)
        return

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –ï—Å–ª–∏ –æ–∫–Ω–æ –ü–æ–ª–∏—Ç–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –î–û–õ–ñ–ï–ù –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω—É –∏–∑ –¥–≤—É—Ö –∫–Ω–æ–ø–æ–∫ (–î–ê –∏–ª–∏ –ù–ï–¢), –∏–Ω–∞—á–µ –æ–∫–Ω–æ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞
    if state_data.get("policy_shown") and current_phase == 2:
        logger.info(f"–û–∫–Ω–æ –ü–æ–ª–∏—Ç–∏–∫–∞ –∞–∫—Ç–∏–≤–Ω–æ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{user_q[:50]}'")
        if not message:
            logger.error("message is None –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –ü–æ–ª–∏—Ç–∏–∫–∞")
            await _delete_waiting_sticker(waiting_sticker_message)
            return
        try:
            # –ü–æ–ª—É—á–∞–µ–º user_intent –∏–∑ state –¥–ª—è –ø–æ–∫–∞–∑–∞ –æ–∫–Ω–∞ –ø–æ–ª–∏—Ç–∏–∫–∏
            user_intent = state_data.get("user_intent", "–û–±—É—á–µ–Ω–∏–µ")
            await show_policy_window(message, state, user_intent, waiting_sticker_message)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ –æ—Ç–ø—Ä–∞–≤–∫—É –≤ LLM
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –æ–∫–Ω–∞ –ü–æ–ª–∏—Ç–∏–∫–∞: {e}", exc_info=True)
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
            await _delete_waiting_sticker(waiting_sticker_message)
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            if message:
                try:
                    await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                except Exception as msg_error:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {msg_error}")
            return

    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –º—ã –≤ –§–∞–∑–µ 2 (–ü–æ–ª–∏—Ç–∏–∫–∞), –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –ø–æ–∏—Å–∫ –∏ –æ–±—â–µ–Ω–∏–µ —Å LLM
    if current_phase == 2:
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤ –§–∞–∑–µ 2 (–ü–æ–ª–∏—Ç–∏–∫–∞) - –ø–æ–∏—Å–∫ –∏ LLM –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –§–∞–∑—ã 3: –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –∞–Ω–∫–µ—Ç—ã (–î–û –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –ø–æ–∏—Å–∫–∞)
    if current_phase == 3 and state_data.get("anketa_started"):
        anketa_question = state_data.get("anketa_question", 1)
        anketa_retry_count = state_data.get("anketa_retry_count", 0)
        invalid_messages = state_data.get("anketa_invalid_messages", [])  # –°–ø–∏—Å–æ–∫ ID –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        is_valid, validation_reason = _validate_anketa_answer(user_q, anketa_question)

        if not is_valid:
            # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω, —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
            if message and message.message_id:
                invalid_messages.append(message.message_id)
                await state.update_data(anketa_invalid_messages=invalid_messages)

            # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫
            anketa_retry_count += 1
            await state.update_data(anketa_retry_count=anketa_retry_count)

            # –ï—Å–ª–∏ –ø–æ–ø—ã—Ç–æ–∫ –±–æ–ª—å—à–µ 2, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –§–∞–∑–µ 1
            if anketa_retry_count > 2:
                logger.warning(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å {anketa_question} –ø–æ—Å–ª–µ {anketa_retry_count} –ø–æ–ø—ã—Ç–æ–∫")
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞) –ø–µ—Ä–µ–¥ –≤—ã—Ö–æ–¥–æ–º
                if invalid_messages and message and message.chat:
                    for msg_id in invalid_messages:
                        try:
                            await message.bot.delete_message(chat_id=message.chat.id, message_id=msg_id)
                            logger.info(f"–£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                        except Exception as e:
                            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id}: {e}")
                await state.update_data(
                    phase=1,
                    anketa_started=False,
                    anketa_question=None,
                    anketa_retry_count=0,
                    anketa_invalid_messages=[]
                )
                await _answer_with_sticker_cleanup(
                    message,
                    "üòï–ñ–∞–ª—å, —á—Ç–æ –í—ã –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∏ –Ω–∞ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã!\n‚ñ∂Ô∏è –Ø —Å–Ω–æ–≤–∞ –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º.",
                    waiting_sticker_message
                )
                await save_chat_message(user_id, "assistant", "üòï–ñ–∞–ª—å, —á—Ç–æ –í—ã –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∏ –Ω–∞ –≤—Å–µ –≤–æ–ø—Ä–æ—Å—ã!\n‚ñ∂Ô∏è –Ø —Å–Ω–æ–≤–∞ –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º.")
                return

            # –ó–∞–¥–∞–µ–º –≤–æ–ø—Ä–æ—Å –ø–æ–≤—Ç–æ—Ä–Ω–æ —Å —Å–æ–æ–±—â–µ–Ω–∏–µ–º "üí§ –ü—Ä–æ—Å—Ç–∏—Ç–µ?"
            question_texts = {
                1: "<b>1. –ö–∞–∫–æ–π —É –í–∞—Å –û–ü–´–¢ –∏–≥—Ä—ã –Ω–∞ –±–∏–ª—å—è—Ä–¥–µ?</b>\n(–ù–∞–ø—Ä–∏–º–µ—Ä: –∏–≥—Ä–∞—é 2 –≥–æ–¥–∞, –Ω–æ–≤–∏—á–æ–∫, –Ω–µ –∏–≥—Ä–∞–ª, —É–º–µ—é –∏–≥—Ä–∞—Ç—å, –∏–≥—Ä–∞–ª –≤ –¥–µ—Ç—Å—Ç–≤–µ –∏ —Ç.–¥.)",
                2: "<b>2. –ö–∞–∫–æ–π –£–†–û–í–ï–ù–¨ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏, –ø–æ –í–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é?</b>\n(–ù–∞–ø—Ä–∏–º–µ—Ä: –Ω–æ–≤–∏—á–æ–∫, –Ω–∞—á–∏–Ω–∞—é—â–∏–π, —Å—Ä–µ–¥–Ω–∏–π, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π, –ª—é–±–∏—Ç–µ–ª—å, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª –∏ —Ç.–¥.)",
                3: "<b>3. –ö–∞–∫–æ–≤—ã –í–∞—à–∏ –¶–ï–õ–ò –≤ –æ–±—É—á–µ–Ω–∏–∏?</b>\n(–ù–∞–ø—Ä–∏–º–µ—Ä: –Ω–∞—É—á–∏—Ç—å—Å—è –∏–≥—Ä–∞—Ç—å, —É–ª—É—á—à–∏—Ç—å —Ç–µ—Ö–Ω–∏–∫—É, –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —Ç—É—Ä–Ω–∏—Ä—É, –æ—Å–≤–æ–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –∏ —Ç.–¥.)",
                4: "<b>4. –£—á–∏–ª–∏—Å—å –ª–∏ –í—ã –†–ê–ù–ï–ï –≤ –®–ë ¬´–ê–±—Ä–∏–∫–æ–ª—å¬ª?</b>\n(–î–∞ –∏–ª–∏ –ù–µ—Ç)"
            }

            retry_message = f"üí§ –ü—Ä–æ—Å—Ç–∏—Ç–µ?\n\n{question_texts.get(anketa_question, '')}"
            sent_message = await _answer_with_sticker_cleanup(
                message,
                retry_message,
                waiting_sticker_message,
                parse_mode=ParseMode.HTML
            )
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –æ—Ç–≤–µ—Ç–∞ –±–æ—Ç–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
            if sent_message and sent_message.message_id:
                invalid_messages.append(sent_message.message_id)
                await state.update_data(anketa_invalid_messages=invalid_messages)
            await save_chat_message(user_id, "assistant", retry_message)
            logger.info(f"–û—Ç–≤–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} –Ω–∞ –≤–æ–ø—Ä–æ—Å {anketa_question} –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–µ–Ω: {validation_reason}. –ü–æ–ø—ã—Ç–∫–∞ {anketa_retry_count}")
            return

        # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –≤–∞–ª–∏–¥–µ–Ω, —É–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞)
        if invalid_messages and message and message.chat:
            for msg_id in invalid_messages:
                try:
                    await message.bot.delete_message(chat_id=message.chat.id, message_id=msg_id)
                    logger.info(f"–£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                except Exception as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id}: {e}")
            await state.update_data(anketa_invalid_messages=[])

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫ –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–≤–µ—Ç
        await state.update_data(anketa_retry_count=0)

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –Ω–∞ –∫–∞–∫–æ–π –≤–æ–ø—Ä–æ—Å –æ—Ç–≤–µ—á–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å
        # –í–æ–ø—Ä–æ—Å 1: –û–ø—ã—Ç
        if anketa_question == 1:
            await update_user_profile(user_id, exp=user_q)
            await state.update_data(anketa_question=2)
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å 1 (–û–ø—ã—Ç): {user_q[:50]}")
            # –ó–∞–¥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
            next_question = (
                "<b>2. –ö–∞–∫–æ–π –£–†–û–í–ï–ù–¨ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏, –ø–æ –í–∞—à–µ–º—É –º–Ω–µ–Ω–∏—é?</b>\n"
                "(–ù–∞–ø—Ä–∏–º–µ—Ä: –Ω–æ–≤–∏—á–æ–∫, –Ω–∞—á–∏–Ω–∞—é—â–∏–π, —Å—Ä–µ–¥–Ω–∏–π, –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π, –ª—é–±–∏—Ç–µ–ª—å, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª –∏ —Ç.–¥.)"
            )
            await _answer_with_sticker_cleanup(
                message,
                next_question,
                waiting_sticker_message,
                parse_mode=ParseMode.HTML
            )
            await save_chat_message(user_id, "assistant", next_question)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ LLM

        # –í–æ–ø—Ä–æ—Å 2: –£—Ä–æ–≤–µ–Ω—å
        elif anketa_question == 2:
            await update_user_profile(user_id, level=user_q)
            await state.update_data(anketa_question=3)
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å 2 (–£—Ä–æ–≤–µ–Ω—å): {user_q[:50]}")
            # –ó–∞–¥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
            next_question = (
                "<b>3. –ö–∞–∫–æ–≤—ã –í–∞—à–∏ –¶–ï–õ–ò –≤ –æ–±—É—á–µ–Ω–∏–∏?</b>\n"
                "(–ù–∞–ø—Ä–∏–º–µ—Ä: –Ω–∞—É—á–∏—Ç—å—Å—è –∏–≥—Ä–∞—Ç—å, —É–ª—É—á—à–∏—Ç—å —Ç–µ—Ö–Ω–∏–∫—É, –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å—Å—è –∫ —Ç—É—Ä–Ω–∏—Ä—É, –æ—Å–≤–æ–∏—Ç—å –ø—Ä–∞–≤–∏–ª–∞ –∏ —Ç.–¥.)"
            )
            await _answer_with_sticker_cleanup(
                message,
                next_question,
                waiting_sticker_message,
                parse_mode=ParseMode.HTML
            )
            await save_chat_message(user_id, "assistant", next_question)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ LLM

        # –í–æ–ø—Ä–æ—Å 3: –¶–µ–ª–∏
        elif anketa_question == 3:
            await update_user_profile(user_id, goals=user_q)
            await state.update_data(anketa_question=4)
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å 3 (–¶–µ–ª–∏): {user_q[:50]}")
            # –ó–∞–¥–∞–µ–º —Å–ª–µ–¥—É—é—â–∏–π –≤–æ–ø—Ä–æ—Å
            next_question = (
                "<b>4. –£—á–∏–ª–∏—Å—å –ª–∏ –í—ã –†–ê–ù–ï–ï –≤ –®–ë ¬´–ê–±—Ä–∏–∫–æ–ª—å¬ª?</b>\n"
                "(–î–∞ –∏–ª–∏ –ù–µ—Ç)"
            )
            await _answer_with_sticker_cleanup(
                message,
                next_question,
                waiting_sticker_message,
                parse_mode=ParseMode.HTML
            )
            await save_chat_message(user_id, "assistant", next_question)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ LLM

        # –í–æ–ø—Ä–æ—Å 4: –û–±—É—á–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ (–î–∞/–ù–µ—Ç)
        elif anketa_question == 4:
            before_value = "–î–∞" if any(word in user_q.lower() for word in ["–¥–∞", "yes", "—É—á–∏–ª", "–æ–±—É—á–∞–ª", "—É—á–∏–ª–∞—Å—å", "–æ–±—É—á–∞–ª–∞—Å—å", "–±—ã–ª", "–±—ã–ª–∞"]) else "–ù–µ—Ç"
            await update_user_profile(user_id, before=before_value)
            await state.update_data(anketa_question=5, anketa_completed=True)
            logger.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å 4 (–û–±—É—á–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ): {before_value}")

            # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É –ø–æ—Å–ª–µ –≤—Å–µ—Ö 4 –æ—Ç–≤–µ—Ç–æ–≤
            profile = await get_user_profile(user_id)
            if profile:
                summary = f"""üåà –û—Ç–ª–∏—á–Ω–æ! –í–æ—Ç –í–∞—à–∏ –æ—Ç–≤–µ—Ç—ã:

1. –û–ø—ã—Ç: <b>{profile.exp or '‚Äî'}</b>

2. –£—Ä–æ–≤–µ–Ω—å: <b>{profile.level or '‚Äî'}</b>

3. –¶–µ–ª—å: <b>{profile.goals or '‚Äî'}</b>

4. –û–±—É—á–µ–Ω–∏–µ —Ä–∞–Ω–µ–µ: <b>{profile.before or '‚Äî'}</b>

üòé <b>–í—ã –±–æ–ª—å—à–æ–π –º–æ–ª–æ–¥–µ—Ü, –∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–∫–æ–Ω—á–µ–Ω–æ!</b>
–í–∞—à–∏ –æ—Ç–≤–µ—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, —á—Ç–æ –ø–æ–º–æ–∂–µ—Ç –Ω–∞–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –¥–ª—è –í–∞—Å –û–ü–¢–ò–ú–ê–õ–¨–ù–£–Æ –ø—Ä–æ–≥—Ä–∞–º–º—É –æ–±—É—á–µ–Ω–∏—è üî•."""

                # –ï—Å–ª–∏ Before=–ù–µ—Ç, –¥–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–º –±–æ–Ω—É—Å–µ
                if profile.before and profile.before.strip().lower() == "–Ω–µ—Ç":
                    summary += "\n\n–ö—Ä–æ–º–µ —Ç–æ–≥–æ, –í–∞–º, –∫–∞–∫ –Ω–æ–≤–æ–º—É —É—á–µ–Ω–∏–∫—É, –ø–æ–ª–∞–≥–∞–µ—Ç—Å—è –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω—ã–π –±–æ–Ω—É—Å üéÅ - –ø–æ–ª–Ω–æ—Å—Ç—å—é –ë–ï–°–ü–õ–ê–¢–ù–´–ô –ø–µ—Ä–≤—ã–π —É—Ä–æ–∫ 1,5 —á–∞—Å–∞."

                await _answer_with_sticker_cleanup(
                    message,
                    summary,
                    waiting_sticker_message,
                    parse_mode=ParseMode.HTML
                )
                await save_chat_message(user_id, "assistant", summary)

            # –ü–æ—Å–ª–µ –≤—Å–µ—Ö 4 –æ—Ç–≤–µ—Ç–æ–≤ –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –§–∞–∑–µ 4
            await state.update_data(phase=4, phase4_check_contacts=False, phase4_window_shown=False)
            logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥ –∫ –§–∞–∑–µ 4 (–ó–∞–ø–∏—Å—å) –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel –±—É–¥–µ—Ç –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ "–°–∞–º" (–µ—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è) –∏–ª–∏ "–ö–æ–Ω—Ç–∞–∫—Ç" (–ø–æ—Å–ª–µ –≤–≤–æ–¥–∞ —Ç–µ–ª–µ—Ñ–æ–Ω–∞)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –∑–∞–ø–∏—Å–∏ —Å –∫–Ω–æ–ø–∫–∞–º–∏
            await _show_phase4_booking_window(message, state, waiting_sticker_message)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ LLM

    # –ü—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –º—ã –≤ –§–∞–∑–µ 3 (–ê–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ), –Ω–æ anketa_started=False, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏–º –ø–æ–∏—Å–∫ –∏ –æ–±—â–µ–Ω–∏–µ —Å LLM
    if current_phase == 3:
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤ –§–∞–∑–µ 3 (–ê–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ) - –ø–æ–∏—Å–∫ –∏ LLM –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        await _delete_waiting_sticker(waiting_sticker_message)
        return

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –ï—Å–ª–∏ –æ–∫–Ω–æ –§–∞–∑—ã 4 –∞–∫—Ç–∏–≤–Ω–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –î–û–õ–ñ–ï–ù –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω—É –∏–∑ —Ç—Ä–µ—Ö –∫–Ω–æ–ø–æ–∫, –∏–Ω–∞—á–µ –æ–∫–Ω–æ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞
    if state_data.get("phase4_window_shown") and current_phase == 4:
        logger.info(f"–û–∫–Ω–æ –§–∞–∑—ã 4 –∞–∫—Ç–∏–≤–Ω–æ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{user_q[:50]}'")
        if not message:
            logger.error("message is None –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –§–∞–∑—ã 4")
            await _delete_waiting_sticker(waiting_sticker_message)
            return
        try:
            await _show_phase4_booking_window(message, state, waiting_sticker_message)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ LLM
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –æ–∫–Ω–∞ –§–∞–∑—ã 4: {e}", exc_info=True)
            await _delete_waiting_sticker(waiting_sticker_message)
            if message:
                try:
                    await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                except Exception as msg_error:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {msg_error}")
            return

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –§–∞–∑—ã 4: –ó–∞–ø–∏—Å—å (–∏–º—è –∏ —Ç–µ–ª–µ—Ñ–æ–Ω) - —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–∫–Ω–æ –Ω–µ –ø–æ–∫–∞–∑–∞–Ω–æ (–ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–≤–æ–¥–∏—Ç –¥–∞–Ω–Ω—ã–µ)
    if current_phase == 4 and not state_data.get("phase4_window_shown"):
        phase4_state = state_data.get("phase4_state", None)  # "waiting_name", "waiting_phone", None

        if phase4_state == "waiting_name":
            # –ü–æ–ª—É—á–∞–µ–º –∏–º—è (–±–µ–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)
            name = user_q.strip()
            if name:
                await update_user_profile(user_id, name=name)
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ –∏–º—è: {name}")
                # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –∑–∞–ø—Ä–æ—Å—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞ - –æ—á–∏—â–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
                await state.update_data(phase4_state="waiting_phone", phase4_invalid_messages=[])
                phone_message = "<b>–í–∞—à –ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞?</b>\n(–≤ —Ñ–æ—Ä–º–∞—Ç–µ +7(8)...)"
                await _answer_with_sticker_cleanup(
                    message,
                    phone_message,
                    waiting_sticker_message,
                    parse_mode=ParseMode.HTML
                )
                await save_chat_message(user_id, "assistant", phone_message)
                return

        elif phase4_state == "waiting_phone":
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ ID –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
            invalid_messages = state_data.get("phase4_invalid_messages", [])

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–∞: 8 –•–•–• –•–•–• –•–•–•–• –∏–ª–∏ +7 –•–•–• –•–•–• –•–•–•–•
            phone_pattern = r"^(\+?7|8)[\s\-\(]?(\d{3})[\s\-\)]?(\d{3})[\s\-]?(\d{2})[\s\-]?(\d{2})$"
            match = re.match(phone_pattern, user_q.strip())

            if match:
                # –¢–µ–ª–µ—Ñ–æ–Ω –≤–∞–ª–∏–¥–µ–Ω - –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ñ–æ—Ä–º–∞—Ç
                phone = re.sub(r"[\s\-\(\)]", "", user_q.strip())
                if phone.startswith("8"):
                    phone = "+7" + phone[1:]
                elif not phone.startswith("+7"):
                    phone = "+7" + phone

                await update_user_profile(user_id, phone=phone)
                logger.info(f"–ü–æ–ª—É—á–µ–Ω —Ç–µ–ª–µ—Ñ–æ–Ω: {phone}")

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞
                phone_waiting_sticker = await _send_waiting_sticker(message)

                # –£–¥–∞–ª—è–µ–º –≤—Å–µ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞) –ø–µ—Ä–µ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ–º
                if invalid_messages and message and message.chat:
                    for msg_id in invalid_messages:
                        try:
                            await message.bot.delete_message(chat_id=message.chat.id, message_id=msg_id)
                            logger.info(f"–£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id} –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                        except Exception as e:
                            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id}: {e}")

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel –ø–æ—Å–ª–µ –∑–∞–ø–∏—Å–∏ Name –∏ Phone
                profile = await get_user_profile(user_id)
                if profile and (profile.status or "").strip() in ("–û–±—É—á–µ–Ω–∏–µ", "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"):
                    try:
                        from ..db.leads_excel import save_lead_to_excel
                        logger.info(f"üîÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} (–ö–æ–Ω—Ç–∞–∫—Ç, Name –∏ Phone –∑–∞–ø–∏—Å–∞–Ω—ã)")
                        await save_lead_to_excel(profile, profile.name_sys or "")
                        logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ª–∏–¥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Excel: —Å—Ç–∞—Ç—É—Å='{profile.status}'")
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Excel: {e}", exc_info=True)

                # –ó–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–ø–∏—Å—å
                await state.update_data(
                    phase=1,
                    phase4_state=None,
                    phase4_window_shown=False,
                    phase4_invalid_messages=[]
                )
                completion_message = (
                    "ü§ù–†–∞–¥ –∑–Ω–∞–∫–æ–º—Å—Ç–≤—É.\n"
                    "–í—Å–µ –í–∞—à–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, –ó–ê–ü–ò–°–¨ –ó–ê–í–ï–†–®–ï–ù–ê!\n"
                    "<b>–ñ–¥–∏—Ç–µ –Ω–∞—à–µ–≥–æ –∑–≤–æ–Ω–∫–∞</b> ‚òéÔ∏è\n‚ñ∂Ô∏è ... –∞ —è - —Å–Ω–æ–≤–∞ –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º."
                )
                await _answer_with_sticker_cleanup(
                    message,
                    completion_message,
                    phone_waiting_sticker,  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∏–∫–µ—Ä, –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–µ–ª–µ—Ñ–æ–Ω–∞
                    parse_mode=ParseMode.HTML
                )
                await save_chat_message(user_id, "assistant", completion_message)
                logger.info(f"–ó–∞–ø–∏—Å—å –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                return
            else:
                # –¢–µ–ª–µ—Ñ–æ–Ω –Ω–µ –≤–∞–ª–∏–¥–µ–Ω - —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
                if message and message.message_id:
                    invalid_messages.append(message.message_id)
                    await state.update_data(phase4_invalid_messages=invalid_messages)

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                retry_message = "üí§ –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ–ª–µ—Ñ–æ–Ω–∞!\n<b>–í–∞—à –ù–æ–º–µ—Ä —Ç–µ–ª–µ—Ñ–æ–Ω–∞?</b>\n(–≤ —Ñ–æ—Ä–º–∞—Ç–µ +7(8)...)"
                sent_message = await _answer_with_sticker_cleanup(
                    message,
                    retry_message,
                    waiting_sticker_message,
                    parse_mode=ParseMode.HTML
                )
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –æ—Ç–≤–µ—Ç–∞ –±–æ—Ç–∞ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è
                if sent_message and sent_message.message_id:
                    invalid_messages.append(sent_message.message_id)
                    await state.update_data(phase4_invalid_messages=invalid_messages)

                await save_chat_message(user_id, "assistant", retry_message)
                return

        # –ï—Å–ª–∏ –Ω–µ –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –æ–∂–∏–¥–∞–Ω–∏—è –∏–º–µ–Ω–∏/—Ç–µ–ª–µ—Ñ–æ–Ω–∞, –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –∏ LLM
        logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤ –§–∞–∑–µ 4 (–ó–∞–ø–∏—Å—å) - –ø–æ–∏—Å–∫ –∏ LLM –æ—Ç–∫–ª—é—á–µ–Ω—ã")
        await _delete_waiting_sticker(waiting_sticker_message)
        return

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –ï—Å–ª–∏ –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞
    # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –î–û–õ–ñ–ï–ù –≤—ã–±—Ä–∞—Ç—å –æ–¥–Ω—É –∏–∑ —Ç—Ä–µ—Ö –∫–Ω–æ–ø–æ–∫, –∏–Ω–∞—á–µ –æ–∫–Ω–æ –±—É–¥–µ—Ç –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è —Å–Ω–æ–≤–∞
    if state_data.get("intent_selection_shown") and current_phase == 1:
        logger.info(f"–û–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –µ–≥–æ —Å–Ω–æ–≤–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{user_q[:50]}'")
        if not message:
            logger.error("message is None –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è")
            await _delete_waiting_sticker(waiting_sticker_message)
            return
        try:
            await _show_intent_selection_window(message, state, waiting_sticker_message)
            return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ –æ—Ç–ø—Ä–∞–≤–∫—É –≤ LLM
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è: {e}", exc_info=True)
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
            await _delete_waiting_sticker(waiting_sticker_message)
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
            if message:
                try:
                    await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                except Exception as msg_error:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {msg_error}")
            return

    # –ï—Å–ª–∏ –±—ã–ª–∞ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å", –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
    # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∫–∞–∑–∞ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞
    if continue_button_pressed:
        logger.info(f"–ö–Ω–æ–ø–∫–∞ '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å' –±—ã–ª–∞ –Ω–∞–∂–∞—Ç–∞ - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –ø–æ—Å–ª–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
        await state.update_data(continue_button_pressed=False)
    else:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –§–∞–∑–µ 2 (–î–û –ø–æ–∏—Å–∫–∞ –∏ LLM)
        user_q_lower = user_q.lower()
        intent_keywords = [
            "–∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü", "–∑–∞–ø–∏—Å", "–ø–æ–∑–≤–æ–Ω", "–ø–µ—Ä–µ–∑–≤–æ–Ω",
            "—Å–≤—è–∑–∞—Ç—å—Å—è", "—Ö–æ—á—É", "–∂–µ–ª–∞—é", "–Ω–∞—á–∞—Ç—å", "—Ç—Ä–µ–Ω–∏–Ω–≥", "—Ä–µ—à–∏–ª", "—Ä–µ—à–µ–Ω"
        ]
        has_intent_keywords = any(kw in user_q_lower for kw in intent_keywords)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª–∞ –ª–∏ –Ω–∞–∂–∞—Ç–∞ –∫–Ω–æ–ø–∫–∞ "–ó–∞–ø–∏—Å–∞—Ç—å—Å—è"
        is_booking_button = user_q.strip() == "üìù –ó–∞–ø–∏—Å–∞—Ç—å—Å—è" or user_q.strip() == "–ó–∞–ø–∏—Å–∞—Ç—å—Å—è"

        logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏–π: user_q='{user_q}', has_intent_keywords={has_intent_keywords}, is_booking_button={is_booking_button}, current_phase={current_phase}, intent_selection_shown={state_data.get('intent_selection_shown')}")

        # –ï—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–ª–∏ –∫–Ω–æ–ø–∫–∞ "–ó–∞–ø–∏—Å–∞—Ç—å—Å—è" –≤ –§–∞–∑–µ 1 - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –ë–ï–ó –ø–æ–∏—Å–∫–∞ –∏ LLM
        if (has_intent_keywords or is_booking_button) and current_phase == 1 and not state_data.get("intent_selection_shown"):
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–µ—Ä–µ—Ö–æ–¥–∞ –∫ –§–∞–∑–µ 2 - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –±–µ–∑ –ø–æ–∏—Å–∫–∞ –∏ LLM")
            if not message:
                logger.error("message is None –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –ø–æ–∫–∞–∑–∞—Ç—å –æ–∫–Ω–æ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è")
                await _delete_waiting_sticker(waiting_sticker_message)
                return
            try:
                await _show_intent_selection_window(message, state, waiting_sticker_message)
                return  # –í—ã—Ö–æ–¥–∏–º, –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥—è –ø–æ–∏—Å–∫ –∏ –æ—Ç–ø—Ä–∞–≤–∫—É –≤ LLM
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∫–∞–∑–µ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è: {e}", exc_info=True)
                # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
                await _delete_waiting_sticker(waiting_sticker_message)
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ
                if message:
                    try:
                        await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
                    except Exception as msg_error:
                        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ: {msg_error}")
                return

    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞ ({input_mode}) –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {user_q[:50]}, —Ñ–∞–∑–∞: {current_phase}")

    try:
        stored_user_q = user_q if input_mode == "text" else f"[voice] {user_q}"
        await save_chat_message(user_id, "user", stored_user_q)
    except Exception as save_user_error:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {save_user_error}")

    # –Ø–≤–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–º—ã –∑–∞–ø—Ä–æ—Å–∞ –ø–µ—Ä–µ–¥ –ø–æ–∏—Å–∫–æ–º
    detected_topic, topic_confidence = classify_topic(user_q)
    logger.info(f"–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–º—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q[:50]}': —Ç–µ–º–∞={detected_topic}, —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å={topic_confidence:.2f}")

    purchase_keywords = ["–∫—É–ø", "–ø–æ–∫—É–ø", "–æ–ø–ª–∞—Ç", "—Å—Ç–æ–∏–º", "—Ü–µ–Ω–∞", "–ø–ª–∞—Ç"]
    purchase_inquiry = any(kw in user_q.lower() for kw in purchase_keywords)

    # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞)
    try:
        chat_history = await get_chat_history(user_id, limit=10)
    except Exception as history_error:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞: {history_error}")
        chat_history = []

    try:
        hits = search_store.search(user_q, top_k=5)
        logger.info(f"–ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É '{user_q}': –Ω–∞–π–¥–µ–Ω–æ {len(hits)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        if hits:
            school_sources = sum(1 for h in hits if h.source and h.source.startswith("1."))
            rules_sources = sum(1 for h in hits if h.source and h.source.startswith("2."))
            logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: –¢–µ–º–∞ 1 (—à–∫–æ–ª–∞)={school_sources}, –¢–µ–º–∞ 2 (–ø—Ä–∞–≤–∏–ª–∞)={rules_sources}, –≤—Å–µ–≥–æ={len(hits)}")

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–º—ã
        if hits and detected_topic != "unknown" and topic_confidence >= 0.4:
            filtered_hits = []
            for h in hits:
                if not h.source:
                    # –ï—Å–ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω, –æ—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    filtered_hits.append(h)
                    continue

                source = h.source
                # –ï—Å–ª–∏ —Ç–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ "school" - –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã 1.x_
                if detected_topic == "school":
                    if source.startswith("1."):
                        filtered_hits.append(h)
                    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –∏—Å–∫–ª—é—á–∞–µ–º —Ñ–∞–π–ª—ã 2.x_
                    elif topic_confidence < 0.7:
                        # –ü—Ä–∏ —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º, –Ω–æ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
                        filtered_hits.append(h)

                # –ï—Å–ª–∏ —Ç–µ–º–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ –∫–∞–∫ "rules" - –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã 2.x_
                elif detected_topic == "rules":
                    if source.startswith("2."):
                        filtered_hits.append(h)
                    # –ï—Å–ª–∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤—ã—Å–æ–∫–∞—è, –∏—Å–∫–ª—é—á–∞–µ–º —Ñ–∞–π–ª—ã 1.x_
                    elif topic_confidence < 0.7:
                        # –ü—Ä–∏ —Å—Ä–µ–¥–Ω–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –æ—Å—Ç–∞–≤–ª—è–µ–º, –Ω–æ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º
                        filtered_hits.append(h)

            # –ï—Å–ª–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –æ—Å—Ç–∞–ª–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
            if filtered_hits:
                # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º: —Å–Ω–∞—á–∞–ª–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –Ω—É–∂–Ω–æ–π —Ç–µ–º—ã, –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                prioritized_hits = []
                other_hits = []

                for h in filtered_hits:
                    if not h.source:
                        other_hits.append(h)
                        continue

                    if detected_topic == "school" and h.source.startswith("1."):
                        prioritized_hits.append(h)
                    elif detected_topic == "rules" and h.source.startswith("2."):
                        prioritized_hits.append(h)
                    else:
                        other_hits.append(h)

                # –û–±—ä–µ–¥–∏–Ω—è–µ–º: —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ, –ø–æ—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                hits = prioritized_hits + other_hits

                # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                hits = hits[:5]

                logger.info(f"–ü–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ '{detected_topic}': –æ—Å—Ç–∞–ª–æ—Å—å {len(hits)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
                if hits:
                    school_after = sum(1 for h in hits if h.source and h.source.startswith("1."))
                    rules_after = sum(1 for h in hits if h.source and h.source.startswith("2."))
                    logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: –¢–µ–º–∞ 1 (—à–∫–æ–ª–∞)={school_after}, –¢–µ–º–∞ 2 (–ø—Ä–∞–≤–∏–ª–∞)={rules_after}")
            else:
                # –ï—Å–ª–∏ –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ (–Ω–∞ —Å–ª—É—á–∞–π –æ—à–∏–±–∫–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏)
                logger.warning(f"–í—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–ª–∏—Å—å –¥–ª—è —Ç–µ–º—ã '{detected_topic}', –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")

    except Exception as search_error:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {search_error}", exc_info=True)
        await _answer_with_sticker_cleanup(message, "‚ö†Ô∏è –û–¥–Ω–∞–∫–æ, –ø—Ä–æ–∏–∑–æ—à–µ–ª —Å–∏—Å—Ç–µ–º–Ω—ã–π —Å–±–æ–π. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å/–æ—Ç–≤–µ—Ç.", waiting_sticker_message)
        return

    # –†–µ—Ä–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ –ø—Ä–æ–≥—Ä–∞–º–º—ã/–≤–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è
    try:
        norm_for_rerank = re.sub(r"\s+", " ", user_q.lower()).strip()
        general_training_phrases = [
            "–≤–∏–¥—ã –æ–±—É—á", "–ø—Ä–æ–≥—Ä–∞–º–º—ã –æ–±—É—á", "—Ñ–æ—Ä–º—ã –æ–±—É—á", "—Ç–∏–ø—ã –æ–±—É—á", "–≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–±—É—á",
            "—É—á–µ–±–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º", "—É—á–µ–±–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã",
            "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–±—É—á", "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–±—É—á–µ–Ω–∏—é",
            "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç", "–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–¥—É–∫—Ç—ã",
        ]
        is_general_programs = any(p in norm_for_rerank for p in general_training_phrases)
        if is_general_programs and hits:
            def _bonus(h):
                src = (h.source or "")
                if src.startswith("1.2_"):
                    return 1.0
                if src.startswith("1.4_"):
                    return -0.6
                return 0.0
            hits = sorted(hits, key=lambda h: (h.score + _bonus(h)), reverse=True)
            # –ñ–µ—Å—Ç–∫–∞—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è 1.4_ –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω 1.2_
            has_12 = any((h.source or "").startswith("1.2_") for h in hits)
            if has_12:
                hits = [h for h in hits if not (h.source or "").startswith("1.4_")]
    except Exception:
        pass

    # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ 1.2 –¥–ª—è —Ç–æ—á–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å"
    try:
        user_q_lower = user_q.lower().strip()
        if "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in user_q_lower and hits:
            # –ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç 1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è
            def _initial_course_priority(h):
                if h.source and "1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è" in h.source:
                    return 2.0  # –ë–æ–ª—å—à–æ–π –±–æ–Ω—É—Å –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ 1.2
                return 0.0

            hits = sorted(hits, key=lambda h: (h.score + _initial_course_priority(h)), reverse=True)
            logger.info(f"–ü—Ä–∏–æ—Ä–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–æ–∫—É–º–µ–Ω—Ç 1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å'")
    except Exception:
        pass

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Ä–µ–¥–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º—ã—Ö –≤ LLM, –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ" (1.1, 1.2, 1.3, 1.4)
    # –≠—Ç–æ –Ω—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –î–û —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤, —á—Ç–æ–±—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    # –í–ê–ñ–ù–û: –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞—á–∞–ª–æ —Å—Ç—Ä–æ–∫–∏ (startswith), –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ª–∏—á–∏–µ –ø–æ–¥—Å—Ç—Ä–æ–∫–∏, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ–ø—É—Ç–∞—Ç—å 2.1.1_ —Å 1.1_
    has_school_sources_in_llm = False
    school_sources_in_hits = []
    if hits:
        school_source_prefixes = ("1.1_", "1.2_", "1.3_", "1.4_")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 3 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞, –∫–æ—Ç–æ—Ä—ã–µ —Ä–µ–∞–ª—å–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è –≤ LLM
        hits_for_llm = hits[:3]
        school_sources_in_hits = [h.source for h in hits_for_llm if h.source and any(h.source.startswith(prefix) for prefix in school_source_prefixes)]

        # –ï—Å–ª–∏ –≤ —Ç–æ–ø-3 –µ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ", –≤—Å–µ–≥–¥–∞ –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if school_sources_in_hits:
            has_school_sources_in_llm = True
            logger.info(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '–û —à–∫–æ–ª–µ' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM: {school_sources_in_hits} - –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω")

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –¥–ª—è –ª—É—á—à–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    contexts = []
    for i, h in enumerate(hits[:3], 1):
        contexts.append(f"[–ò—Å—Ç–æ—á–Ω–∏–∫ {i}: {h.source}]\n{h.text}")

    # –î–ª—è –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∞–º –¥–æ–±–∞–≤–ª—è–µ–º —Å–≤–æ–¥–∫—É –∏–∑ 1.2 –≤ –Ω–∞—á–∞–ª–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤
    try:
        if 'is_general_programs' in locals() and is_general_programs:
            programs_file = os.path.join(STRUCTURED_DIR, "1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è_structured.txt")
            if os.path.exists(programs_file):
                with open(programs_file, "r", encoding="utf-8") as f:
                    txt = f.read()
                lines = []
                for block in txt.split("–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç "):
                    if "|" not in block:
                        continue
                    title_part = block.split("|", 1)[1]
                    title_clean = title_part.split("–†–∏—Å.")[0]
                    title_clean = title_clean.split("###")[0].strip()
                    if not title_clean:
                        continue
                    m_cost = re.search(r"—Å—Ç–æ–∏–º–æ—Å—Ç—å\s+([0-9\s]+\s*—Ä—É–±\.?(:?/—á–∞—Å)?)", block, re.IGNORECASE)
                    if m_cost:
                        lines.append(f"- {title_clean} ‚Äî {m_cost.group(1).strip()}")
                    else:
                        lines.append(f"- {title_clean}")
                if lines:
                    summary_ctx = "[–ò—Å—Ç–æ—á–Ω–∏–∫: 1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è_structured.txt]\n" + "\n".join(lines)
                    contexts.insert(0, summary_ctx)
    except Exception:
        pass

    # –ï—Å–ª–∏ —è–≤–Ω—ã–π –∑–∞–ø—Ä–æ—Å —Ü–µ–Ω—ã/—Å—Ç–æ–∏–º–æ—Å—Ç–∏, –¥–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–∞–π—Å –∏–∑ 1.2
    price_intent = any(kw in user_q.lower() for kw in [
        "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "—Ü–µ–Ω–∞", "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç", "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç –æ–±—É—á–µ–Ω–∏–µ",
        "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç –∫—É—Ä—Å", "–ø—Ä–∞–π—Å", "–æ–ø–ª–∞—Ç–∞", "—Ä—É–±", "—Ä—É–±.", "—Ä—É–±/—á–∞—Å"
    ])
    if price_intent:
        try:
            price_file = os.path.join(STRUCTURED_DIR, "1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è_structured.txt")
            if os.path.exists(price_file):
                with open(price_file, "r", encoding="utf-8") as f:
                    txt = f.read()
                import re as _re
                entries = []
                for block in txt.split("–°–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç "):
                    if "|" not in block or "—Å—Ç–æ–∏–º–æ—Å—Ç—å" not in block:
                        continue
                    title_part = block.split("|", 1)[1]
                    title_clean = title_part.split("–†–∏—Å.")[0]
                    title_clean = title_clean.split("###")[0].strip()
                    m_cost = _re.search(r"—Å—Ç–æ–∏–º–æ—Å—Ç—å\s+([0-9\s]+\s*—Ä—É–±\.?(:?/—á–∞—Å)?)", block, _re.IGNORECASE)
                    if title_clean and m_cost:
                        cost = m_cost.group(1).strip()
                        entries.append((title_clean, cost))
                if entries:
                    price_lines = [f"- {t} ‚Äî {c}" for t, c in entries]
                    price_context = "[–ò—Å—Ç–æ—á–Ω–∏–∫: 1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è_structured.txt]\n" + "\n".join(price_lines)
                    contexts.insert(0, price_context)
        except Exception:
            pass

    # –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –∏–∑ –ë–ó ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if not contexts:
        logger.warning(f"–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{user_q}'")
        await _answer_with_sticker_cleanup(message, "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å.", waiting_sticker_message)
        return

    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç —Å —É—á—ë—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞
    history_context = ""
    if chat_history:
        recent_history = chat_history[-5:] if len(chat_history) > 5 else chat_history
        history_lines = []
        for msg in recent_history:
            role_ru = "–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg["role"] == "user" else "–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
            history_lines.append(f"{role_ru}: {msg['content']}")
        history_context = "\n\n–ü—Ä–µ–¥—ã–¥—É—â–∏–π –¥–∏–∞–ª–æ–≥:\n" + "\n".join(history_lines) + "\n"

    prompt = f"""–ö–æ–Ω—Ç–µ–∫—Å—Ç—ã –∏–∑ –ë–∞–∑—ã –∑–Ω–∞–Ω–∏–π:

{chr(10).join([f"--- –ö–æ–Ω—Ç–µ–∫—Å—Ç {i+1} ---{chr(10)}{ctx}" for i, ctx in enumerate(contexts[:3])])}

{history_context}

–í–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞: {user_q}

–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è: –û—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∫–ª–∏–µ–Ω—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ü–†–ï–î–û–°–¢–ê–í–õ–ï–ù–ù–´–• –ö–û–ù–¢–ï–ö–°–¢–û–í. –°–ª–µ–¥—É–π —Å–∏—Å—Ç–µ–º–Ω–æ–º—É –ø—Ä–æ–º–ø—Ç—É (—Ç—ã –õ–µ–æ–Ω–∏–¥—ã—á, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —à–∫–æ–ª—ã –±–∏–ª—å—è—Ä–¥–∞ ¬´–ê–±—Ä–∏–∫–æ–ª—å¬ª). –ò—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ –≤—ã—à–µ. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ, —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ, –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ, –∫–∞–∫ –∂–∏–≤–æ–π —á–µ–ª–æ–≤–µ–∫."""

    logger.info(
        f"–û—Ç–ø—Ä–∞–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –≤ DeepSeek API. –î–ª–∏–Ω–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞: {len(prompt_config.SYSTEM_PROMPT)} —Å–∏–º–≤–æ–ª–æ–≤"
    )
    logger.debug(f"–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç: {prompt_config.SYSTEM_PROMPT[:200]}...")
    logger.debug(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø—Ä–æ–º–ø—Ç: {prompt[:300]}...")

    try:
        answer = await deepseek.chat_completion(
            messages=[{"role": "user", "content": prompt}],
            system_prompt=prompt_config.SYSTEM_PROMPT,
            temperature=prompt_config.TEMPERATURE,
            max_tokens=prompt_config.MAX_TOKENS,
        )
        logger.info(f"–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç DeepSeek: {answer[:100]}...")
        if not answer or len(answer.strip()) < 10:
            answer = contexts[0] if contexts else "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ DeepSeek API: {e}")
        answer = "\n\n".join(contexts[:2]) if contexts else "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."

    try:
        data = await state.get_data()
    except Exception as state_get_error:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ state: {state_get_error}")
        data = {}

    # ========== –û–ë–†–ê–ë–û–¢–ö–ê –§–ê–ó –û–ë–©–ï–ù–ò–Ø ==========

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç LLM –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ñ—Ä–∞–∑—ã –æ –Ω–∞—á–∞–ª–µ –∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–§–∞–∑–∞ 3)
    answer_lower = answer.lower() if answer else ""
    has_anketa_phrase = "–ø—Ä–æ–≤–µ–¥—ë–º –Ω–µ–±–æ–ª—å—à–æ–µ –∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ" in answer_lower or "–∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ" in answer_lower
    has_ready_phrase = "—è —Å–Ω–æ–≤–∞ –≥–æ—Ç–æ–≤ –∫ –≤–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º" in answer_lower or "—è –≥–æ—Ç–æ–≤ –∫ –≤–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º" in answer_lower

    # has_school_sources_in_llm —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤—ã—à–µ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ" –≤ —Ç–æ–ø-3
    # –ï—Å–ª–∏ –≤ —Ç–æ–ø-3 –µ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ" (1.1, 1.2, 1.3, 1.4), –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤—Å–µ–≥–¥–∞ –±–ª–æ–∫–∏—Ä—É–µ—Ç—Å—è

    # –ï—Å–ª–∏ LLM –Ω–∞—á–∞–ª –∞–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –§–∞–∑–µ 3
    # –ù–û –Ω–µ –ø–µ—Ä–µ—Ö–æ–¥–∏–º, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ç–æ–ª—å–∫–æ —á—Ç–æ –Ω–∞–∂–∞–ª "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å"
    continue_button_pressed = data.get("continue_button_pressed", False)
    if has_anketa_phrase and current_phase < 3 and not continue_button_pressed:
        await state.update_data(phase=3, anketa_started=True, anketa_question=1)
        logger.info(f"–ü–µ—Ä–µ—Ö–æ–¥ –∫ –§–∞–∑–µ 3 (–ê–Ω–∫–µ—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ) –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    elif continue_button_pressed:
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞
        await state.update_data(continue_button_pressed=False)

    # –ï—Å–ª–∏ LLM —Å–∫–∞–∑–∞–ª "–≥–æ—Ç–æ–≤ –∫ –≤–æ–ø—Ä–æ—Å–∞–º", –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –§–∞–∑–µ 1
    if has_ready_phrase:
        await state.update_data(phase=1)
        logger.info(f"–í–æ–∑–≤—Ä–∞—Ç –∫ –§–∞–∑–µ 1 –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

    # ========== –ö–û–ù–ï–¶ –û–ë–†–ê–ë–û–¢–ö–ò –§–ê–ó ==========

    user_lower = user_q.lower()

    # –°–ù–ê–ß–ê–õ–ê –æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–∞–ø—Ä–æ—Å –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–º
    # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ –æ–±—â–∏–µ –∑–∞–ø—Ä–æ—Å—ã –∏–∑ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
    # (–Ω–∞–ø—Ä–∏–º–µ—Ä, "—Ç—ã –∫—Ç–æ", "–∫—Ç–æ —Ç—ã", "–ø–æ–º–æ—â—å" –∏ —Ç.–¥.)
    excluded_general_queries = [
        "—Ç—ã –∫—Ç–æ", "–∫—Ç–æ —Ç—ã", "—á—Ç–æ —Ç—ã", "—á—Ç–æ —Ç–∞–∫–æ–µ —Ç—ã",
        "–ø–æ–º–æ—â—å", "–ø–æ–º–æ–≥–∏", "—á—Ç–æ —É–º–µ–µ—à—å", "—á—Ç–æ –º–æ–∂–µ—à—å",
        "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π", "–¥–æ–±—Ä–æ–µ",
        "–∫–∞–∫ –¥–µ–ª–∞", "–∫–∞–∫ –ø–æ–∂–∏–≤–∞–µ—à—å",
    ]
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ
    # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
    is_excluded_query = any(pattern in user_lower for pattern in excluded_general_queries)

    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç "—Ç—ã –∫—Ç–æ" –∏–ª–∏ "–∫—Ç–æ —Ç—ã" - –í–°–ï–ì–î–ê –±–ª–æ–∫–∏—Ä—É–µ–º
    # –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –¥—Ä—É–≥–∏—Ö —É—Å–ª–æ–≤–∏–π (—ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —á–∞—Å—Ç—å –±–æ–ª–µ–µ –¥–ª–∏–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞, –Ω–æ –≤—Å–µ —Ä–∞–≤–Ω–æ –±–ª–æ–∫–∏—Ä—É–µ–º)
    critical_excluded = ["—Ç—ã –∫—Ç–æ", "–∫—Ç–æ —Ç—ã"]
    if any(pattern in user_lower for pattern in critical_excluded):
        is_excluded_query = True
        logger.info(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê: –ó–∞–ø—Ä–æ—Å '{user_q}' —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏–π (<= 10 —Å–∏–º–≤–æ–ª–æ–≤) –∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ —Å–ª–æ–≤–∞
    if len(user_lower.strip()) <= 10 and is_excluded_query:
        # –£—Å–∏–ª–∏–≤–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –¥–ª—è –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
        words = user_lower.strip().split()
        excluded_words = ["—Ç—ã", "–∫—Ç–æ", "—á—Ç–æ", "–ø–æ–º–æ—â—å", "–ø–æ–º–æ–≥–∏", "–ø—Ä–∏–≤–µ—Ç", "–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π", "–¥–æ–±—Ä—ã–π", "–¥–æ–±—Ä–æ–µ", "–∫–∞–∫", "–¥–µ–ª–∞", "–ø–æ–∂–∏–≤–∞–µ—à—å", "—É–º–µ–µ—à—å", "–º–æ–∂–µ—à—å"]
        if all(w in excluded_words for w in words if len(w) > 1):
            is_excluded_query = True
            logger.info(f"–£—Å–∏–ª–µ–Ω–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")

    matched_corpus_from_alias = None

    # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (—Ç–µ—Ö–Ω–∏—á, —Ä–∞–∑–º–µ—Ä, —Ç—Ä–µ–±–æ–≤–∞–Ω, –∞–∫—Å–µ—Å, –æ–±–æ—Ä—É–¥) –Ω–∞–¥ –æ–±—â–∏–º–∏ (–ø—Ä–∞–≤–∏–ª–∞)
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
    # –ù–û: –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if not is_excluded_query:
        technical_keywords = ["—Ç–µ—Ö–Ω–∏—á", "—Ä–∞–∑–º–µ—Ä", "—Ç—Ä–µ–±–æ–≤–∞–Ω", "–∞–∫—Å–µ—Å", "–æ–±–æ—Ä—É–¥"]
        for kw in technical_keywords:
            if kw in user_lower and kw in PRIMARY_SOURCE_ALIASES:
                matched_corpus_from_alias = PRIMARY_SOURCE_ALIASES[kw]
                break

    # –ï—Å–ª–∏ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –Ω–µ—Ç, –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ
    # –ù–û: –¥–ª—è –æ–±—â–µ–≥–æ –∞–ª–∏–∞—Å–∞ "–ø—Ä–∞–≤–∏–ª–∞" —Ç—Ä–µ–±—É–µ–º –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
    # –ò –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º matched_corpus_from_alias –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    if not matched_corpus_from_alias and not is_excluded_query:
        for alias, file_name in PRIMARY_SOURCE_ALIASES.items():
            if alias in user_lower:
                # –î–ª—è –æ–±—â–µ–≥–æ –∞–ª–∏–∞—Å–∞ "–ø—Ä–∞–≤–∏–ª–∞" —Ç—Ä–µ–±—É–µ–º, —á—Ç–æ–±—ã —ç—Ç–æ –±—ã–ª–æ —á–∞—Å—Ç—å—é –∑–Ω–∞—á–∏–º–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                # (–Ω–µ –ø—Ä–æ—Å—Ç–æ —Å–ª—É—á–∞–π–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –≤ –∫–æ—Ä–æ—Ç–∫–æ–º –∑–∞–ø—Ä–æ—Å–µ)
                if alias == "–ø—Ä–∞–≤–∏–ª–∞":
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∑–∞–ø—Ä–æ—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–µ–Ω (–Ω–µ –º–µ–Ω–µ–µ 8 —Å–∏–º–≤–æ–ª–æ–≤)
                    # –∏–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥—Ä—É–≥–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏
                    if len(user_lower) < 8:
                        # –î–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç—Ä–µ–±—É–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                        rule_context_words = ["–∏–≥—Ä", "–∫–æ—Ä–æ–Ω–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥", "–±–∏–ª—å—è—Ä–¥"]
                        has_rule_context = any(word in user_lower for word in rule_context_words)
                        if not has_rule_context:
                            continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —ç—Ç–æ—Ç –∞–ª–∏–∞—Å –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                matched_corpus_from_alias = file_name
                break

    # –°–Ω–∞—á–∞–ª–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ–º rule_query –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
    # –ù–û: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–µ —Å—á–∏—Ç–∞–µ–º –µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–º –æ –ø—Ä–∞–≤–∏–ª–∞—Ö
    rule_query = False
    if not is_excluded_query:
        rule_query = is_rule_intent(user_q) or (
            matched_corpus_from_alias in RULE_PRIMARY_ALLOWED_SOURCES if matched_corpus_from_alias else False
        )
        if rule_query:
            logger.info(f"rule_query=True –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}': is_rule_intent={is_rule_intent(user_q)}, matched_corpus_from_alias={matched_corpus_from_alias}")
    else:
        logger.info(f"–ó–∞–ø—Ä–æ—Å '{user_q}' –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –ø–æ–∏—Å–∫–∞ –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º (–æ–±—â–∏–π –∑–∞–ø—Ä–æ—Å), is_excluded_query=True")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ hits –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª (2.x_), –¥–∞–∂–µ –µ—Å–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–º—ã –±—ã–ª–∞ "school"
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ –∑–∞–ø—Ä–æ—Å –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è, –Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –∫–∞–∫ "school"
    # –ù–û: –Ω–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º rule_query –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    has_rules_sources_in_hits = any(h.source and h.source.startswith("2.") for h in hits) if hits else False

    # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª –≤ hits, –Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –±—ã–ª–∞ "school", –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º rule_query
    # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –±—ã–ª –∏—Å–∫–ª—é—á–µ–Ω
    if has_rules_sources_in_hits and detected_topic == "school" and not is_excluded_query:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Å—Ä–µ–¥–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è
        has_technical_in_hits = any(
            h.source and "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è" in h.source
            for h in hits
        )
        if has_technical_in_hits:
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤ hits, —ç—Ç–æ —Ç–æ—á–Ω–æ –∑–∞–ø—Ä–æ—Å –ø–æ –ø—Ä–∞–≤–∏–ª–∞–º
            rule_query = True
            logger.info(f"–ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω rule_query=True: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤ hits –ø—Ä–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ 'school'")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤ –∑–∞–ø—Ä–æ—Å–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
    # –ï—Å–ª–∏ –µ—Å—Ç—å "–∫–æ—Ä–æ–Ω–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥" - –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
    specific_game_keywords = ["–∫–æ—Ä–æ–Ω–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–º–µ–∂–¥—É–Ω–∞—Ä–æ–¥", "–ø—Ä–∞–≤–∏–ª–∞ –∫–æ—Ä–æ–Ω–∞", "–∏–≥—Ä–µ –∫–æ—Ä–æ–Ω–∞"]
    has_specific_game = any(kw in user_lower for kw in specific_game_keywords)

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º allowed_sources –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –∏—Å–∫–ª—é—á–µ–Ω
    if is_excluded_query:
        allowed_sources = []
        logger.info(f"allowed_sources –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
    elif matched_corpus_from_alias and matched_corpus_from_alias in RULE_PRIMARY_ALLOWED_SOURCES:
        # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–æ–µ –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ –∏–≥—Ä—ã - –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        if has_specific_game:
            allowed_sources = [matched_corpus_from_alias]
        # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ - –∏—â–µ–º –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ø—Ä–∞–≤–∏–ª
        elif rule_query:
            allowed_sources = list(RULE_PRIMARY_ALLOWED_SOURCES)
        else:
            # –î–ª—è –¥—Ä—É–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è –æ–¥–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
            allowed_sources = [matched_corpus_from_alias]
    elif matched_corpus_from_alias:
        # –î–ª—è –¥—Ä—É–≥–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º—Å—è –æ–¥–Ω–∏–º –¥–æ–∫—É–º–µ–Ω—Ç–æ–º
        allowed_sources = [matched_corpus_from_alias]
    else:
        # –ï—Å–ª–∏ –Ω–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ PRIMARY_SOURCE_ALIASES, –Ω–æ –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ - –∏—â–µ–º –ø–æ –≤—Å–µ–º –¥–æ–∫—É–º–µ–Ω—Ç–∞–º –ø—Ä–∞–≤–∏–ª
        if rule_query:
            allowed_sources = list(RULE_PRIMARY_ALLOWED_SOURCES)
            logger.info(f"allowed_sources —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø—Ä–∞–≤–∏–ª –¥–ª—è rule_query=True")
        else:
            allowed_sources = []

    primary_sources_blocked = any(stop_word in user_lower for stop_word in STOP_WORDS_FOR_PRIMARY)
    candidate_sources: list[str] = []
    for alias, file_name in PRIMARY_SOURCE_ALIASES.items():
        if alias in user_lower:
            candidate_sources.append(file_name)
    for h in hits:
        if h.source:
            candidate_sources.append(h.source)
    candidate_sources = _unique_preserving(candidate_sources)
    if not candidate_sources and hits:
        first_src = hits[0].source
        if first_src:
            candidate_sources.append(first_src)
    main_source = candidate_sources[0] if candidate_sources else None

    # === –ë–ª–æ–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ===
    primary_sources = []
    allow_rule_button = False

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –î–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    if is_excluded_query:
        logger.info(f"–ñ–ï–°–¢–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê: –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∫–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –ó–ê–ü–†–ï–©–ï–ù–´ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
        primary_sources = []
        allow_rule_button = False
        stored_primary_sources = []
    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –î–ª—è –§–∞–∑ 3 –∏ 4 –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–ª–æ–∫–∏—Ä—É–µ–º –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –ø–æ–∫–∞–∑ –∫–Ω–æ–ø–∫–∏
    elif current_phase == 3 or current_phase == 4:
        logger.info(f"–ñ–ï–°–¢–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê: –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∫–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –ó–ê–ü–†–ï–©–ï–ù–´ –¥–ª—è –§–∞–∑—ã {current_phase}")
        primary_sources = []
        allow_rule_button = False
        stored_primary_sources = []
    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –ï—Å–ª–∏ –µ—Å—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ" –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM,
    # –ü–û–õ–ù–û–°–¢–¨–Æ –∑–∞–ø—Ä–µ—â–∞–µ–º –ø–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –ø–æ–∫–∞–∑ –∫–Ω–æ–ø–∫–∏ "–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫"
    # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ù–ï –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=False)
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=True), –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ "–û —à–∫–æ–ª–µ"
    elif has_school_sources_in_llm and not rule_query:
        logger.info(f"–ñ–ï–°–¢–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê: –ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏ –∫–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –ó–ê–ü–†–ï–©–ï–ù–´ –¥–ª—è —Ä–∞–∑–¥–µ–ª–∞ '–û —à–∫–æ–ª–µ' (rule_query=False)")
        primary_sources = []
        allow_rule_button = False
        stored_primary_sources = []
    else:
        try:
            # –µ—Å–ª–∏ –µ—Å—Ç—å –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ (–ø–æ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞–º) ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
            if primary_sources_blocked:
                allowed_sources = []

            # –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—å —á—Ç–æ-—Ç–æ —Ä–∞–∑—Ä–µ—à—ë–Ω–Ω–æ–µ ‚Äî —Å—Ç—Ä–æ–∏–º
            if allowed_sources:
                logger.info(f"–ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}' —Å allowed_sources={allowed_sources}")
                primary_sources = search_store.get_primary_source_fragments(
                    hits[:5],
                    user_q,
                    allowed_sources=allowed_sources,
                )
                logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(primary_sources)}")
                # –õ–æ–≥–∏—Ä—É–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                if primary_sources:
                    sources_in_fragments = set(f.get('source', '') for f in primary_sources if isinstance(f, dict))
                    logger.info(f"–ò—Å—Ç–æ—á–Ω–∏–∫–∏ –≤ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞—Ö: {sources_in_fragments}")
                    technical_fragments = [f for f in primary_sources if isinstance(f, dict) and '2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è' in f.get('source', '')]
                    logger.info(f"–§—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π: {len(technical_fragments)}")

                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –±—ã–ª –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤, –Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
                    if is_excluded_query:
                        logger.info(f"–ó–∞–ø—Ä–æ—Å '{user_q}' –±—ã–ª –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –æ–±—â–∏—Ö, –Ω–æ –Ω–∞–π–¥–µ–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã - –ø—Ä–æ–≤–µ—Ä—è–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å")
                        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã: –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                        # (–∏—Å–∫–ª—é—á–∞—è —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞)
                        query_words = [w for w in user_lower.split() if len(w) > 2 and w not in ["—Ç—ã", "–∫—Ç–æ", "—á—Ç–æ", "–∫–∞–∫", "–≥–¥–µ", "–∫–æ–≥–¥–∞", "—ç—Ç–æ", "–¥–ª—è", "–ø—Ä–∏", "–Ω–∞–¥", "–ø–æ–¥"]]
                        if query_words:
                            relevant_fragments = []
                            for frag in primary_sources:
                                if isinstance(frag, dict):
                                    frag_text = (frag.get('text', '') or '').lower()
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–∏–º–æ–µ —Å–ª–æ–≤–æ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
                                    if any(word in frag_text for word in query_words):
                                        relevant_fragments.append(frag)
                            if not relevant_fragments:
                                logger.info(f"–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã –∑–∞–ø—Ä–æ—Å—É '{user_q}' - –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É")
                                primary_sources = []
                                allow_rule_button = False
                            else:
                                primary_sources = relevant_fragments
                                logger.info(f"–û—Å—Ç–∞–≤–ª–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(primary_sources)}")
                        else:
                            # –ï—Å–ª–∏ –Ω–µ—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ –≤ –∑–∞–ø—Ä–æ—Å–µ - –±–ª–æ–∫–∏—Ä—É–µ–º
                            logger.info(f"–ó–∞–ø—Ä–æ—Å '{user_q}' –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–Ω–∞—á–∏–º—ã—Ö —Å–ª–æ–≤ - –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É")
                            primary_sources = []
                            allow_rule_button = False

                    allow_rule_button = bool(primary_sources)
                    if primary_sources:
                        logger.info(f"allow_rule_button —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ True –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}', –Ω–∞–π–¥–µ–Ω–æ {len(primary_sources)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤")
                    # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏, –Ω–æ –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ - –ø—Ä–æ–±—É–µ–º –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
                    if not primary_sources and rule_query and not primary_sources_blocked:
                        logger.info(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
                        primary_sources = search_store.get_primary_source_fragments(
                            hits[:5],
                            user_q,
                        )
                        logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π: {len(primary_sources)}")
                        allow_rule_button = bool(primary_sources)
                # –µ—Å–ª–∏ –Ω–µ –±—ã–ª–æ —Å—Ç–æ–ø-—Å–ª–æ–≤, –Ω–æ —É –Ω–∞—Å –≤–æ–æ–±—â–µ –Ω–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π ‚Äî –ø—Ä–æ–±—É–µ–º –ø—Ä–æ—Å—Ç–æ –ø–æ hits
                # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ –±—ã–ª –∏—Å–∫–ª—é—á–µ–Ω –∏–∑ –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
                elif not primary_sources_blocked and rule_query and not is_excluded_query:
                    logger.info(f"–ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}' –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π (rule_query=True)")
                    primary_sources = search_store.get_primary_source_fragments(
                        hits[:5],
                        user_q,
                    )
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {len(primary_sources)}")
                    allow_rule_button = bool(primary_sources)
                elif is_excluded_query:
                    logger.info(f"–ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∏—Å–∫–ª—é—á–µ–Ω–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
                    primary_sources = []
                    allow_rule_button = False
                # –µ—Å–ª–∏ –∏–Ω–∞—á–µ ‚Äî –≤—Å—ë –ø—É—Å—Ç–æ
                else:
                    logger.info(f"–ü–æ–∏—Å–∫ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
        except Exception as primary_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {primary_error}", exc_info=True)
            primary_sources = []
            allow_rule_button = False

    fragment_sources: set[str] = {
        fr.get("source") for fr in primary_sources if isinstance(fr, dict) and fr.get("source")
    }
    logger.info(f"fragment_sources –ø–æ—Å–ª–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–∑ primary_sources: {fragment_sources}, primary_sources count: {len(primary_sources)}")
    if not fragment_sources and main_source:
        fragment_sources = {main_source}
        logger.info(f"fragment_sources —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ main_source: {fragment_sources}")

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ fragment_sources –ø—É—Å—Ç, –Ω–æ –≤ hits –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª (2.x_)
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (2.2), –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã
    if not fragment_sources and hits:
        rules_sources_in_hits = {h.source for h in hits if h.source and h.source in RULE_PRIMARY_ALLOWED_SOURCES}
        if rules_sources_in_hits:
            fragment_sources = rules_sources_in_hits
            logger.info(f"fragment_sources —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ hits (–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø—Ä–∞–≤–∏–ª): {fragment_sources}")
            # –ï—Å–ª–∏ main_source –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –µ–≥–æ –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            if not main_source:
                main_source = list(rules_sources_in_hits)[0]
                logger.info(f"main_source —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ fragment_sources: {main_source}")

    # –ï—Å–ª–∏ fragment_sources –≤—Å–µ –µ—â–µ –ø—É—Å—Ç, –Ω–æ –µ—Å—Ç—å primary_sources –∏ allowed_sources - –∏—Å–ø–æ–ª—å–∑—É–µ–º allowed_sources
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –∏–º–µ—é—Ç –ø–æ–ª—è "source"
    if not fragment_sources and primary_sources and allowed_sources:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ allowed_sources, –∫–æ—Ç–æ—Ä—ã–π –µ—Å—Ç—å –≤ RULE_PRIMARY_ALLOWED_SOURCES
        for src in allowed_sources:
            if src in RULE_PRIMARY_ALLOWED_SOURCES:
                fragment_sources = {src}
                if not main_source:
                    main_source = src
                logger.info(f"fragment_sources —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ allowed_sources: {fragment_sources} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
                break

    # –ï—Å–ª–∏ fragment_sources –≤—Å–µ –µ—â–µ –ø—É—Å—Ç, –Ω–æ –µ—Å—Ç—å primary_sources - –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ hits
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –∏–º–µ—é—Ç –ø–æ–ª—è "source"
    if not fragment_sources and primary_sources and rule_query:
        logger.info(f"fragment_sources –ø—É—Å—Ç, –Ω–æ –µ—Å—Ç—å primary_sources, –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ hits")
        for h in hits[:5]:
            if h.source and h.source in RULE_PRIMARY_ALLOWED_SOURCES:
                fragment_sources.add(h.source)
                if not main_source:
                    main_source = h.source
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ {h.source} –∏–∑ hits –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
                break

    # –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –µ—Å—Ç—å hits –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∞–≤–∏–ª - –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ —Ç–∏–ø–∞ "–æ–±–æ—Ä—É–¥" –∏ "–∞–∫—Å–µ—Å"
    if not fragment_sources and rule_query:
        for h in hits[:5]:
            if h.source and h.source in RULE_PRIMARY_ALLOWED_SOURCES:
                fragment_sources.add(h.source)
                if not main_source:
                    main_source = h.source
                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ {h.source} –∏–∑ hits –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
                break

    if not rule_query and fragment_sources:
        if any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
            rule_query = True

    logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π: allow_rule_button={allow_rule_button}, rule_query={rule_query}, fragment_sources={fragment_sources}, allowed_sources={allowed_sources}")

    # –ï—Å–ª–∏ –≤ LLM –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ", –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É
    # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ù–ï –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=False)
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=True), –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ "–û —à–∫–æ–ª–µ"
    if has_school_sources_in_llm and not rule_query:
        allow_rule_button = False
        primary_sources = []
        logger.info(f"–ö–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '–û —à–∫–æ–ª–µ' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM (rule_query=False)")

    if allow_rule_button:
        # –ï—Å–ª–∏ fragment_sources –ø—É—Å—Ç, –Ω–æ –µ—Å—Ç—å allowed_sources - –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö
        if not fragment_sources and allowed_sources:
            for src in allowed_sources:
                if src in RULE_PRIMARY_ALLOWED_SOURCES:
                    fragment_sources = {src}
                    logger.info(f"fragment_sources —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏–∑ allowed_sources –≤ –ø—Ä–æ–≤–µ—Ä–∫–µ: {fragment_sources}")
                    break

        # –ï—Å–ª–∏ fragment_sources –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ –ø—Ä–∞–≤–∏–ª, –ø—Ä–æ–≤–µ—Ä—è–µ–º hits
        if not fragment_sources or not any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª –≤ hits
            # –≠—Ç–æ –≤–∞–∂–Ω–æ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π (2.2) –∏ –¥—Ä—É–≥–∏—Ö —Å–ª—É—á–∞–µ–≤
            rules_sources_in_hits = [h.source for h in hits if h.source and h.source in RULE_PRIMARY_ALLOWED_SOURCES]
            if rules_sources_in_hits:
                # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–∑ –ø—Ä–∞–≤–∏–ª –≤ hits, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ fragment_sources
                fragment_sources = set(rules_sources_in_hits)
                logger.info(f"fragment_sources –æ–±–Ω–æ–≤–ª–µ–Ω –∏–∑ hits: {fragment_sources}")
                # –¢–∞–∫–∂–µ –æ–±–Ω–æ–≤–ª—è–µ–º rule_query, –µ—Å–ª–∏ –æ–Ω –±—ã–ª False
                if not rule_query:
                    rule_query = True
                    logger.info(f"rule_query –æ–±–Ω–æ–≤–ª–µ–Ω –Ω–∞ True –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ hits")
                # –ï—Å–ª–∏ primary_sources –ø—É—Å—Ç, –Ω–æ rule_query=True, —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–Ω–æ–ø–∫—É
                if not primary_sources and rule_query:
                    allow_rule_button = True
                    logger.info(f"allow_rule_button —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ True –¥–ª—è rule_query=True, –¥–∞–∂–µ –µ—Å–ª–∏ primary_sources –ø—É—Å—Ç")
            elif not rule_query:
                logger.warning(f"–ö–Ω–æ–ø–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞: fragment_sources {fragment_sources} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ RULE_PRIMARY_ALLOWED_SOURCES –∏ –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ hits, rule_query=False")
                allow_rule_button = False
                primary_sources = []
                allowed_sources = []

        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ rule_query=True –∏ –µ—Å—Ç—å fragment_sources –∏–∑ –ø—Ä–∞–≤–∏–ª, —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–Ω–æ–ø–∫—É
        if rule_query and fragment_sources and any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
            if not allow_rule_button:
                allow_rule_button = True
                logger.info(f"allow_rule_button —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –≤ True –¥–ª—è rule_query=True —Å fragment_sources={fragment_sources}")

        if allow_rule_button and not any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
            logger.warning(f"–ö–Ω–æ–ø–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞: fragment_sources {fragment_sources} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ RULE_PRIMARY_ALLOWED_SOURCES")
            allow_rule_button = False
            primary_sources = []
            allowed_sources = []
        elif allow_rule_button and not rule_query:
            logger.warning(f"–ö–Ω–æ–ø–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞: rule_query={rule_query} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}'")
            allow_rule_button = False
            primary_sources = []
            allowed_sources = []
        elif allow_rule_button:
            logger.info(f"–ö–Ω–æ–ø–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∞: allow_rule_button={allow_rule_button}, rule_query={rule_query}, fragment_sources={fragment_sources}")
    # –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –ø—Ä–∞–≤–∏–ª–∞–º–∏ –∏ –µ—Å—Ç—å hits –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∞–≤–∏–ª - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É
    # –ù–û: –Ω–µ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫, –µ—Å–ª–∏ –≤ LLM –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ"
    if not allow_rule_button and rule_query and fragment_sources and not has_school_sources_in_llm:
        if any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
            # –ü—Ä–æ–±—É–µ–º –µ—â–µ —Ä–∞–∑ –Ω–∞–π—Ç–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π
            if not primary_sources and not primary_sources_blocked:
                logger.info(f"–ü–æ–≤—Ç–æ—Ä–Ω—ã–π –ø–æ–∏—Å–∫ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{user_q}' –±–µ–∑ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π")
                primary_sources = search_store.get_primary_source_fragments(
                    hits[:5],
                    user_q,
                )
                if primary_sources:
                    allow_rule_button = True
                    logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –ø–æ–∏—Å–∫–µ: {len(primary_sources)}")
                else:
                    # –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ –µ—Å—Ç—å hits –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø—Ä–∞–≤–∏–ª -
                    # —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–≤–æ–≥–æ hit
                    for h in hits[:5]:
                        if h.source and h.source in RULE_PRIMARY_ALLOWED_SOURCES:
                            logger.info(f"–°–æ–∑–¥–∞–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ hit –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {h.source}, –∑–∞–ø—Ä–æ—Å '{user_q}'")
                            # –°–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –ø–æ–∫–∞–∑–∞ –∫–Ω–æ–ø–∫–∏
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ–∫—Å—Ç –∏–∑ hit, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
                            hit_text = ""
                            if hasattr(h, 'text') and h.text:
                                hit_text = h.text[:500]
                            elif hasattr(h, 'content') and h.content:
                                hit_text = h.content[:500]

                            primary_sources = [{
                                "source": h.source,
                                "text": hit_text,
                                "section": "",
                                "_position": 0
                            }]
                            allow_rule_button = True
                            fragment_sources = {h.source}
                            if not main_source:
                                main_source = h.source
                            logger.info(f"–§—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω, allow_rule_button={allow_rule_button}, fragment_sources={fragment_sources}")
                            break

    if allow_rule_button:
        # –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É, –µ—Å–ª–∏ "–ø—Ä–∞–≤–∏–ª–∞" –µ—Å—Ç—å, –∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–≥—Ä—ã –Ω–µ—Ç (–¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ 2.1.x)
        # –ù–û: –µ—Å–ª–∏ –≤ fragment_sources –µ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è (2.2), —Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–≥—Ä—É –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è
        # –ò–õ–ò: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç "–æ–±–æ—Ä—É–¥" –∏–ª–∏ "–∞–∫—Å–µ—Å", —Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–≥—Ä—É –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è
        # –ò–õ–ò: –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –±–∏–ª—å—è—Ä–¥–∞, —Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–≥—Ä—É –Ω–µ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è
        TECHNICAL_REQUIREMENTS_SOURCE = "2.2_–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –±–∏–ª—å—è—Ä–¥–Ω—ã–º —Å—Ç–æ–ª–∞–º –∏ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é –§–ë–°–†_structured.txt"
        has_technical_requirements = TECHNICAL_REQUIREMENTS_SOURCE in fragment_sources
        is_equipment_query = "–æ–±–æ—Ä—É–¥" in user_lower or "–∞–∫—Å–µ—Å" in user_lower

        # –ë–∞–∑–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –±–∏–ª—å—è—Ä–¥–∞, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —Ç—Ä–µ–±—É—é—Ç —É–∫–∞–∑–∞–Ω–∏—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∏–≥—Ä—ã
        # –≠—Ç–∏ —Ç–µ—Ä–º–∏–Ω—ã —è–≤–ª—è—é—Ç—Å—è –æ–±—â–∏–º–∏ –¥–ª—è –≤—Å–µ—Ö –∏–≥—Ä –∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç —É—Ç–æ—á–Ω–µ–Ω–∏—è
        BASIC_BILLIARD_TERMS = (
            "–±–∏—Ç–æ–∫", "–±–∏—Ç", "–ø—Ä–∏—Ü–µ–ª", "–ø—Ä–∏—Ü–µ–ª—å–Ω", "—à–∞—Ä", "—à–∞—Ä—ã", "—à–∞—Ä–∏–∫", "—à–∞—Ä–∏–∫–∏",
            "—à—Ç—Ä–∞—Ñ", "–Ω–∞—Ä—É—à–µ–Ω", "—É–¥–∞—Ä", "—É–¥–∞—Ä–∞", "–∫–∏–π", "–∫–∏–µ–º", "—Å—Ç–æ–ª",
            "–ª—É–∑–∞", "–ª—É–∑—ã", "–±–æ—Ä—Ç", "–±–æ—Ä—Ç–∞", "—Ä–∞–∑–º–µ—Ç–∫", "—Ä–∞–∑–º–µ—Ç–∫–∞"
        )
        is_basic_term_query = any(term in user_lower for term in BASIC_BILLIARD_TERMS)

        if not has_technical_requirements and not is_equipment_query and not is_basic_term_query:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∏–≥—Ä—É –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –ò –∑–∞–ø—Ä–æ—Å –Ω–µ –ø—Ä–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ/–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã –ò –Ω–µ —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            RULE_DISCIPLINE_HINTS = (
                "–∫–æ—Ä–æ–Ω–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "—Å–≤–æ–±–æ–¥–Ω–∞—è", "–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è", "–¥–∏–Ω–∞–º–∏—á–Ω–∞—è", "–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è",
                "71 –æ—á–∫–æ", "51 –æ—á–∫–æ", "8 –æ—á–∫–æ–≤"
            )
            game_required_sources = RULE_PRIMARY_ALLOWED_SOURCES - {
                TECHNICAL_REQUIREMENTS_SOURCE,
            }
            requires_game_hint = any(src in game_required_sources for src in fragment_sources)
            if requires_game_hint:
                no_game = not any(hint in user_lower for hint in RULE_DISCIPLINE_HINTS)
                if is_rule_intent(user_q) and no_game:
                    logger.warning(f"–ö–Ω–æ–ø–∫–∞ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞: —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–∫–∞–∑–∞–Ω–∏–µ –∏–≥—Ä—ã –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ {fragment_sources}")
                    allow_rule_button = False
                else:
                    logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–≥—Ä—ã –ø—Ä–æ–π–¥–µ–Ω–∞: requires_game_hint={requires_game_hint}, no_game={no_game}")
        else:
            if has_technical_requirements:
                logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–≥—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–∞: –µ—Å—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤ fragment_sources {fragment_sources}")
            if is_equipment_query:
                logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–≥—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–∞: –∑–∞–ø—Ä–æ—Å –ø—Ä–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ/–∞–∫—Å–µ—Å—Å—É–∞—Ä—ã '{user_q}'")
            if is_basic_term_query:
                logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏–≥—Ä—ã –ø—Ä–æ–ø—É—â–µ–Ω–∞: –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –±–∞–∑–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –±–∏–ª—å—è—Ä–¥–∞ '{user_q}'")

    focused_fragments = primary_sources[:1] if primary_sources else []

    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏–º —Ä–∏—Å—É–Ω–∫–∏ –≤ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞—Ö
    used_hits = hits[:3] if len(hits) > 3 else hits
    figures_found = []
    forced_figures: set[str] = set()

    try:
        for hit in used_hits:
            if hit.figures:
                for fig in hit.figures.split(","):
                    fig = fig.strip()
                    if fig:
                        # –†–∏—Å.1.2.1 –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å"
                        if fig == "–†–∏—Å.1.2.1":
                            if answer and "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer.lower():
                                figures_found.append(fig)
                        else:
                            figures_found.append(fig)

        figures_in_answer = image_mapper.find_figures_in_text(answer) if answer else []
        figures_in_question = image_mapper.find_figures_in_text(user_q) if user_q else []
        for fig in figures_in_question:
            forced_figures.add(fig)

        # –§–∏–ª—å—Ç—Ä—É–µ–º –†–∏—Å.1.2.1 –∏–∑ figures_in_answer - –æ–Ω –¥–æ–ª–∂–µ–Ω –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å"
        # –ù–û –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –µ–≥–æ, –µ—Å–ª–∏ –æ–Ω –Ω–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ find_figures_in_text (—Ç.–µ. —Ç–æ–ª—å–∫–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ "–†–∏—Å.1.2.1" –≤ —Ç–µ–∫—Å—Ç–µ)
        # –†–∏—Å.1.2.1 –¥–æ–ª–∂–µ–Ω –¥–æ–±–∞–≤–ª—è—Ç—å—Å—è —Ç–æ–ª—å–∫–æ —á–µ—Ä–µ–∑ —è–≤–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞–ª–∏—á–∏—è —Ñ—Ä–∞–∑—ã "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" –≤ –æ—Ç–≤–µ—Ç–µ
        filtered_figures_in_answer = []
        for fig in figures_in_answer:
            if fig == "–†–∏—Å.1.2.1":
                # –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –†–∏—Å.1.2.1 –∏–∑ figures_in_answer - –æ–Ω –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –ø–æ–∑–∂–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å"
                # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –†–∏—Å.1.2.1, –µ—Å–ª–∏ –æ–Ω –Ω–∞–π–¥–µ–Ω —Ç–æ–ª—å–∫–æ –ø–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—é –≤ —Ç–µ–∫—Å—Ç–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏)
                pass
            else:
                filtered_figures_in_answer.append(fig)

        figures_found.extend(filtered_figures_in_answer)
        figures_found.extend(figures_in_question)
    except Exception as e:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–∏—Å—É–Ω–∫–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ: {e}")

    lowered_q = user_lower

    # –†–∏—Å—É–Ω–∫–∏ –¥–ª—è –ö–æ—Ä–æ–Ω–∞ –∏ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π —Ç–µ–ø–µ—Ä—å –æ–ø—Ä–µ–¥–µ–ª—è—é—Ç—Å—è –ø—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ –æ–∫–Ω–∞ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞
    # –∏ –Ω–µ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –≤ figures_found –∑–¥–µ—Å—å

    figures_found = _unique_preserving(figures_found + list(forced_figures))

    blocked_figures: set[str] = set()
    if re.search(r"—Ä–∞–∑–º\w*\s+–ª—É–∑", lowered_q):
        blocked_figures.add("–†–∏—Å.2.2.5")

    if blocked_figures:
        figures_found = [fig for fig in figures_found if fig not in blocked_figures]
        forced_figures.difference_update(blocked_figures)

    question_keywords = {w for w in re.findall(r"\w+", user_q.lower()) if len(w) >= 3}
    all_keywords = set(question_keywords)
    stop_keywords = {"—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç—ã"}
    all_keywords = {w for w in all_keywords if w not in stop_keywords}

    # –û—Å—Ç–∞–ª—å–Ω—ã–µ —Ñ—Ä–∞–∑—ã –ø—Ä–æ–≤–µ—Ä—è—é—Ç—Å—è –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    course_figures_user_query = {
        "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å": "–†–∏—Å.1.2.1",
        "–∫1": "–†–∏—Å.1.2.1",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç 1": "–†–∏—Å.1.2.1",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∫1": "–†–∏—Å.1.2.1",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ1": "–†–∏—Å.1.2.1",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 1": "–†–∏—Å.1.2.1",
        "–±–∞–∑–æ–≤—ã–π –∫—É—Ä—Å": "–†–∏—Å.1.2.2",
        "–∫2": "–†–∏—Å.1.2.2",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç 2": "–†–∏—Å.1.2.2",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∫2": "–†–∏—Å.1.2.2",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ2": "–†–∏—Å.1.2.2",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 2": "–†–∏—Å.1.2.2",
        "—ç–∫—Å–ø—Ä–µ—Å—Å": "–†–∏—Å.1.2.3",
        "–∫3": "–†–∏—Å.1.2.3",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç 3": "–†–∏—Å.1.2.3",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∫3": "–†–∏—Å.1.2.3",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ3": "–†–∏—Å.1.2.3",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 3": "–†–∏—Å.1.2.3",
        "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω": "–†–∏—Å.1.2.4",
        "—Ç1": "–†–∏—Å.1.2.4",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç —Ç1": "–†–∏—Å.1.2.4",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ4": "–†–∏—Å.1.2.4",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 4": "–†–∏—Å.1.2.4",
        "—Ç—Ä–µ–Ω–∏–Ω–≥": "–†–∏—Å.1.2.5",
        "—É1": "–†–∏—Å.1.2.5",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç —É1": "–†–∏—Å.1.2.5",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ5": "–†–∏—Å.1.2.5",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 5": "–†–∏—Å.1.2.5",
        "–∞–±–æ–Ω–µ–º–µ–Ω—Ç": "–†–∏—Å.1.2.6",
        "–º–∞—Å—Ç–µ—Ä": "–†–∏—Å.1.2.6",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∞1": "–†–∏—Å.1.2.6",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ6": "–†–∏—Å.1.2.6",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 6": "–†–∏—Å.1.2.6",
        "—é–Ω–∏–æ—Ä": "–†–∏—Å.1.2.7",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∞2": "–†–∏—Å.1.2.7",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ7": "–†–∏—Å.1.2.7",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 7": "–†–∏—Å.1.2.7",
        "–ø—Ä–æ—Ñ–∏": "–†–∏—Å.1.2.8",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç –∞3": "–†–∏—Å.1.2.8",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ8": "–†–∏—Å.1.2.8",
        "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç ‚Ññ 8": "–†–∏—Å.1.2.8",
    }
    course_figure_selected = False
    course_selected_figures: set[str] = set()
    # –ü–†–ò–û–†–ò–¢–ï–¢–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" (–ù–ï "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä"),
    # —Ç–æ –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Å—É–Ω–∫–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∞ —Å—Ä–∞–∑—É —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–ª–∞–≥ –¥–ª—è –†–∏—Å.1.2.1
    has_initial_course_in_answer = False
    if answer and isinstance(answer, str):
        answer_lower = answer.lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–ß–ù–£–Æ —Ñ—Ä–∞–∑—É "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" (–Ω–µ "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä")
        has_initial_course_phrase = "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer_lower
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ù–ï –ø—Ä–æ –ø—Ä–∞–≤–∏–ª–∞ (–Ω–µ—Ç "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä")
        has_initial_strike = "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä" in answer_lower
        has_initial_course_in_answer = has_initial_course_phrase and not has_initial_strike and has_school_sources_in_llm

        if has_initial_course_in_answer:
            logger.info(f"‚úÖ –û–ë–ù–ê–†–£–ñ–ï–ù '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ LLM - –±–ª–æ–∫–∏—Ä—É–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥—Ä—É–≥–∏—Ö —Ä–∏—Å—É–Ω–∫–æ–≤ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∏—Å—É–Ω–∫–∏ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –Ω–µ—Ç "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" –≤ –æ—Ç–≤–µ—Ç–µ LLM
    if not has_initial_course_in_answer:
        for phrase, fig_key in course_figures_user_query.items():
            if phrase in user_q.lower():
                figures_found.append(fig_key)
                course_figure_selected = True
                course_selected_figures.add(fig_key)

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: –†–∏—Å.1.2.1 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –∫–æ–≥–¥–∞:
    # 1. –í –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å –¢–û–ß–ù–ê–Ø —Ñ—Ä–∞–∑–∞ "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" (–ù–ï "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä")
    # 2. –ò —ç—Ç–æ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ä–∞–∑–¥–µ–ª—É "–û —à–∫–æ–ª–µ" (has_school_sources_in_llm = True)
    # 3. –ò –Ω–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–≤–∏–ª (—É–¥–∞—Ä, –±–∏—Ç–æ–∫ –∏ —Ç.–¥.)
    # 4. –ü—Ä–∏ –ø–æ–∫–∞–∑–µ –†–∏—Å.1.2.1 –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏ (–≤–∫–ª—é—á–∞—è 1.2.2, 1.2.3) –ù–ï –ø–æ–∫–∞–∑—ã–≤–∞—é—Ç—Å—è
    if answer and has_school_sources_in_llm:
        answer_lower = answer.lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–ß–ù–£–Æ —Ñ—Ä–∞–∑—É "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
        has_initial_course_phrase = "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer_lower
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –ù–ï "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä" –∏–∑ –ø—Ä–∞–≤–∏–ª
        has_initial_strike = "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä" in answer_lower

        # –†–∏—Å.1.2.1 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" –ò –ù–ï–¢ "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä"
        if has_initial_course_phrase and not has_initial_strike:
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –Ω–µ –¥–æ–±–∞–≤–ª—è–µ–º, –µ—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å –¥—Ä—É–≥–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–≤–∏–ª
            rules_indicators_in_answer = ["–±–∏—Ç–æ–∫", "–ø—Ä–∏—Ü–µ–ª", "—à–∞—Ä", "–ª—É–∑–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã", "—à—Ç—Ä–∞—Ñ", "—Å–æ—É–¥–∞—Ä–µ–Ω–∏–µ"]
            has_rules_in_answer = any(indicator in answer_lower for indicator in rules_indicators_in_answer)

            if not has_rules_in_answer:
                # –î–æ–±–∞–≤–ª—è–µ–º –†–∏—Å.1.2.1, –µ—Å–ª–∏ –µ–≥–æ –µ—â–µ –Ω–µ—Ç
                if "–†–∏—Å.1.2.1" not in figures_found:
                    figures_found.append("–†–∏—Å.1.2.1")
                course_figure_selected = True
                course_selected_figures.add("–†–∏—Å.1.2.1")
                # –ñ–ï–°–¢–ö–û: –ü—Ä–∏ –ø–æ–∫–∞–∑–µ –†–∏—Å.1.2.1 —É–¥–∞–ª—è–µ–º –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏ (–≤–∫–ª—é—á–∞—è 1.2.2, 1.2.3 –∏ –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ)
                # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –†–∏—Å.1.2.1
                figures_found = ["–†–∏—Å.1.2.1"]
                course_selected_figures = {"–†–∏—Å.1.2.1"}
                forced_figures = set()  # –û—á–∏—â–∞–µ–º forced_figures, —á—Ç–æ–±—ã –Ω–µ –¥–æ–±–∞–≤–ª—è–ª–∏—Å—å –¥—Ä—É–≥–∏–µ —Ä–∏—Å—É–Ω–∫–∏
                logger.info(f"‚úÖ –†–∏—Å.1.2.1 –¥–æ–±–∞–≤–ª–µ–Ω –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ LLM. –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏ —É–¥–∞–ª–µ–Ω—ã, –æ—Å—Ç–∞–≤–ª–µ–Ω —Ç–æ–ª—å–∫–æ –†–∏—Å.1.2.1.")
            else:
                logger.info(f"–†–∏—Å.1.2.1 –ù–ï –¥–æ–±–∞–≤–ª–µ–Ω: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–≤–∏–ª –≤ –æ—Ç–≤–µ—Ç–µ")
        else:
            logger.info(f"–†–∏—Å.1.2.1 –ù–ï –¥–æ–±–∞–≤–ª–µ–Ω: –Ω–µ—Ç '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ (has_initial_course_phrase={has_initial_course_phrase}, has_initial_strike={has_initial_strike})")
    elif answer and not has_school_sources_in_llm:
        # –ï—Å–ª–∏ —ç—Ç–æ –ù–ï —Ä–∞–∑–¥–µ–ª "–û —à–∫–æ–ª–µ", –†–∏—Å.1.2.1 –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è
        if "–†–∏—Å.1.2.1" in figures_found:
            figures_found = [fig for fig in figures_found if fig != "–†–∏—Å.1.2.1"]
            if "–†–∏—Å.1.2.1" in course_selected_figures:
                course_selected_figures.remove("–†–∏—Å.1.2.1")
            if "–†–∏—Å.1.2.1" in forced_figures:
                forced_figures.remove("–†–∏—Å.1.2.1")
            logger.info(f"–†–∏—Å.1.2.1 —É–¥–∞–ª–µ–Ω: —ç—Ç–æ –ù–ï —Ä–∞–∑–¥–µ–ª '–û —à–∫–æ–ª–µ'")

    # –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ —Ä–∏—Å—É–Ω–∫–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
    if not has_initial_course_in_answer:
        figure_keyword_hints = {
            "–ª–æ–≥–æ —à–∫–æ–ª—ã": "–†–∏—Å.1.1.1",
            "–ª–æ–≥–æ—Ç–∏–ø —à–∫–æ–ª—ã": "–†–∏—Å.1.1.1",
            "–±–∞–Ω–Ω–µ—Ä": "–†–∏—Å.1.1.2",
            "–ª–æ–≥–æ –±–∏—Å–∞": "–†–∏—Å.1.4.1",
            "–ª–æ–≥–æ—Ç–∏–ø –±–∏—Å–∞": "–†–∏—Å.1.4.1",
            "—Ñ–æ—Ä–º–∞ –≤–≤–æ–¥–∞": "–†–∏—Å.1.4.2",
            "–Ω–∞–≤–∏–≥–∞—Ü–∏—è": "–†–∏—Å.1.4.3",
            "—Å–æ—Å—Ç–∞–≤ —É–ø—Ä–∞–∂–Ω–µ–Ω–∏–π": "–†–∏—Å.1.4.4",
            "–±–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö": "–†–∏—Å.1.4.5",
            "–ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏": "–†–∏—Å.1.4.6",
        }
        for keyword, fig in figure_keyword_hints.items():
            if keyword in lowered_q:
                figures_found.append(fig)
                forced_figures.add(fig)

    # –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –¥—Ä—É–≥–∏–µ —Ä–∏—Å—É–Ω–∫–∏
    if not has_initial_course_in_answer:
        if answer and (
            BRACKETED_COUNT_FIGURE_PATTERN.search(answer)
            or COUNT_FIGURE_PATTERN.search(answer)
        ):
            figures_found.append("–†–∏—Å.1.4.4")
            forced_figures.add("–†–∏—Å.1.4.4")

    try:
        title_candidates = image_mapper.find_figures_by_keywords(all_keywords)
        figures_found.extend(title_candidates)
    except Exception as title_error:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ä–∏—Å—É–Ω–∫–æ–≤ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º: {title_error}")

    # –ñ–ï–°–¢–ö–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", —É–¥–∞–ª—è–µ–º –í–°–ï —Ä–∏—Å—É–Ω–∫–∏ –∫—Ä–æ–º–µ –†–∏—Å.1.2.1
    # –ò —É–¥–∞–ª—è–µ–º –†–∏—Å.1.2.1, –µ—Å–ª–∏ –µ–≥–æ –Ω–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å
    if answer and isinstance(answer, str):
        answer_lower = answer.lower()
        has_initial_course_phrase = "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer_lower
        has_initial_strike = "–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä" in answer_lower

        if has_initial_course_phrase and not has_initial_strike and has_school_sources_in_llm:
            # –ï—Å–ª–∏ –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", –æ—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1
            rules_indicators = ["–±–∏—Ç–æ–∫", "–ø—Ä–∏—Ü–µ–ª", "—à–∞—Ä", "–ª—É–∑–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã", "—à—Ç—Ä–∞—Ñ", "—Å–æ—É–¥–∞—Ä–µ–Ω–∏–µ"]
            has_rules = any(indicator in answer_lower for indicator in rules_indicators)

            if not has_rules:
                # –û—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1, —É–¥–∞–ª—è–µ–º –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                figures_found = ["–†–∏—Å.1.2.1"] if "–†–∏—Å.1.2.1" in figures_found else []
                course_selected_figures = {"–†–∏—Å.1.2.1"} if "–†–∏—Å.1.2.1" in figures_found else set()
                forced_figures = set()
                logger.info(f"‚úÖ –ñ–ï–°–¢–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –æ—Å—Ç–∞–≤–ª–µ–Ω –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1, –≤—Å–µ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —É–¥–∞–ª–µ–Ω—ã")
        elif "–†–∏—Å.1.2.1" in figures_found:
            # –ï—Å–ª–∏ –†–∏—Å.1.2.1 –µ—Å—Ç—å, –Ω–æ –Ω–µ—Ç "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" - —É–¥–∞–ª—è–µ–º –µ–≥–æ
            if not has_initial_course_phrase or has_initial_strike or not has_school_sources_in_llm:
                figures_found = [fig for fig in figures_found if fig != "–†–∏—Å.1.2.1"]
                if "–†–∏—Å.1.2.1" in course_selected_figures:
                    course_selected_figures.remove("–†–∏—Å.1.2.1")
                if "–†–∏—Å.1.2.1" in forced_figures:
                    forced_figures.remove("–†–∏—Å.1.2.1")
                logger.info(f"–ñ–ï–°–¢–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –†–∏—Å.1.2.1 —É–¥–∞–ª–µ–Ω - –Ω–µ—Ç '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ")

    try:
        figure_scores: list[tuple[str, int, bool]] = []
        for fig in figures_found:
            try:
                fig_lower = fig.lower()
                explicit = fig_lower in user_q.lower() or (answer and fig_lower in answer.lower())
                score = 0
                if explicit:
                    score += 100
                if fig in course_selected_figures:
                    score += 100
                title = image_mapper.get_figure_title(fig)
                if title:
                    title_lower = title.lower()
                    score += sum(1 for kw in all_keywords if kw in title_lower)
                if score > 0:
                    figure_scores.append((fig, score, explicit))
            except Exception as fig_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ä–∏—Å—É–Ω–∫–∞ {fig}: {fig_error}")
                continue
    except Exception as scoring_error:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ü–µ–Ω–∫–µ —Ä–∏—Å—É–Ω–∫–æ–≤: {scoring_error}")
        figure_scores = []

    filtered_figures: list[str] = []
    if figure_scores:
        max_score = max(score for _, score, _ in figure_scores)
        for fig, score, explicit in figure_scores:
            if explicit or score == max_score:
                filtered_figures.append(fig)

    if forced_figures:
        filtered_figures = _unique_preserving(list(forced_figures) + filtered_figures)

    filtered_figures = _unique_preserving(filtered_figures)
    if blocked_figures:
        filtered_figures = [fig for fig in filtered_figures if fig not in blocked_figures]

    image_intent_words = [
        "–ø–æ–∫–∞–∂–∏", "–ø–æ–∫–∞–∂–∏—Ç–µ", "–ø–æ–∫–∞–∑–∞—Ç—å", "–ø–æ–∫–∞–∂–∏-–∫–∞", "–ø–æ–∫–∞–∂",
        "–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "–∫–∞—Ä—Ç–∏–Ω–∫–∞", "—Ä–∏—Å—É–Ω–æ–∫", "—Ä–∏—Å.", "—Å—Ö–µ–º–∞", "—Ñ–æ—Ç–æ",
        "–ª–æ–≥–æ—Ç–∏–ø", "–ª–æ–≥–æ—Ç–∏–ø —à–∫–æ–ª—ã", "—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç",
        "–ø—Ä–∏–∫—Ä–µ–ø–∏", "–ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å", "–æ—Ç–ø—Ä–∞–≤—å", "–ø–æ–∫–∞–∂–∏ —Ñ–æ—Ç–æ"
    ]
    has_image_intent = any(w in user_q.lower() for w in image_intent_words)
    has_explicit_fig_ref = bool(figures_in_question or figures_in_answer)

    training_keywords = {
        "–∫—É—Ä—Å", "–Ω–∞—á–∞–ª—å–Ω—ã–π", "–±–∞–∑–æ–≤—ã–π", "—ç–∫—Å–ø—Ä–µ—Å—Å", "–∞–±–æ–Ω–µ–º–µ–Ω—Ç",
        "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ", "—Ç—Ä–µ–Ω–∏–Ω–≥", "—Ç—Ä–µ–Ω–∏–Ω–≥-–∫–ª–∞—Å—Å", "—é–Ω–∏–æ—Ä", "–º–∞—Å—Ç–µ—Ä", "–ø—Ä–æ—Ñ–∏"
    }
    is_training_topic = any(k in user_q.lower() for k in training_keywords)
    try:
        if not is_training_topic:
            is_training_topic = any("1.2_–í–∏–¥—ã –æ–±—É—á–µ–Ω–∏—è" in (h.source or "") for h in used_hits)
    except Exception:
        pass
    has_cert_fig = any((image_mapper.get_figure_title(f) or "").lower().find("—Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç") >= 0 for f in filtered_figures)
    allow_auto_images = is_training_topic and has_cert_fig

    norm_q = re.sub(r"\s+", " ", user_q.lower()).strip()
    general_training_phrases = [
        "–≤–∏–¥—ã –æ–±—É—á", "–ø—Ä–æ–≥—Ä–∞–º–º—ã –æ–±—É—á", "—Ñ–æ—Ä–º—ã –æ–±—É—á", "—Ç–∏–ø—ã –æ–±—É—á", "–≤–∞—Ä–∏–∞–Ω—Ç—ã –æ–±—É—á",
        "—É—á–µ–±–Ω—ã–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã", "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ –æ–±—É—á"
    ]
    has_general_training_phrase = any(p in norm_q for p in general_training_phrases)
    has_specific_course_marker = any(s in norm_q for s in [
        "–Ω–∞—á–∞–ª—å–Ω", "–±–∞–∑–æ–≤", "—ç–∫—Å–ø—Ä–µ—Å—Å", "–∞–±–æ–Ω–µ–º", "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω", "—Ç—Ä–µ–Ω–∏–Ω–≥",
        "–∫1", "–∫2", "–∫3", "–∞1", "–∞2", "–∞3", "—Ç1"
    ])
    generic_training = has_general_training_phrase and not has_specific_course_marker

    if not (has_image_intent or has_explicit_fig_ref or allow_auto_images or course_figure_selected or forced_figures):
        filtered_figures = []
    if generic_training and not forced_figures:
        filtered_figures = []
    if purchase_inquiry and not (course_figure_selected or has_explicit_fig_ref or has_image_intent or forced_figures):
        filtered_figures = []

    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å —Ñ—Ä–∞–∑–∞ "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–õ–¨–ö–û –≤ –æ—Ç–≤–µ—Ç–µ LLM, –Ω–µ –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    # –≠—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –ü–û–°–õ–ï –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å —Ä–∏—Å—É–Ω–∫–∞–º–∏, –Ω–æ –ü–ï–†–ï–î —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
    if answer and isinstance(answer, str):
        answer_lower = answer.lower()
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–ß–ù–£–Æ —Ñ—Ä–∞–∑—É "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" (—Ä–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º–æ)
        has_initial_course_phrase = "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer_lower

        if has_initial_course_phrase and has_school_sources_in_llm:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–∞–≤–∏–ª
            rules_indicators = ["–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä", "–±–∏—Ç–æ–∫", "–ø—Ä–∏—Ü–µ–ª", "—à–∞—Ä", "–ª—É–∑–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã", "—à—Ç—Ä–∞—Ñ", "—Å–æ—É–¥–∞—Ä–µ–Ω–∏–µ"]
            has_rules = any(indicator in answer_lower for indicator in rules_indicators)

            if not has_rules:
                # –ö–†–ò–¢–ò–ß–ù–û: –û—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1, —É–¥–∞–ª—è–µ–º –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–∏—Å—É–Ω–∫–∏
                # –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç—å –ü–û–°–õ–ï –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π —Å —Ä–∏—Å—É–Ω–∫–∞–º–∏
                original_figures = filtered_figures.copy()
                filtered_figures = ["–†–∏—Å.1.2.1"]
                logger.info(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø: –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —Ñ—Ä–∞–∑—ã '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ LLM –æ—Å—Ç–∞–≤–ª–µ–Ω –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1. –ë—ã–ª–æ: {original_figures}, —Å—Ç–∞–ª–æ: {filtered_figures}")

    if not answer or not isinstance(answer, str):
        answer = "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."

    try:
        final_answer = answer.strip() if answer and isinstance(answer, str) else ""
        if not final_answer:
            final_answer = "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."

        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫
        # –ì–ª–æ–±–∞–ª—å–Ω–∞—è –∑–∞—â–∏—Ç–∞ —Å—Ç—Ä–æ–∫ —Å "‚Äî" —Ç–µ–ø–µ—Ä—å –≤—Å—Ç—Ä–æ–µ–Ω–∞ –≤ _format_llm_response_layout (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤ —à–∞–≥–µ 0)
        # –∏ _enhance_layout (–∑–∞—â–∏—Ç–∞ –º–∞—Ä–∫–µ—Ä–∞–º–∏)
        # –°–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
        processing_functions_main = [
            _bold_to_arrow,
            _format_pointers_and_bold,  # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ "üëâ—Ç–µ–∫—Å—Ç:" –∏ "*—Ç–µ–∫—Å—Ç*"
            _format_llm_response_layout,  # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ LLM: –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –Ω–æ–≤–æ–π —Å—Ç—Ä–æ–∫–∏, —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å—Ç—Ä–æ–∫ —Å "‚Äî"
            _normalize_arrows,
            _strip_unwanted_symbols,
            _enhance_layout,  # –ó–∞—â–∏—â–∞–µ—Ç —Å—Ç—Ä–æ–∫–∏ —Å "‚Äî" –º–∞—Ä–∫–µ—Ä–∞–º–∏ –æ—Ç –¥–∞–ª—å–Ω–µ–π—à–∏—Ö –æ–±—Ä–∞–±–æ—Ç–æ–∫
            _remove_lonely_emojis,
        ]
        
        # –ó–∞—Ç–µ–º –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–ª–æ–∫ CTA (–≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ)
        processing_functions_cta = [
            _move_cta_to_end,  # –ü–µ—Ä–µ–Ω–æ—Å–∏—Ç CTA –≤ –∫–æ–Ω–µ—Ü
            _ensure_cta_spacing,  # –î–æ–±–∞–≤–ª—è–µ—Ç –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É –ø–µ—Ä–µ–¥ CTA –∏ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç üéØ
            _normalize_cta_block,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –±–ª–æ–∫ CTA
        ]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –æ—Å–Ω–æ–≤–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        for func in processing_functions_main:
            try:
                final_answer = func(final_answer) if final_answer else ""
                if not final_answer:
                    break
            except Exception as func_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ {func.__name__}: {func_error}")
                continue
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É CTA –±–ª–æ–∫–∞ (–≤ —Å–∞–º–æ–º –∫–æ–Ω—Ü–µ)
        for func in processing_functions_cta:
            try:
                final_answer = func(final_answer) if final_answer else ""
                if not final_answer:
                    break
            except Exception as func_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ {func.__name__}: {func_error}")
                continue

        for func in processing_functions:
            try:
                final_answer = func(final_answer) if final_answer else ""
                if not final_answer:
                    break
            except Exception as func_error:
                logger.warning(f"–û—à–∏–±–∫–∞ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ {func.__name__}: {func_error}")
                continue

        if not final_answer:
            final_answer = "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."
    except Exception as text_error:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞: {text_error}", exc_info=True)
        final_answer = "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."

    if not purchase_inquiry and final_answer:
        try:
            sentences = _split_into_sentences(final_answer)
            filtered_sentences = [
                s for s in sentences
                if s and not re.search(r"–ø–æ–∫—É–ø–∫|–ø—Ä–µ–¥–æ–ø–ª–∞—Ç|–æ–ø–ª–∞—Ç–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è|–æ—Ñ–æ—Ä–º", s, re.IGNORECASE)
            ]
            if filtered_sentences:
                final_answer = " ".join(filtered_sentences).strip()
                if final_answer:
                    try:
                        final_answer = _move_cta_to_end(final_answer)
                        final_answer = _ensure_cta_spacing(final_answer)
                        final_answer = _remove_lonely_emojis(final_answer)
                        final_answer = _normalize_cta_block(final_answer)
                    except Exception as post_error:
                        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç-–æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {post_error}")
        except Exception as sent_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π: {sent_error}")
    elif purchase_inquiry:
        try:
            replacements = [
                (r"\b–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è"),
                (r"\b–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è"),
                (r"\b–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ä–æ–∫–∏\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ —É—Ä–æ–∫–∏"),
                (r"\b–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É—Ä–æ–∫–∏\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ —É—Ä–æ–∫–∏"),
                (r"\b–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è"),
                (r"\b–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ\b", "–û—Ç–¥–µ–ª—å–Ω—ã–µ –∑–∞–Ω—è—Ç–∏—è"),
            ]
            for pat, repl in replacements:
                final_answer = re.sub(pat, repl, final_answer)
        except Exception:
            pass
        finally:
            final_answer = _move_cta_to_end(final_answer)
            final_answer = _ensure_cta_spacing(final_answer)
            final_answer = _remove_lonely_emojis(final_answer)
            final_answer = _normalize_cta_block(final_answer)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –≤ LLM –±—ã–ª–∏ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ "–û —à–∫–æ–ª–µ", –ø–æ–ª–Ω–æ—Å—Ç—å—é –±–ª–æ–∫–∏—Ä—É–µ–º –∫–Ω–æ–ø–∫—É
    # –ù–û —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –ù–ï –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=False)
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–∏–ª–∞–º (rule_query=True), –∫–Ω–æ–ø–∫–∞ –¥–æ–ª–∂–Ω–∞ –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å—Å—è –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –Ω–∞–ª–∏—á–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ "–û —à–∫–æ–ª–µ"
    if has_school_sources_in_llm and not rule_query:
        allow_rule_button = False
        primary_sources = []
        logger.info(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞: –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ '–û —à–∫–æ–ª–µ' –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–ª—è LLM (rule_query=False)")

    # –ñ–ï–°–¢–ö–û–ï –û–ì–†–ê–ù–ò–ß–ï–ù–ò–ï: stored_primary_sources —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –µ—Å–ª–∏ allow_rule_button = True
    # –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∫–Ω–æ–ø–∫–∞ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è, –µ—Å–ª–∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã
    stored_primary_sources = primary_sources if (allow_rule_button and primary_sources) else []
    logger.info(f"–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –ø–æ–∫–∞–∑–æ–º –∫–Ω–æ–ø–∫–∏: allow_rule_button={allow_rule_button}, primary_sources count={len(primary_sources)}, stored_primary_sources count={len(stored_primary_sources)}")

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã (–ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å–ª–æ–≤–∞—Ä–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
    # –ò –¢–û–õ–¨–ö–û –µ—Å–ª–∏ allow_rule_button = True
    if stored_primary_sources and allow_rule_button:
        serializable_sources = []
        for frag in stored_primary_sources:
            if isinstance(frag, dict):
                serializable_sources.append(frag)
            else:
                # –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –ø—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å
                try:
                    serializable_sources.append(dict(frag) if hasattr(frag, '__dict__') else frag)
                except:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç: {frag}")
        stored_primary_sources = serializable_sources
        logger.info(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏: count={len(stored_primary_sources)}")

    try:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ state –µ—Å–ª–∏ allow_rule_button = True
        # –î–ª—è rule_query=True –∏ –Ω–∞–ª–∏—á–∏—è –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤ fragment_sources —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–∞–∂–µ –µ—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
        # (—Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –±—É–¥—É—Ç –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É)
        if allow_rule_button:
            # –ï—Å–ª–∏ –µ—Å—Ç—å stored_primary_sources - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö
            # –ï—Å–ª–∏ stored_primary_sources –ø—É—Å—Ç, –Ω–æ rule_query=True –∏ –µ—Å—Ç—å fragment_sources - –≤—Å–µ —Ä–∞–≤–Ω–æ —Ä–∞–∑—Ä–µ—à–∞–µ–º
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º hits –≤ —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏ –Ω–∞ –∫–Ω–æ–ø–∫—É
            hits_serializable = []
            for h in hits[:5]:
                if hasattr(h, 'text') and hasattr(h, 'source'):
                    hits_serializable.append({
                        "text": h.text,
                        "source": h.source,
                        "score": getattr(h, 'score', 0.0),
                        "title": getattr(h, 'title', ""),
                        "figures": getattr(h, 'figures', ""),
                        "section": getattr(h, 'section', "")
                    })

            if stored_primary_sources:
                await state.update_data(
                    primary_sources=stored_primary_sources,
                    primary_source_index=0,
                    primary_source_main_source=main_source,
                    primary_source_is_rules=True,
                    primary_source_hits=hits_serializable,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º hits –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
                )
                logger.info(f"State –æ–±–Ω–æ–≤–ª–µ–Ω: primary_sources count={len(stored_primary_sources)}, primary_source_is_rules=True, main_source={main_source}")
            elif rule_query and fragment_sources and any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources):
                # –î–ª—è rule_query=True —Ä–∞–∑—Ä–µ—à–∞–µ–º –∫–Ω–æ–ø–∫—É –¥–∞–∂–µ –±–µ–∑ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ (–æ–Ω–∏ –±—É–¥—É—Ç –Ω–∞–π–¥–µ–Ω—ã –ø—Ä–∏ –Ω–∞–∂–∞—Ç–∏–∏)
                await state.update_data(
                    primary_sources=[],
                    primary_source_index=0,
                    primary_source_main_source=main_source or (list(fragment_sources)[0] if fragment_sources else None),
                    primary_source_is_rules=True,
                    primary_source_hits=hits_serializable,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º hits –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞
                )
                logger.info(f"State –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è rule_query=True: primary_source_is_rules=True, main_source={main_source or (list(fragment_sources)[0] if fragment_sources else None)}, fragment_sources={fragment_sources}")
            else:
                # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã, –æ—á–∏—â–∞–µ–º state
                await state.update_data(
                    primary_sources=[],
                    primary_source_index=0,
                    primary_source_main_source=None,
                    primary_source_is_rules=False,
                )
                logger.info(f"State –æ—á–∏—â–µ–Ω: allow_rule_button={allow_rule_button}, stored_primary_sources count={len(stored_primary_sources) if stored_primary_sources else 0}, rule_query={rule_query}")
        else:
            # –ï—Å–ª–∏ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã, –æ—á–∏—â–∞–µ–º state
            await state.update_data(
                primary_sources=[],
                primary_source_index=0,
                primary_source_main_source=None,
                primary_source_is_rules=False,
            )
            logger.info(f"State –æ—á–∏—â–µ–Ω: allow_rule_button={allow_rule_button}, stored_primary_sources count={len(stored_primary_sources) if stored_primary_sources else 0}")
    except Exception as state_error:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å state –¥–ª—è –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞: {state_error}", exc_info=True)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç LLM –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
    # –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ –µ—Å—Ç—å —Å—Ç–æ–ø-—Å–ª–æ–≤–∞, –∫–Ω–æ–ø–∫–∞ "–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫" –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è
    llm_response_blocked = False
    critical_llm_response_blocked = False
    if final_answer and isinstance(final_answer, str):
        final_answer_lower = final_answer.lower()
        llm_response_blocked = any(stop_word in final_answer_lower for stop_word in STOP_WORDS_IN_LLM_RESPONSE)
        if llm_response_blocked:
            logger.info(f"–ö–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑-–∑–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ LLM")

        # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –∂–µ—Å—Ç–∫–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤
        # –≠—Ç–∏ —Å–ª–æ–≤–∞ –±–ª–æ–∫–∏—Ä—É—é—Ç –∫–Ω–æ–ø–∫—É –¥–∞–∂–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª (rule_query=True)
        critical_llm_response_blocked = any(critical_word in final_answer_lower for critical_word in CRITICAL_STOP_WORDS_IN_LLM_RESPONSE)
        if critical_llm_response_blocked:
            logger.info(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê: –ö–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –∂–µ—Å—Ç–∫–æ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω–∞ –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤ ('–∑–∞—Ç—Ä—É–¥–Ω' –∏–ª–∏ '–∏–∑–≤–∏–Ω') –≤ –æ—Ç–≤–µ—Ç–µ LLM")

    reply_markup = None
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –±—ã–ª –∏—Å–∫–ª—é—á–µ–Ω - –∫–Ω–æ–ø–∫–∞ –ù–ò–ö–û–ì–î–ê –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π (–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è is_excluded_query –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –¥–æ—Å—Ç—É–ø–Ω–∞ –∑–¥–µ—Å—å)
    # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã - –±–ª–æ–∫–∏—Ä—É–µ–º
    user_q_lower_check = user_q.lower() if user_q else ""
    critical_excluded_check = ["—Ç—ã –∫—Ç–æ", "–∫—Ç–æ —Ç—ã"]
    is_critically_excluded = any(pattern in user_q_lower_check for pattern in critical_excluded_check)

    # –ö–Ω–æ–ø–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –µ—Å–ª–∏:
    # 0. –ó–∞–ø—Ä–æ—Å –ù–ï –∏—Å–∫–ª—é—á–µ–Ω (–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
    # 0.5. –ù–ï–¢ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ LLM (–∂–µ—Å—Ç–∫–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞, –¥–∞–∂–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª)
    # 1. allow_rule_button = True (–ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã)
    # 2. –ù–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ LLM (–ù–û –¥–ª—è –ø—Ä–∞–≤–∏–ª —ç—Ç–æ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ—Ç –∫–Ω–æ–ø–∫—É, –µ—Å–ª–∏ –Ω–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö)
    # 3. –ò (stored_primary_sources –Ω–µ –ø—É—Å—Ç –ò–õ–ò rule_query=True —Å fragment_sources –∏–∑ –ø—Ä–∞–≤–∏–ª)
    # –î–ª—è –ø—Ä–∞–≤–∏–ª (rule_query=True) –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ–±—ã—á–Ω—É—é –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –∏–∑-–∑–∞ —Å—Ç–æ–ø-—Å–ª–æ–≤, –ù–û –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤—Å–µ–≥–¥–∞
    should_show_button = (
        not is_critically_excluded and
        not critical_llm_response_blocked and
        allow_rule_button and (
            (not llm_response_blocked or rule_query) and (
                stored_primary_sources or
                (rule_query and fragment_sources and any(src in RULE_PRIMARY_ALLOWED_SOURCES for src in fragment_sources))
            )
        )
    )

    if is_critically_excluded:
        logger.info(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê –ö–ù–û–ü–ö–ò: –ó–∞–ø—Ä–æ—Å '{user_q}' —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∏—Å–∫–ª—é—á–µ–Ω–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω - –∫–Ω–æ–ø–∫–∞ –ù–ï –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–∞")

    if critical_llm_response_blocked:
        logger.info(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ë–õ–û–ö–ò–†–û–í–ö–ê –ö–ù–û–ü–ö–ò: –û—Ç–≤–µ—Ç LLM —Å–æ–¥–µ—Ä–∂–∏—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤–∞ ('–∑–∞—Ç—Ä—É–¥–Ω' –∏–ª–∏ '–∏–∑–≤–∏–Ω') - –∫–Ω–æ–ø–∫–∞ –ù–ï –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–∞, –¥–∞–∂–µ –¥–ª—è –ø—Ä–∞–≤–∏–ª")

    if should_show_button:
        reply_markup = InlineKeyboardMarkup(
            inline_keyboard=[[InlineKeyboardButton(text="üìÑ –ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫", callback_data="primary_source:open")]]
        )
        logger.info(f"–ö–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–∞: stored_primary_sources count={len(stored_primary_sources) if stored_primary_sources else 0}, allow_rule_button={allow_rule_button}, rule_query={rule_query}, fragment_sources={fragment_sources}")
    else:
        logger.info(f"–ö–Ω–æ–ø–∫–∞ '–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫' –ù–ï –±—É–¥–µ—Ç –ø–æ–∫–∞–∑–∞–Ω–∞: stored_primary_sources count={len(stored_primary_sources) if stored_primary_sources else 0}, allow_rule_button={allow_rule_button}, llm_response_blocked={llm_response_blocked}, rule_query={rule_query}, fragment_sources={fragment_sources}")

    try:
        await save_chat_message(user_id, "assistant", final_answer)
    except Exception as save_error:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é: {save_error}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –§–∞–∑—ã 4: –µ—Å–ª–∏ –∏–º—è –∏ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã, –≤—ã–≤–æ–¥–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ
    if current_phase == 4 and data.get("phase4_check_contacts"):
        profile_check = await get_user_profile(user_id)
        if profile_check:
            has_name = bool(profile_check.name and profile_check.name.strip())
            has_phone = bool(profile_check.phone and profile_check.phone.strip())

            if not has_name or not has_phone:
                await _answer_with_sticker_cleanup(message, "üòï –ñ–∞–ª—å! –Ø –≥–æ—Ç–æ–≤ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –í–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã.", waiting_sticker_message)
                await save_chat_message(user_id, "assistant", "üòï –ñ–∞–ª—å! –Ø –≥–æ—Ç–æ–≤ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –í–∞—à–∏ –≤–æ–ø—Ä–æ—Å—ã.")
                await state.update_data(phase=1, phase4_check_contacts=False, phase4_no_contacts_shown=False)
                logger.info(f"–ò–º—è –∏/–∏–ª–∏ —Ç–µ–ª–µ—Ñ–æ–Ω –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}, –≤–æ–∑–≤—Ä–∞—Ç –∫ –§–∞–∑–µ 1")

    try:
        if not final_answer or not isinstance(final_answer, str):
            final_answer = "‚ö†Ô∏è –ó–∞—Ç—Ä—É–¥–Ω—è—é—Å—å –æ—Ç–≤–µ—Ç–∏—Ç—å. –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å."

        # Telegram –∏–º–µ–µ—Ç –ª–∏–º–∏—Ç 4096 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ
        MAX_MESSAGE_LENGTH = 4096

        if len(final_answer) <= MAX_MESSAGE_LENGTH:
            # –°–æ–æ–±—â–µ–Ω–∏–µ –∫–æ—Ä–æ—Ç–∫–æ–µ, –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
            await _answer_with_sticker_cleanup(message, final_answer, waiting_sticker_message, reply_markup=reply_markup)
            logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")
        else:
            # –°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–æ–µ, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º, —á—Ç–æ–±—ã –Ω–µ —Ä–µ–∑–∞—Ç—å —Ç–µ–∫—Å—Ç –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ
            sentences = _split_into_sentences(final_answer)
            parts = []
            current_part = ""

            for sentence in sentences:
                # –ï—Å–ª–∏ —Å–∞–º–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–ª–∏–Ω–Ω–µ–µ –ª–∏–º–∏—Ç–∞, —Ä–∞–∑–±–∏–≤–∞–µ–º –µ–≥–æ –ø–æ —Å–ª–æ–≤–∞–º
                if len(sentence) > MAX_MESSAGE_LENGTH:
                    # –°–Ω–∞—á–∞–ª–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å, –µ—Å–ª–∏ –æ–Ω–∞ –µ—Å—Ç—å
                    if current_part:
                        parts.append(current_part.strip())
                        current_part = ""

                    # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ —Å–ª–æ–≤–∞–º
                    words = sentence.split()
                    for word in words:
                        if len(current_part) + len(word) + 1 <= MAX_MESSAGE_LENGTH:
                            current_part += (word + " " if current_part else word)
                        else:
                            if current_part:
                                parts.append(current_part.strip())
                            current_part = word
                # –ï—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ –ø—Ä–µ–≤—ã—à–∞–µ—Ç –ª–∏–º–∏—Ç
                elif len(current_part) + len(sentence) + 1 <= MAX_MESSAGE_LENGTH:
                    current_part += (sentence + " " if current_part else sentence)
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é —á–∞—Å—Ç—å –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é
                    if current_part:
                        parts.append(current_part.strip())
                    current_part = sentence

            # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å
            if current_part:
                parts.append(current_part.strip())

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ —á–∞—Å—Ç–∏, –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É –ø—Ä–∏–∫—Ä–µ–ø–ª—è–µ–º —Ç–æ–ª—å–∫–æ –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Å–æ–æ–±—â–µ–Ω–∏—é
            # –°—Ç–∏–∫–µ—Ä —É–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            for i, part in enumerate(parts):
                is_last = (i == len(parts) - 1)
                if i == 0:
                    # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                    await _answer_with_sticker_cleanup(message, part, waiting_sticker_message, reply_markup=reply_markup if is_last else None)
                else:
                    await message.answer(part, reply_markup=reply_markup if is_last else None)

            logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id} ({len(parts)} —á–∞—Å—Ç–µ–π)")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞: {e}", exc_info=True)
        raise

    # –ê–ë–°–û–õ–Æ–¢–ù–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: –ï—Å–ª–∏ –≤ –æ—Ç–≤–µ—Ç–µ LLM –µ—Å—Ç—å "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å", –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1
    # –≠—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞, –∫–æ—Ç–æ—Ä–∞—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –≤—Å–µ—Ö –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¢–û–õ–¨–ö–û –≤ –æ—Ç–≤–µ—Ç–µ LLM (–ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è answer), –ù–ï –≤ –∑–∞–ø—Ä–æ—Å–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    if answer and isinstance(answer, str):
        answer_lower = answer.lower()
        has_initial_course_phrase = "–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å" in answer_lower

        logger.info(f"üîç –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: answer —Å–æ–¥–µ—Ä–∂–∏—Ç '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å'? {has_initial_course_phrase}, has_school_sources_in_llm={has_school_sources_in_llm}, filtered_figures={filtered_figures}")
        logger.info(f"üîç –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: answer (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {answer[:200]}")

        if has_initial_course_phrase and has_school_sources_in_llm:
            rules_indicators = ["–Ω–∞—á–∞–ª—å–Ω—ã–π —É–¥–∞—Ä", "–±–∏—Ç–æ–∫", "–ø—Ä–∏—Ü–µ–ª", "—à–∞—Ä", "–ª—É–∑–∞", "–ø–∏—Ä–∞–º–∏–¥–∞", "–ø—Ä–∞–≤–∏–ª–∞ –∏–≥—Ä—ã", "—à—Ç—Ä–∞—Ñ", "—Å–æ—É–¥–∞—Ä–µ–Ω–∏–µ"]
            has_rules = any(indicator in answer_lower for indicator in rules_indicators)

            logger.info(f"üîç –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: has_rules={has_rules}")

            if not has_rules:
                # –ê–ë–°–û–õ–Æ–¢–ù–û: –û—Å—Ç–∞–≤–ª—è–µ–º –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1, —É–¥–∞–ª—è–µ–º –í–°–ï –æ—Å—Ç–∞–ª—å–Ω—ã–µ
                # –≠—Ç–æ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π, –æ–Ω–∞ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—Å–µ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
                original_figures = filtered_figures.copy()
                filtered_figures = ["–†–∏—Å.1.2.1"]
                logger.info(f"‚úÖ‚úÖ‚úÖ –ê–ë–°–û–õ–Æ–¢–ù–ê–Ø –§–ò–õ–¨–¢–†–ê–¶–ò–Ø –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –≤ –æ—Ç–≤–µ—Ç–µ LLM –æ—Å—Ç–∞–≤–ª–µ–Ω –¢–û–õ–¨–ö–û –†–∏—Å.1.2.1. –ë—ã–ª–æ: {original_figures}, —Å—Ç–∞–ª–æ: {filtered_figures}")
            else:
                logger.info(f"‚ö†Ô∏è –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –Ω–∞–π–¥–µ–Ω, –Ω–æ –µ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø—Ä–∞–≤–∏–ª, –†–∏—Å.1.2.1 –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è")
        elif has_initial_course_phrase and not has_school_sources_in_llm:
            logger.info(f"‚ö†Ô∏è –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ, –Ω–æ has_school_sources_in_llm=False, –†–∏—Å.1.2.1 –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è")
        else:
            logger.info(f"‚ÑπÔ∏è –ü–†–û–í–ï–†–ö–ê –ü–ï–†–ï–î –û–¢–ü–†–ê–í–ö–û–ô: '–Ω–∞—á–∞–ª—å–Ω—ã–π –∫—É—Ä—Å' –ù–ï –Ω–∞–π–¥–µ–Ω –≤ –æ—Ç–≤–µ—Ç–µ LLM, filtered_figures={filtered_figures}")

    images_sent = []

    for fig_key in filtered_figures:
        img_path = image_mapper.get_image_path_for_figure(fig_key)
        if img_path and img_path not in images_sent:
            try:
                photo = FSInputFile(img_path)
                title = image_mapper.get_figure_title(fig_key)
                if title:
                    caption = f"{title} {fig_key}."
                else:
                    caption = f"{fig_key}."
                await message.answer_photo(photo=photo, caption=caption)
                images_sent.append(img_path)
                logger.info(f"–û—Ç–ø—Ä–∞–≤–ª–µ–Ω —Ä–∏—Å—É–Ω–æ–∫ {fig_key} –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {user_id}")
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {fig_key}: {e}")
                pass

# –§—É–Ω–∫—Ü–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ db/chat_history.py


@router.message(Command("cancel"))
async def cmd_cancel(message: Message, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã /cancel - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –≤–æ–∑–≤—Ä–∞—Ç –∫ –§–∞–∑–µ 1"""
    logger = logging.getLogger(__name__)
    user_id = message.from_user.id if message.from_user else 0
    logger.info(f"–ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ /cancel –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")

    try:
        await _normalize_state(state, user_id)
        cancel_message = "‚ñ∂Ô∏è –Ø –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º."
        await message.answer(cancel_message, parse_mode=ParseMode.HTML)
        if message.from_user:
            await save_chat_message(message.from_user.id, "assistant", cancel_message)
        logger.info(f"–ö–æ–º–∞–Ω–¥–∞ /cancel –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ /cancel: {e}", exc_info=True)
        try:
            await message.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–æ–º–∞–Ω–¥—ã.")
        except:
            pass


@router.message(lambda m: m.text and not m.text.startswith("/") and m.text != "üìù –ó–∞–ø–∏—Å—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ")
async def handle_faq(message: Message, state: FSMContext) -> None:
    logger = logging.getLogger(__name__)

    current_state = await state.get_state()
    if current_state and current_state.startswith("BookingStates"):
        logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º FAQ –æ–±—Ä–∞–±–æ—Ç–∫—É - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ {current_state}")
        return

    if not message.text or message.text.startswith("/"):
        return

    if message.text == "üìù –ó–∞–ø–∏—Å—å –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ":
        return

    user_text = message.text
    if user_text.startswith("üìö "):
        user_text = user_text[2:].strip()
    elif user_text.startswith("üî• "):
        user_text = user_text[2:].strip()

    logger.info(
        f"–ü–æ–ª—É—á–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è FAQ: '{user_text[:50]}' –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.id if message.from_user else 'unknown'}"
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É - –¥–ª—è —Ñ–∞–∑ 2, 3 –∏ 4 –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è
    state_data = await state.get_data()
    current_phase = state_data.get("phase", 1)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –§–∞–∑—ã 1
    waiting_sticker_message = None
    if current_phase == 1:
        waiting_sticker_message = await _send_waiting_sticker(message)
    else:
        logger.info(f"–°—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –¥–ª—è –§–∞–∑—ã {current_phase}")

    try:
        await _process_faq_query(message, state, user_text, input_mode="text", waiting_sticker_message=waiting_sticker_message)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ FAQ: {e}", exc_info=True)
        try:
            await message.answer("‚ö†Ô∏è –û–¥–Ω–∞–∫–æ, –ø—Ä–æ–∏–∑–æ—à–µ–ª —Å–∏—Å—Ç–µ–º–Ω—ã–π —Å–±–æ–π. –ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –í–∞—à –∑–∞–ø—Ä–æ—Å/–æ—Ç–≤–µ—Ç.")
        except Exception:
            pass


@router.message(F.voice)
async def handle_voice_message(message: Message, state: FSMContext) -> None:
    logger = logging.getLogger(__name__)

    current_state = await state.get_state()
    if current_state and current_state.startswith("BookingStates"):
        logger.debug(f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º FAQ –æ–±—Ä–∞–±–æ—Ç–∫—É –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è - —Å–æ—Å—Ç–æ—è–Ω–∏–µ {current_state}")
        return

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É - –¥–ª—è —Ñ–∞–∑ 2, 3 –∏ 4 –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è
    state_data = await state.get_data()
    current_phase = state_data.get("phase", 1)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –§–∞–∑—ã 1
    waiting_sticker_message = None
    if current_phase == 1:
        waiting_sticker_message = await _send_waiting_sticker(message)
    else:
        logger.info(f"–°—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –¥–ª—è –§–∞–∑—ã {current_phase}")

    temp_path: str | None = None
    converted_path: str | None = None
    transcript: str = ""
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º /tmp –≤ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω, –∏–Ω–∞—á–µ —Å–∏—Å—Ç–µ–º–Ω—É—é –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        temp_dir = os.getenv("TMPDIR", os.getenv("TEMP", tempfile.gettempdir()))
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(temp_dir, exist_ok=True)

        # –°–∫–∞—á–∏–≤–∞–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ .oga —Ñ–æ—Ä–º–∞—Ç–µ
        with tempfile.NamedTemporaryFile(delete=False, suffix=".oga", dir=temp_dir) as tmp:
            await message.bot.download(message.voice, destination=tmp.name)
            temp_path = tmp.name

        logger.info(f"–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–∫–∞—á–∞–Ω–æ: {temp_path}, —Ä–∞–∑–º–µ—Ä: {os.path.getsize(temp_path) if os.path.exists(temp_path) else 0} –±–∞–π—Ç")

        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º .oga –≤ .wav —á–µ—Ä–µ–∑ ffmpeg (faster-whisper –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å .wav)
        import subprocess
        converted_path = temp_path.replace(".oga", ".wav")

        logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è .oga –≤ .wav: {converted_path}")
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —á–µ—Ä–µ–∑ ffmpeg
            subprocess.run(
                ["ffmpeg", "-i", temp_path, "-y", "-ar", "16000", "-ac", "1", "-f", "wav", converted_path],
                check=True,
                capture_output=True,
                timeout=30
            )
            logger.info(f"–ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ: {converted_path}")

            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –¥–ª—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏
            audio_file = converted_path
        except subprocess.CalledProcessError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏ —á–µ—Ä–µ–∑ ffmpeg: {e.stderr.decode() if e.stderr else str(e)}")
            # –ü—ã—Ç–∞–µ–º—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª
            audio_file = temp_path
            logger.warning("–ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π .oga —Ñ–∞–π–ª (–º–æ–∂–µ—Ç –Ω–µ —Ä–∞–±–æ—Ç–∞—Ç—å)")
        except FileNotFoundError:
            logger.warning("ffmpeg –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª")
            audio_file = temp_path
        except Exception as e:
            logger.error(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {e}", exc_info=True)
            audio_file = temp_path

        logger.info(f"–ù–∞—á–∞–ª–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞: {audio_file}")
        transcript = await transcribe_file(audio_file)
        logger.info(f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: '{transcript[:100] if transcript else '–ü–£–°–¢–û'}'...")
    except ImportError as e:
        logger.error(f"STT –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ: {e}", exc_info=True)
        # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø—Ä–∏ –æ—à–∏–±–∫–µ
        if waiting_sticker_message:
            try:
                await waiting_sticker_message.delete()
            except Exception:
                pass
        await message.answer(
            "–î–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –Ω—É–∂–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å Whisper. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ 'faster-whisper' –∏ ffmpeg, –∑–∞—Ç–µ–º –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )
        return
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}", exc_info=True)
        logger.error(f"–ü—É—Ç—å –∫ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É: {temp_path}, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(temp_path) if temp_path else 'N/A'}")
        logger.error(f"–ü—É—Ç—å –∫ —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É: {converted_path}, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {os.path.exists(converted_path) if converted_path else 'N/A'}")
        logger.error(f"TMPDIR: {os.getenv('TMPDIR')}, TEMP: {os.getenv('TEMP')}, tempfile.gettempdir(): {tempfile.gettempdir()}")
        await _answer_with_sticker_cleanup(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑ –∏–ª–∏ –∑–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å —Ç–µ–∫—Å—Ç–æ–º.", waiting_sticker_message)
        return
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        for file_path in [temp_path, converted_path]:
            if file_path and os.path.exists(file_path):
                try:
                    os.remove(file_path)
                    logger.debug(f"–£–¥–∞–ª–µ–Ω –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
                except OSError as e:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª {file_path}: {e}")

    transcript = (transcript or "").strip()
    if not transcript:
        await _answer_with_sticker_cleanup(message, "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑.", waiting_sticker_message)
        return

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –ø–æ—Å–ª–µ –ø–æ—è–≤–ª–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∞–Ω–Ω–æ–π —Ñ—Ä–∞–∑—ã
    if waiting_sticker_message:
        try:
            await waiting_sticker_message.delete()
        except Exception as e:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è: {e}")

    logger.info(
        f"–ü–æ–ª—É—á–µ–Ω–æ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.id if message.from_user else 'unknown'}: '{transcript[:50]}'"
    )

    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    # –£–±–∏—Ä–∞–µ–º –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è –∏ –¥–µ–ª–∞–µ–º –ø–µ—Ä–≤—É—é –±—É–∫–≤—É –º–∞–ª–µ–Ω—å–∫–æ–π
    # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã, —Ü–∏—Ñ—Ä—ã –∏ –ø—Ä–æ–±–µ–ª—ã
    cleaned_transcript = ''.join(c for c in transcript if c.isalnum() or c.isspace()).strip()
    if cleaned_transcript:
        cleaned_transcript = cleaned_transcript[0].lower() + cleaned_transcript[1:] if len(cleaned_transcript) > 1 else cleaned_transcript.lower()
    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫—É –≥–æ–ª–æ—Å–∞ - —ç—Ç–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –ø–æ—ç—Ç–æ–º—É —É–¥–∞–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è
    transcript_message = await message.answer(f"üé§ {cleaned_transcript}")
    await _delete_waiting_sticker(waiting_sticker_message)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â—É—é —Ñ–∞–∑—É - –¥–ª—è —Ñ–∞–∑ 2, 3 –∏ 4 –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è
    state_data_voice = await state.get_data()
    current_phase_voice = state_data_voice.get("phase", 1)

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è –§–∞–∑—ã 1
    waiting_sticker_message = None
    if current_phase_voice == 1:
        waiting_sticker_message = await _send_waiting_sticker(transcript_message)
    else:
        logger.info(f"–°—Ç–∏–∫–µ—Ä –æ–∂–∏–¥–∞–Ω–∏—è –Ω–µ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –¥–ª—è –§–∞–∑—ã {current_phase_voice}")

    await _process_faq_query(message, state, transcript, input_mode="voice", waiting_sticker_message=waiting_sticker_message)


@router.callback_query(F.data.startswith("intent:"))
async def handle_intent_selection(callback: CallbackQuery, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –∏–∑ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞"""
    logger = logging.getLogger(__name__)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    if not callback.from_user:
        logger.error("callback.from_user is None")
        await callback.answer("–û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    if not callback.message:
        logger.error("callback.message is None")
        await callback.answer("–û—à–∏–±–∫–∞: —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", show_alert=True)
        return

    user_id = callback.from_user.id
    intent_type = callback.data.split(":")[1] if ":" in callback.data else ""

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–∫–Ω–æ–º –≤—ã–±–æ—Ä–∞ –≤ —á–∞—Ç–µ (–Ω–µ —É–¥–∞–ª—è–µ–º)

    try:
        if intent_type == "training":
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª "–û–±—É—á–µ–Ω–∏–µ"
            user_intent = "–û–±—É—á–µ–Ω–∏–µ"
            status = "–û–±—É—á–µ–Ω–∏–µ"
            # –ü–æ–ª—É—á–∞–µ–º name_sys –∏–∑ callback
            name_sys = ""
            if callback.from_user:
                if callback.from_user.first_name:
                    name_sys = callback.from_user.first_name
                elif callback.from_user.username:
                    name_sys = callback.from_user.username
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ name_sys
            profile = await get_user_profile(user_id)
            if profile and not profile.name_sys and name_sys:
                await update_user_profile(tg_user_id=user_id, status=status, name_sys=name_sys)
            else:
                await update_user_profile(tg_user_id=user_id, status=status)
            await callback.answer("–í—ã–±—Ä–∞–Ω–æ: –û–±—É—á–µ–Ω–∏–µ")
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–±—Ä–∞–ª –û–±—É—á–µ–Ω–∏–µ")

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –≤—ã–±–æ—Ä —Å–¥–µ–ª–∞–Ω
            await state.update_data(intent_selection_shown=False)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–∏ (waiting_sticker_message –Ω–µ –Ω—É–∂–µ–Ω, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ callback)
            await show_policy_window(callback.message, state, user_intent, None)

        elif intent_type == "consultation":
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"
            user_intent = "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"
            status = "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è"
            # –ü–æ–ª—É—á–∞–µ–º name_sys –∏–∑ callback
            name_sys = ""
            if callback.from_user:
                if callback.from_user.first_name:
                    name_sys = callback.from_user.first_name
                elif callback.from_user.username:
                    name_sys = callback.from_user.username
            # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–æ—Ñ–∏–ª—å –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ name_sys
            profile = await get_user_profile(user_id)
            if profile and not profile.name_sys and name_sys:
                await update_user_profile(tg_user_id=user_id, status=status, name_sys=name_sys)
            else:
                await update_user_profile(tg_user_id=user_id, status=status)
            await callback.answer("–í—ã–±—Ä–∞–Ω–æ: –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è")
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–±—Ä–∞–ª –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è")

            # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –æ–∫–Ω–∞ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è, —Ç–∞–∫ –∫–∞–∫ –≤—ã–±–æ—Ä —Å–¥–µ–ª–∞–Ω
            await state.update_data(intent_selection_shown=False)

            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–∫–Ω–æ –ø–æ–ª–∏—Ç–∏–∫–∏ (waiting_sticker_message –Ω–µ –Ω—É–∂–µ–Ω, —Ç–∞–∫ –∫–∞–∫ —ç—Ç–æ callback)
            await show_policy_window(callback.message, state, user_intent, None)

        elif intent_type == "continue":
            # –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã–±—Ä–∞–ª "–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å" - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—Å—è –∫ –§–∞–∑–µ 1
            await callback.answer("–ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—â–µ–Ω–∏–µ")
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–±—Ä–∞–ª –ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å - –≤–æ–∑–≤—Ä–∞—Ç –∫ –§–∞–∑–µ 1")

            # –Ø–≤–Ω–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∞–∑—É –≤ 1 –∏ —Å–±—Ä–∞—Å—ã–≤–∞–µ–º –≤—Å–µ —Ñ–ª–∞–≥–∏
            await state.update_data(
                phase=1,
                intent_selection_shown=False,
                original_query_for_continue="",
                anketa_started=False,
                anketa_question=None,
                continue_button_pressed=False,
            )

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ –≤–æ–ø—Ä–æ—Å–∞–º
            if callback.message:
                try:
                    await callback.message.answer("‚ñ∂Ô∏è –Ø –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º.")
                    if callback.from_user:
                        await save_chat_message(callback.from_user.id, "assistant", "‚ñ∂Ô∏è –Ø –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º.")
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏: {e}")
        else:
            logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –Ω–∞–º–µ—Ä–µ–Ω–∏—è: {intent_type}")
            await callback.answer("–û—à–∏–±–∫–∞: –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≤—ã–±–æ—Ä", show_alert=True)

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤—ã–±–æ—Ä–∞ –Ω–∞–º–µ—Ä–µ–Ω–∏—è: {e}", exc_info=True)
        await callback.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", show_alert=True)


@router.callback_query(F.data == "primary_source:open")
async def handle_primary_source_open(callback: CallbackQuery, state: FSMContext) -> None:
    logger = logging.getLogger(__name__)
    data = await state.get_data()
    fragments = data.get("primary_sources") or []
    primary_source_is_rules = data.get("primary_source_is_rules", False)
    logger.info(f"–û—Ç–∫—Ä—ã—Ç–∏–µ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞: fragments count={len(fragments)}, primary_source_is_rules={primary_source_is_rules}, data keys={list(data.keys())}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã
    if not primary_source_is_rules:
        logger.warning(f"–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∏ –Ω–µ —Ä–∞–∑—Ä–µ—à–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ (primary_source_is_rules=False)")
        await callback.answer("–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
        return

    # –ï—Å–ª–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ primary_source_is_rules=True, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∏—Ö –∑–∞–Ω–æ–≤–æ
    if not fragments:
        main_source = data.get("primary_source_main_source")
        if main_source and main_source in RULE_PRIMARY_ALLOWED_SOURCES:
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            logger.info(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ state, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {main_source}")
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏
            user_id = callback.from_user.id if callback.from_user else 0
            chat_history = await get_chat_history(user_id, limit=5)
            if chat_history:
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
                last_user_message = next((msg for msg in reversed(chat_history) if msg["role"] == "user"), None)
                if last_user_message:
                    user_query = last_user_message.get("content", "")
                    # –ò—â–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
                    try:
                        # –ü–æ–ª—É—á–∞–µ–º hits –∏–∑ state, –µ—Å–ª–∏ –æ–Ω–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, –∏–Ω–∞—á–µ –¥–µ–ª–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
                        saved_hits_data = data.get("primary_source_hits")
                        search_hits = []
                        if saved_hits_data:
                            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º hits –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                            from ..knowledge.text_search import SearchHit
                            for hit_data in saved_hits_data:
                                if isinstance(hit_data, dict):
                                    search_hits.append(SearchHit(
                                        text=hit_data.get("text", ""),
                                        source=hit_data.get("source", ""),
                                        score=hit_data.get("score", 0.0),
                                        title=hit_data.get("title", ""),
                                        figures=hit_data.get("figures", ""),
                                        section=hit_data.get("section", "")
                                    ))

                        if not search_hits:
                            # –ï—Å–ª–∏ hits –Ω–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã, –¥–µ–ª–∞–µ–º –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫
                            from ..knowledge import search_store as kb_search
                            search_results = kb_search.search(user_query, limit=5)
                            search_hits = search_results if search_results else []

                        fragments = search_store.get_primary_source_fragments(
                            search_hits,
                            user_query,
                            allowed_sources=[main_source],
                        )
                        if fragments:
                            await state.update_data(primary_sources=fragments, primary_source_index=0)
                            logger.info(f"–ù–∞–π–¥–µ–Ω–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –ø–æ–∏—Å–∫–µ: {len(fragments)}")
                        else:
                            logger.warning(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {main_source} –∏ –∑–∞–ø—Ä–æ—Å–∞ '{user_query[:50]}'")
                            await callback.answer("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
                            return
                    except Exception as e:
                        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤: {e}", exc_info=True)
                        await callback.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.", show_alert=True)
                        return
                else:
                    logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω –ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏–∏")
                    await callback.answer("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
                    return
            else:
                logger.warning(f"–ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞ –ø—É—Å—Ç–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                await callback.answer("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
                return
        else:
            logger.warning(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ state –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–∏—è –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞. data keys: {list(data.keys())}")
            await callback.answer("–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
            return

    # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    if not fragments or len(fragments) == 0:
        logger.warning(f"–§—Ä–∞–≥–º–µ–Ω—Ç—ã –ø—É—Å—Ç—ã –ø–æ—Å–ª–µ –ø–æ–≤—Ç–æ—Ä–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")
        await callback.answer("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
        return

    fragment = fragments[0]
    main_source = data.get("primary_source_main_source")
    fragment_source = fragment.get("source") if isinstance(fragment, dict) else None
    resolved_source = fragment_source or main_source
    download_info = _get_download_info_for_source(resolved_source) if resolved_source else None

    try:
        text = _format_primary_source_fragment(fragment, 0, len(fragments), download_info)
    except Exception as format_error:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: {format_error}", exc_info=True)
        await callback.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞.", show_alert=True)
        return

    markup = _build_primary_source_markup(0, len(fragments), download_info)

    await state.update_data(primary_source_index=0, primary_source_figure_messages=[])
    try:
        sent_message = await callback.message.answer(text, reply_markup=markup, parse_mode='HTML')
        await callback.answer()
    except Exception as send_error:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–æ–º: {send_error}", exc_info=True)
        await callback.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è.", show_alert=True)
        return

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∏—Å—É–Ω–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –¥–ª—è —ç—Ç–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
    figure_message_ids = []
    try:
        figures_to_send = _get_figures_for_fragment(fragment, main_source)
        for fig_key in figures_to_send:
            img_path = image_mapper.get_image_path_for_figure(fig_key)
            if img_path:
                try:
                    photo = FSInputFile(img_path)
                    title = image_mapper.get_figure_title(fig_key)
                    if title:
                        caption = f"{title} {fig_key}."
                    else:
                        caption = f"{fig_key}."
                    fig_message = await sent_message.answer_photo(photo=photo, caption=caption)
                    if fig_message and fig_message.message_id:
                        figure_message_ids.append(fig_message.message_id)
                except Exception as img_error:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {fig_key}: {img_error}")
        await state.update_data(primary_source_figure_messages=figure_message_ids)
    except Exception as fig_error:
        logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ä–∏—Å—É–Ω–∫–æ–≤ –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: {fig_error}")


@router.callback_query(F.data.startswith("phase4:"))
async def handle_phase4_button(callback: CallbackQuery, state: FSMContext) -> None:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–æ–∫ –§–∞–∑—ã 4 (–ó–∞–ø–∏—Å—å)"""
    logger = logging.getLogger(__name__)

    if not callback.from_user:
        logger.error("callback.from_user is None")
        await callback.answer("–û—à–∏–±–∫–∞: –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω", show_alert=True)
        return

    if not callback.message:
        logger.error("callback.message is None")
        await callback.answer("–û—à–∏–±–∫–∞: —Å–æ–æ–±—â–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ", show_alert=True)
        return

    user_id = callback.from_user.id
    button_type = callback.data.split(":")[1] if ":" in callback.data else ""

    # –û—Å—Ç–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –æ–∫–Ω–æ–º –≤ —á–∞—Ç–µ (–Ω–µ —É–¥–∞–ª—è–µ–º)

    try:
        if button_type == "self":
            # –ö–Ω–æ–ø–∫–∞ "üìû –°–ê–ú"
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ —Å—Ç–∞—Ç—É—Å (—Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Å—Ç–∞—Ä—ã–º —Å—Ç–∞—Ç—É—Å–æ–º)
            state_data = await state.get_data()
            old_status = state_data.get("old_status_before_intent", "")
            profile = await get_user_profile(user_id)
            current_status = (profile.status or "").strip() if profile else ""

            # –°—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è, –µ—Å–ª–∏ –æ–Ω –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Å—Ç–∞—Ä–æ–≥–æ –∏–ª–∏ –µ—Å–ª–∏ —Å—Ç–∞—Ä—ã–π –±—ã–ª –ø—É—Å—Ç—ã–º/–ß–∏—Ç–∞—Ç–µ–ª—å
            is_lead_status = current_status in ("–û–±—É—á–µ–Ω–∏–µ", "–ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è")
            status_changed = (
                current_status != old_status or
                (old_status in ("", "–ß–∏—Ç–∞—Ç–µ–ª—å") and is_lead_status)
            )

            # –ï—Å–ª–∏ —Å—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel
            if status_changed and is_lead_status:
                try:
                    from ..db.leads_excel import save_lead_to_excel
                    logger.info(f"üîÑ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ Excel –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id} (–°–∞–º, —Å—Ç–∞—Ç—É—Å –∏–∑–º–µ–Ω–∏–ª—Å—è): old='{old_status}' -> new='{current_status}'")
                    await save_lead_to_excel(profile, profile.name_sys or "" if profile else "")
                    logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –ª–∏–¥–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Excel: —Å—Ç–∞—Ç—É—Å='{current_status}'")
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤ Excel: {e}", exc_info=True)

            await state.update_data(phase=1, phase4_window_shown=False, phase4_state=None)
            message_text = "üëå<b>–ü—Ä–µ–∫—Ä–∞—Å–Ω–æ, –∂–¥—ë–º –í–∞—à–µ–≥–æ –∑–≤–æ–Ω–∫–∞!</b>\n... –∞ —è - –≤–µ—Å—å –≤–Ω–∏–º–∞–Ω–∏–µ, –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º! ‚ñ∂Ô∏è"
            await callback.message.answer(message_text, parse_mode=ParseMode.HTML)
            await save_chat_message(user_id, "assistant", message_text)
            await callback.answer()
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–±—Ä–∞–ª —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—É—é –∑–∞–ø–∏—Å—å, status_changed={status_changed}")

        elif button_type == "contacts":
            # –ö–Ω–æ–ø–∫–∞ "üë®‚Äçüéì –ö–û–ù–¢–ê–ö–¢–´"
            await state.update_data(phase4_state="waiting_name", phase4_window_shown=False)
            name_message = "üëç –î–∞–≤–∞–π—Ç–µ –∑–Ω–∞–∫–æ–º–∏—Ç—å—Å—è.\n<b>–í–∞—à–µ –ò–º—è?</b>\n(–∫–∞–∫ –∫ –í–∞–º –æ–±—Ä–∞—â–∞—Ç—å—Å—è)"
            await callback.message.answer(name_message, parse_mode=ParseMode.HTML)
            await save_chat_message(user_id, "assistant", name_message)
            await callback.answer()
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –≤—ã–±—Ä–∞–ª –æ—Å—Ç–∞–≤–∏—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç—ã")

        elif button_type == "cancel":
            # –ö–Ω–æ–ø–∫–∞ "‚ùå –û—Ç–º–µ–Ω–∞"
            # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            state_data = await state.get_data()
            invalid_messages = state_data.get("phase4_invalid_messages", [])

            # –£–¥–∞–ª—è–µ–º –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–≤–∫–ª—é—á–∞—è –æ—Ç–≤–µ—Ç—ã –±–æ—Ç–∞) –ø–µ—Ä–µ–¥ –æ—Ç–º–µ–Ω–æ–π
            if invalid_messages and callback.message and callback.message.chat:
                for msg_id in invalid_messages:
                    try:
                        await callback.message.bot.delete_message(
                            chat_id=callback.message.chat.id,
                            message_id=msg_id
                        )
                        logger.info(f"–£–¥–∞–ª–µ–Ω–æ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id} –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
                    except Exception as e:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ {msg_id} –ø—Ä–∏ –æ—Ç–º–µ–Ω–µ: {e}")

            await _normalize_state(state, user_id)
            cancel_message = "‚ñ∂Ô∏è –Ø –≥–æ—Ç–æ–≤ –∫ –í–∞—à–∏–º –≤–æ–ø—Ä–æ—Å–∞–º."
            await callback.message.answer(cancel_message, parse_mode=ParseMode.HTML)
            await save_chat_message(user_id, "assistant", cancel_message)
            await callback.answer()
            logger.info(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {user_id} –æ—Ç–º–µ–Ω–∏–ª –∑–∞–ø–∏—Å—å")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∫–Ω–æ–ø–∫–∏ –§–∞–∑—ã 4: {e}", exc_info=True)
        await callback.answer("‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.", show_alert=True)


async def _normalize_state(state: FSMContext, user_id: int) -> None:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–æ—Ç–∞ - —Å–±—Ä–æ—Å –≤—Å–µ—Ö –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π"""
    logger = logging.getLogger(__name__)
    try:
        await state.update_data(
            phase=1,
            phase4_window_shown=False,
            phase4_state=None,
            phase4_check_contacts=False,
            phase4_invalid_messages=[],
            anketa_started=False,
            anketa_question=None,
            anketa_retry_count=0,
            anketa_invalid_messages=[],
            intent_selection_shown=False,
            policy_shown=False,
            continue_button_pressed=False
        )
        logger.info(f"–°–æ—Å—Ç–æ—è–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–æ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è: {e}", exc_info=True)


@router.callback_query(F.data.startswith("primary_source:goto"))
async def handle_primary_source_goto(callback: CallbackQuery, state: FSMContext) -> None:
    logger = logging.getLogger(__name__)
    data = await state.get_data()
    if not data.get("primary_source_is_rules"):
        await callback.answer("–ü–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞.", show_alert=True)
        return

    fragments = data.get("primary_sources") or []
    if not fragments:
        await callback.answer("–§—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã.", show_alert=True)
        return

    parts = callback.data.split(":")
    try:
        requested_index = int(parts[-1])
    except (ValueError, IndexError):
        requested_index = 0

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–∏–∫–ª–∏—á–µ—Å–∫—É—é –Ω–∞–≤–∏–≥–∞—Ü–∏—é (–ø–æ –∫—Ä—É–≥—É)
    idx = requested_index % len(fragments) if len(fragments) > 0 else 0

    fragment = fragments[idx]
    main_source = data.get("primary_source_main_source")
    fragment_source = fragment.get("source") if isinstance(fragment, dict) else None
    resolved_source = fragment_source or main_source
    download_info = _get_download_info_for_source(resolved_source) if resolved_source else None
    text = _format_primary_source_fragment(fragment, idx, len(fragments), download_info)
    markup = _build_primary_source_markup(idx, len(fragments), download_info)

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ä–∏—Å—É–Ω–∫–∏ –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ—Ö–æ–¥–æ–º –∫ –Ω–æ–≤–æ–º—É —Ñ—Ä–∞–≥–º–µ–Ω—Ç—É
    old_figure_messages = data.get("primary_source_figure_messages") or []
    for msg_id in old_figure_messages:
        try:
            await callback.bot.delete_message(chat_id=callback.message.chat.id, message_id=msg_id)
        except Exception as del_error:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∏—Å—É–Ω–∫–æ–º {msg_id}: {del_error}")

    sent_message = None
    try:
        await callback.message.edit_text(text, reply_markup=markup, parse_mode='HTML')
        sent_message = callback.message
    except Exception:
        sent_message = await callback.message.answer(text, reply_markup=markup, parse_mode='HTML')

    await state.update_data(primary_source_index=idx)
    await callback.answer()

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–∏—Å—É–Ω–∫–∏, –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –¥–ª—è —ç—Ç–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞
    figure_message_ids = []
    if sent_message:
        try:
            figures_to_send = _get_figures_for_fragment(fragment, main_source)
            for fig_key in figures_to_send:
                img_path = image_mapper.get_image_path_for_figure(fig_key)
                if img_path:
                    try:
                        photo = FSInputFile(img_path)
                        title = image_mapper.get_figure_title(fig_key)
                        if title:
                            caption = f"{title} {fig_key}."
                        else:
                            caption = f"{fig_key}."
                        fig_message = await sent_message.answer_photo(photo=photo, caption=caption)
                        if fig_message and fig_message.message_id:
                            figure_message_ids.append(fig_message.message_id)
                    except Exception as img_error:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–ø—Ä–∞–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {fig_key}: {img_error}")
            await state.update_data(primary_source_figure_messages=figure_message_ids)
        except Exception as fig_error:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ —Ä–∏—Å—É–Ω–∫–æ–≤ –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞: {fig_error}")


@router.callback_query(F.data == "primary_source:close")
async def handle_primary_source_close(callback: CallbackQuery, state: FSMContext) -> None:
    logger = logging.getLogger(__name__)
    # –£–¥–∞–ª—è–µ–º —Ä–∏—Å—É–Ω–∫–∏ –ø—Ä–∏ –∑–∞–∫—Ä—ã—Ç–∏–∏ –æ–∫–Ω–∞
    data = await state.get_data()
    old_figure_messages = data.get("primary_source_figure_messages") or []
    for msg_id in old_figure_messages:
        try:
            await callback.bot.delete_message(chat_id=callback.message.chat.id, message_id=msg_id)
        except Exception as del_error:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ä–∏—Å—É–Ω–∫–æ–º {msg_id}: {del_error}")

    await state.update_data(primary_source_figure_messages=[])

    try:
        await callback.message.delete()
    except Exception:
        try:
            await callback.message.edit_reply_markup(reply_markup=None)
        except Exception:
            pass
    await callback.answer()


def register_faq(dp: Dispatcher) -> None:
    dp.include_router(router)


